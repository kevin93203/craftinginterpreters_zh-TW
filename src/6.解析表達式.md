# 6. Parsing Expressions 解析表達式

> *Grammar, which knows how to control even kings.*
>
> ​																									——Molière

語法，它甚至知道如何控制國王。（莫里哀）

> This chapter marks the first major milestone of the book. Many of us have cobbled together a mishmash of regular expressions and substring operations to extract some sense out of a pile of text. The code was probably riddled with bugs and a beast to maintain. Writing a *real* parser—one with decent error handling, a coherent internal structure, and the ability to robustly chew through a sophisticated syntax—is considered a rare, impressive skill. In this chapter, you will attain it.

本章是本書的第一個重要里程碑。我們中的許多人都曾將正則表達式和字符串操作糅合在一起，以便從一堆文本中提取一些信息。這些代碼可能充滿了錯誤，而且很難維護。編寫一個真正的解析器[^1]——具有良好的錯誤處理、一致的內部結構和能夠健壯地分析複雜語法的能力——被認為是一種罕見的、令人印象深刻的技能。在這一章中，你將獲得這種技能。

> It’s easier than you think, partially because we front-loaded a lot of the hard work in the [last chapter](http://craftinginterpreters.com/representing-code.html). You already know your way around a formal grammar. You’re familiar with syntax trees, and we have some Java classes to represent them. The only remaining piece is parsing—transmogrifying a sequence of tokens into one of those syntax trees.

這比想象中要簡單，部分是因為我們在上一章中提前完成了很多困難的工作。你已經對形式化語法瞭如指掌，也熟悉了語法樹，而且我們有一些Java類來表示它們。唯一剩下的部分是解析——將一個標記序列轉換成這些語法樹中的一個。

> Some CS textbooks make a big deal out of parsers. In the ’60s, computer scientists—understandably tired of programming in assembly language—started designing more sophisticated, human-friendly languages like Fortran and ALGOL. Alas, they weren’t very *machine*-friendly for the primitive computers of the time.

一些CS教科書在解析器上大做文章。在60年代，計算機科學家——他們理所當然地厭倦了用匯編語言編程——開始設計更復雜的、對人類友好的語言，比如Fortran和ALGOL[^2]。唉，對於當時原始的計算機來説，這些語言對機器並不友好。

> These pioneers designed languages that they honestly weren’t even sure how to write compilers for, and then did groundbreaking work inventing parsing and compiling techniques that could handle these new, big languages on those old, tiny machines.

這些先驅們設計了一些語言，説實話，他們甚至不知道如何編寫編譯器。然後他們做了開創性的工作，發明瞭解析和編譯技術，可以在那些老舊、小型的機器上處理這些新的、大型的語言。

> Classic compiler books read like fawning hagiographies of these heroes and their tools. The cover of *Compilers: Principles, Techniques, and Tools* literally has a dragon labeled “complexity of compiler design” being slain by a knight bearing a sword and shield branded “LALR parser generator” and “syntax directed translation”. They laid it on thick.

經典的編譯書讀起來就像是對這些英雄和他們的工具的吹捧傳記。《編譯器:原理、技術和工具》（*Compilers: Principles, Techniques, and Tools*）的封面上有一條標記着“編譯器設計複雜性”的龍，被一個手持劍和盾的騎士殺死，劍和盾上標記着“LALR解析器生成器”和“語法制導翻譯”。他們在過分吹捧。

> A little self-congratulation is well-deserved, but the truth is you don’t need to know most of that stuff to bang out a high quality parser for a modern machine. As always, I encourage you to broaden your education and take it in later, but this book omits the trophy case.

稍微的自我祝賀是當之無愧的，但事實是，你不需要知道其中的大部分知識，就可以為現代機器製作出高質量的解析器。一如既往，我鼓勵你先擴大學習範圍，以後再慢慢接受它，但這本書省略了獎盃箱。

> ## 6 . 1 Ambiguity and the Parsing Game

## 6.1 歧義與解析遊戲

> In the last chapter, I said you can “play” a context-free grammar like a game in order to *generate* strings. Parsers play that game in reverse. Given a string—a series of tokens—we map those tokens to terminals in the grammar to figure out which rules could have generated that string.
>

在上一章中，我説過你可以像“玩”遊戲一樣使用上下文無關的語法來*生成*字符串。解析器則以相反的方式玩遊戲。給定一個字符串(一系列語法標記)，我們將這些標記映射到語法中的終止符，以確定哪些規則可能生成該字符串。

> The “could have” part is interesting. It’s entirely possible to create a grammar that is *ambiguous*, where different choices of productions can lead to the same string. When you’re using the grammar to *generate* strings, that doesn’t matter much. Once you have the string, who cares how you got to it?
>

"可能產生 "這部分很有意思。我們完全有可能創建一個*模稜兩可*的語法，在這個語法中，不同的生成式可能會得到同一個字符串。當你使用該語法來*生成*字符串時，這一點不太重要。一旦你有了字符串，誰還會在乎你是怎麼得到它的呢？

> When parsing, ambiguity means the parser may misunderstand the user’s code. As we parse, we aren’t just determining if the string is valid Lox code, we’re also tracking which rules match which parts of it so that we know what part of the language each token belongs to. Here’s the Lox expression grammar we put together in the last chapter:
>

但是在解析時，歧義意味着解析器可能會誤解用户的代碼。當我們進行解析時，我們不僅要確定字符串是不是有效的Lox代碼，還要記錄哪些規則與代碼的哪些部分相匹配，以便我們知道每個標記屬於語言的哪一部分。下面是我們在上一章整理的Lox表達式語法：

```js
expression     → literal
               | unary
               | binary
               | grouping ;

literal        → NUMBER | STRING | "true" | "false" | "nil" ;
grouping       → "(" expression ")" ;
unary          → ( "-" | "!" ) expression ;
binary         → expression operator expression ;
operator       → "==" | "!=" | "<" | "<=" | ">" | ">="
               | "+"  | "-"  | "*" | "/" ;
```

> This is a valid string in that grammar:

下面是一個滿足語法的有效字符串：

![6 / 3 - 1](6.解析表達式/tokens.png)

> But there are two ways we could have generated it. One way is:

但是，有兩種方式可以生成該字符串。其一是：

> 1. Starting at `expression`, pick `binary`.
> 2. For the left-hand `expression`, pick `NUMBER`, and use `6`.
> 3. For the operator, pick `"/"`.
> 4. For the right-hand `expression`, pick `binary` again.
> 5. In that nested `binary` expression, pick `3 - 1`.
>

1. 從`expression`開始，選擇`binary`。
2. 對於左邊的`expression`，選擇`NUMBER`，並且使用`6`。
3. 對於操作符，選擇`/`。
4. 對於右邊的`expression`，再次選擇`binary`。
5. 在內層的`binary` 表達式中，選擇`3-1`。

> Another is:

其二是：

> 1. Starting at `expression`, pick `binary`.
> 2. For the left-hand `expression`, pick `binary` again.
> 3. In that nested `binary` expression, pick `6 / 3`.
> 4. Back at the outer `binary`, for the operator, pick `"-"`.
> 5. For the right-hand `expression`, pick `NUMBER`, and use `1`.
>

1. 從`expression`開始，選擇`binary`。
2. 對於左邊的`expression`，再次選擇`binary`。
3. 在內層的`binary` 表達式中，選擇`6/3`。
4. 返回外層的`binary` ，對於操作符，選擇`-`。
5. 對於右邊的`expression`，選擇`NUMBER`，並且使用`1`。

> Those produce the same *strings*, but not the same *syntax trees*:

它們產生相同的字符串，但對應的是不同的*語法樹*：

![Two valid syntax trees: (6 / 3) - 1 and 6 / (3 - 1)](6.解析表達式/syntax-trees.png)

> In other words, the grammar allows seeing the expression as `(6 / 3) - 1` or `6 / (3 - 1)`. The `binary` rule lets operands nest any which way you want. That in turn affects the result of evaluating the parsed tree. The way mathematicians have addressed this ambiguity since blackboards were first invented is by defining rules for precedence and associativity.

換句話説，這個語法可以將該表達式看作是 `(6 / 3) - 1`或`6 / (3 - 1)`。`binary` 規則運行操作數以任意方式嵌套，這反過來又會影響解析數的計算結果。自從黑板被髮明以來，數學家們解決這種模糊性的方法就是定義優先級和結合性規則。

- > **Precedence** determines which operator is evaluated first in an expression containing a mixture of different operators. Precedence rules tell us that we evaluate the `/` before the `-` in the above example. Operators with higher precedence are evaluated before operators with lower precedence. Equivalently, higher precedence operators are said to “bind tighter”.

- **優先級**決定了在一個包含不同運算符的混合表達式中，哪個運算符先被執行[^3]。優先級規則告訴我們，在上面的例子中，我們在`-`之前先計算`/`。優先級較高的運算符在優先級較低的運算符之前計算。同樣，優先級較高的運算符被稱為 "更嚴格的綁定"。

- > **Associativity** determines which operator is evaluated first in a series of the *same* operator. When an operator is **left-associative** (think “left-to-right”), operators on the left evaluate before those on the right. Since `-` is left-associative, this expression:

- **結合性**決定在一系列相同操作符中先計算哪個操作符。如果一個操作符是**左結合**的(可以認為是“從左到右”)時，左邊的操作符在右邊的操作符之前計算。因為`-`是左結合的，下面的表達式：

  ```java
  5 - 3 - 1
  ```

  > is equivalent to:

  等價於：

  ```java
  (5 - 3) - 1
  ```

  > Assignment, on the other hand, is **right-associative**. This:

  另一方面，賦值是**右結合**的。如：

  ```java
  a = b = c
  ```

  > is equivalent to:

  等價於：

  ```java
  a = (b = c)
  ```

> Without well-defined precedence and associativity, an expression that uses multiple operators is ambiguous—it can be parsed into different syntax trees, which could in turn evaluate to different results. We’ll fix that in Lox by applying the same precedence rules as C, going from lowest to highest.

如果沒有明確定義的優先級和結合性，使用多個運算符的表達式可能就會變得有歧義——它可以被解析為不同的語法樹，而這些語法樹又可能會計算出不同的結果。我們在Lox中會解決這個問題，使用與C語言相同的優先級規則，從低到高分別是：

| Name              | Operators         | Associates    |
| ----------------- | ----------------- | ------------- |
| Equality  等於    | `==` `!=`         | Left  左結合  |
| Comparison  比較  | `>` `>=` `<` `<=` | Left  左結合  |
| Term  加減運算    | `-` `+`           | Left  左結合  |
| Factor   乘除運算 | `/` `*`           | Left  左結合  |
| Unary  一元運算符 | `!` `-`           | Right  右結合 |

> Right now, the grammar stuffs all expression types into a single `expression` rule. That same rule is used as the non-terminal for operands, which lets the grammar accept any kind of expression as a subexpression, regardless of whether the precedence rules allow it.

現在，該語法將所有表達式類型都添加到一個 `expression`規則中。這條規則同樣作用於操作數中的非終止符，這使得語法中可以接受任何類型的表達式作為子表達式，而不管優先級規則是否允許。

> We fix that by stratifying the grammar. We define a separate rule for each precedence level.

我們通過對語法進行分層來解決這個問題。我們為每個優先級定義一個單獨的規則[^4]。

```js
expression     → ...
equality       → ...
comparison     → ...
term           → ...
factor         → ...
unary          → ...
primary        → ...
```

> Each rule here only matches expressions at its precedence level or higher. For example, `unary` matches a unary expression like `!negated` or a primary expression like `1234`. And `term` can match `1 + 2` but also `3 * 4 / 5`. The final `primary` rule covers the highest-precedence forms—literals and parenthesized expressions.

此處的每個規則僅匹配其當前優先級或更高優先級的表達式。 例如，`unary` 匹配一元表達式（如 `!negated`）或主表達式（如`1234`）。`term`可以匹配`1 + 2`，但也可以匹配`3 * 4 /5`。最後的`primary` 規則涵蓋優先級最高的形式——字面量和括號表達式。

> We just need to fill in the productions for each of those rules. We’ll do the easy ones first. The top `expression` rule matches any expression at any precedence level. Since `equality` has the lowest precedence, if we match that, then it covers everything.

我們只需要填寫每條規則的生成式。我們先從簡單的開始。頂級的`expression` 規則可以匹配任何優先級的表達式。由於`equality`的優先級最低，只要我們匹配了它，就涵蓋了一切[^5]。

```
expression     → equality
```

> Over at the other end of the precedence table, a primary expression contains all the literals and grouping expressions.

在優先級表的另一端，`primary`表達式包括所有的字面量和分組表達式。

```js
primary        → NUMBER | STRING | "true" | "false" | "nil"
               | "(" expression ")" ;
```

> A unary expression starts with a unary operator followed by the operand. Since unary operators can nest—`!!true` is a valid if weird expression—the operand can itself be a unary operator. A recursive rule handles that nicely.

一元表達式以一元操作符開頭，後跟操作數。因為一元操作符可以嵌套——`!!true`雖奇怪也是可用的表達式——這個操作數本身可以是一個一元表達式。遞歸規則可以很好地解決這個問題。

```js
unary          → ( "!" | "-" ) unary ;
```

> But this rule has a problem. It never terminates.

但是這條規則有一個問題，它永遠不會終止。

> Remember, each rule needs to match expressions at that precedence level *or higher*, so we also need to let this match a primary expression.

請記住，每個規則都需要匹配該優先級或更高優先級的表達式，因此我們還需要使其與主表達式匹配。

```js
unary          → ( "!" | "-" ) unary
               | primary ;
```

> That works.

這樣就可以了。

> The remaining rules are all binary operators. We’ll start with the rule for multiplication and division. Here’s a first try:

剩下的規則就是二元運算符。我們先從乘法和除法的規則開始。下面是第一次嘗試：

```js
factor         → factor ( "/" | "*" ) unary
               | unary ;
```

> The rule recurses to match the left operand. That enables the rule to match a series of multiplication and division expressions like `1 * 2 / 3`. Putting the recursive production on the left side and `unary` on the right makes the rule left-associative and unambiguous.

該規則遞歸匹配左操作數，這樣一來，就可以匹配一系列乘法和除法表達式，例如 `1 * 2 / 3`。將遞歸生成式放在左側並將`unary` 放在右側，可以使該規則具有左關聯性和明確性[^6]。

> All of this is correct, but the fact that the first symbol in the body of the rule is the same as the head of the rule means this production is **left-recursive**. Some parsing techniques, including the one we’re going to use, have trouble with left recursion. (Recursion elsewhere, like we have in `unary` and the indirect recursion for grouping in `primary` are not a problem.)

所有這些都是正確的，但規則主體中的第一個符號與規則頭部相同意味着這個生成式是**左遞歸**的。一些解析技術，包括我們將要使用的解析技術，在處理左遞歸時會遇到問題。(其他地方的遞歸，比如在`unary`中，以及在`primary`分組中的間接遞歸都不是問題。)

> There are many grammars you can define that match the same language. The choice for how to model a particular language is partially a matter of taste and partially a pragmatic one. This rule is correct, but not optimal for how we intend to parse it. Instead of a left recursive rule, we’ll use a different one.

你可以定義很多符合同一種語言的語法。如何對某一特定語言進行建模，一部分是品味問題，一部分是實用主義問題。這個規則是正確的，但對於我們後續的解析來説它並不是最優的。我們將使用不同的規則來代替左遞歸規則。

```js
factor         → unary ( ( "/" | "*" ) unary )* ;
```

> We define a factor expression as a flat *sequence* of multiplications and divisions. This matches the same syntax as the previous rule, but better mirrors the code we’ll write to parse Lox. We use the same structure for all of the other binary operator precedence levels, giving us this complete expression grammar:

我們將因子表達式定義為乘法和除法的扁平*序列*。這與前面的規則語法相同，但更好地反映了我們將編寫的解析Lox的代碼。我們對其它二元運算符的優先級使用相同的結構，從而得到下面這個完整的表達式語法：

```js
expression     → equality ;
equality       → comparison ( ( "!=" | "==" ) comparison )* ;
comparison     → term ( ( ">" | ">=" | "<" | "<=" ) term )* ;
term           → factor ( ( "-" | "+" ) factor )* ;
factor         → unary ( ( "/" | "*" ) unary )* ;
unary          → ( "!" | "-" ) unary
               | primary ;
primary        → NUMBER | STRING | "true" | "false" | "nil"
               | "(" expression ")" ;
```

This grammar is more complex than the one we had before, but in return we have eliminated the previous one’s ambiguity. It’s just what we need to make a parser.

這個語法比我們以前的那個更復雜，但反過來我們也消除了前一個語法定義中的歧義。這正是我們製作解析器時所需要的。

> ## 6 . 2 Recursive Descent Parsing

## 6.2 遞歸下降分析

> There is a whole pack of parsing techniques whose names are mostly combinations of “L” and “R”—[LL(k)](https://en.wikipedia.org/wiki/LL_parser), [LR(1)](https://en.wikipedia.org/wiki/LR_parser), [LALR](https://en.wikipedia.org/wiki/LALR_parser)—along with more exotic beasts like [parser combinators](https://en.wikipedia.org/wiki/Parser_combinator), [Earley parsers](https://en.wikipedia.org/wiki/Earley_parser), [the shunting yard algorithm](https://en.wikipedia.org/wiki/Shunting-yard_algorithm), and [packrat parsing](https://en.wikipedia.org/wiki/Parsing_expression_grammar). For our first interpreter, one technique is more than sufficient: **recursive descent**.
>

現在有一大堆解析技術，它們的名字大多是 "L "和 "R "的組合——[LL(k)](https://en.wikipedia.org/wiki/LL_parser)、[LR(1)](https://en.wikipedia.org/wiki/LR_parser)、[LALR](https://en.wikipedia.org/wiki/LALR_parser)——還有更多的異類，比如[解析器組合子](https://en.wikipedia.org/wiki/Parser_combinator)、[Earley parsers](https://en.wikipedia.org/wiki/Earley_parser)、[分流碼算法](https://en.wikipedia.org/wiki/Shunting-yard_algorithm)和[packrat解析](https://en.wikipedia.org/wiki/Parsing_expression_grammar)。對於我們的第一個解釋器來説，一種技術已經足夠了：**遞歸下降**。

> Recursive descent is the simplest way to build a parser, and doesn’t require using complex parser generator tools like Yacc, Bison or ANTLR. All you need is straightforward handwritten code. Don’t be fooled by its simplicity, though. Recursive descent parsers are fast, robust, and can support sophisticated error handling. In fact, GCC, V8 (the JavaScript VM in Chrome), Roslyn (the C# compiler written in C#) and many other heavyweight production language implementations use recursive descent. It rocks.
>

遞歸下降是構建解析器最簡單的方法，不需要使用複雜的解析器生成工具，如Yacc、Bison或ANTLR。你只需要直接手寫代碼。但是不要被它的簡單性所欺騙，遞歸下降解析器速度快、健壯，並且可以支持複雜的錯誤處理。事實上，GCC、V8 (Chrome中的JavaScript VM)、Roslyn(用c#編寫的c#編譯器)和許多其他重量級產品語言實現都使用了遞歸下降技術。它很好用。

> Recursive descent is considered a **top-down parser** because it starts from the top or outermost grammar rule (here `expression`) and works its way down into the nested subexpressions before finally reaching the leaves of the syntax tree. This is in contrast with bottom-up parsers like LR that start with primary expressions and compose them into larger and larger chunks of syntax.
>

遞歸下降被認為是一種**自頂向下解析器**，因為它從最頂部或最外層的語法規則(這裏是`expression`)開始，一直向下進入嵌套子表達式，最後到達語法樹的葉子。這與LR等自下而上的解析器形成鮮明對比，後者從初級表達式(primary)開始，將其組成越來越大的語法塊[^7]。

> A recursive descent parser is a literal translation of the grammar’s rules straight into imperative code. Each rule becomes a function. The body of the rule translates to code roughly like:

遞歸下降解析器是一種將語法規則直接翻譯成命令式代碼的文本翻譯器。每個規則都會變成一個函數，規則主體翻譯成代碼大致是這樣的：

| Grammar notation | Code representation                                          |
| ---------------- | ------------------------------------------------------------ |
| Terminal         | Code to match and consume a token      匹配並消費一個語法標記 |
| Nonterminal      | Call to that rule’s function       調用規則對應的函數        |
| `|`              | `if` or `switch` statement      if或switch語句               |
| `*` or `+`       | `while` or `for` loop      while或for循環                    |
| `?`              | `if` statement      if語句                                   |

> The descent is described as “recursive” because when a grammar rule refers to itself—directly or indirectly—that translates to a recursive function call.

下降被“遞歸”修飾是因為，如果一個規則引用自身（直接或間接）就會變為遞歸的函數調用。

> ### 6 . 2 . 1 The parser class

### 6.2.1 Parser類

> Each grammar rule becomes a method inside this new class:

每個語法規則都成為新類中的一個方法:

*<u>lox/Parser.java，創建新文件：</u>*

```java
package com.craftinginterpreters.lox;

import java.util.List;

import static com.craftinginterpreters.lox.TokenType.*;

class Parser {
  private final List<Token> tokens;
  private int current = 0;

  Parser(List<Token> tokens) {
    this.tokens = tokens;
  }
}
```

> Like the scanner, the parser consumes a flat input sequence, only now we’re reading tokens instead of characters. We store the list of tokens and use `current` to point to the next token eagerly waiting to be parsed.

與掃描器一樣，解析器也是消費一個扁平的輸入序列，只是這次我們要讀取的是語法標記而不是字符。我們會保存標記列表並使用`current`指向待解析的下一個標記。

> We’re going to run straight through the expression grammar now and translate each rule to Java code. The first rule, `expression`, simply expands to the `equality` rule, so that’s straightforward.

我們現在要直接執行表達式語法，並將每一條規則翻譯為Java代碼。第一條規則`expression`，簡單地展開為`equality`規則，所以很直接：

<u>*lox/Parser.java，在 Parser()方法後添加：*</u>

```java
  private Expr expression() {
    return equality();
  }
```

> Each method for parsing a grammar rule produces a syntax tree for that rule and returns it to the caller. When the body of the rule contains a nonterminal—a reference to another rule—we call that other rule’s method.

每個解析語法規則的方法都會生成該規則對應的語法樹，並將其返回給調用者。當規則主體中包含一個非終止符——對另一條規則的引用時，我們就會調用另一條規則對應的方法[^8]。

> The rule for equality is a little more complex.

`equality`規則有一點複雜：

```js
equality       → comparison ( ( "!=" | "==" ) comparison )* ;
```

> In Java, that becomes:

在Java中，這會變成：

*<u>lox/Parser.java，在 expression()後面添加：</u>*

```java
  private Expr equality() {
    Expr expr = comparison();

    while (match(BANG_EQUAL, EQUAL_EQUAL)) {
      Token operator = previous();
      Expr right = comparison();
      expr = new Expr.Binary(expr, operator, right);
    }

    return expr;
  }
```

> Let’s step through it. The first `comparison` nonterminal in the body translates to the first call to `comparison()` in the method. We take that result and store it in a local variable.

讓我們一步步來。規則體中的第一個 `comparison` 非終止符變成了方法中對 `comparison()` 的第一次調用。我們獲取結果並將其保存在一個局部變量中。

> Then, the `( ... )*` loop in the rule maps to a `while` loop. We need to know when to exit that loop. We can see that inside the rule, we must first find either a `!=` or `==` token. So, if we *don’t* see one of those, we must be done with the sequence of equality operators. We express that check using a handy `match()` method.

然後，規則中的`( ... )*`循環映射為一個`while`循環。我們需要知道何時退出這個循環。可以看到，在規則體中，我們必須先找到一個` !=` 或` == `標記。因此，如果我們*沒有*看到其中任一標記，我們必須結束相等(不相等)運算符的序列。我們使用一個方便的`match()`方法來執行這個檢查。

*<u>lox/Parser.java，在 equality()方法後添加：</u>*

```java
  private boolean match(TokenType... types) {
    for (TokenType type : types) {
      if (check(type)) {
        advance();
        return true;
      }
    }

    return false;
  }
```

> This checks to see if the current token has any of the given types. If so, it consumes the token and returns `true`. Otherwise, it returns `false` and leaves the current token alone. The `match()` method is defined in terms of two more fundamental operations.

這個檢查會判斷當前的標記是否屬於給定的類型之一。如果是，則消費該標記並返回`true`；否則，就返回`false`並保留當前標記。`match()`方法是由兩個更基本的操作來定義的。

> The `check()` method returns `true` if the current token is of the given type. Unlike `match()`, it never consumes the token, it only looks at it.

如果當前標記屬於給定類型，則`check()`方法返回`true`。與`match()`不同的是，它從不消費標記，只是讀取。

*<u>lox/Parser.java，在 match()方法後添加：</u>*

```java
  private boolean check(TokenType type) {
    if (isAtEnd()) return false;
    return peek().type == type;
  }
```

> The `advance()` method consumes the current token and returns it, similar to how our scanner’s corresponding method crawled through characters.

`advance()`方法會消費當前的標記並返回它，類似於掃描器中對應方法處理字符的方式。

*<u>lox/Parser.java，在 check()方法後添加：</u>*

```java
  private Token advance() {
    if (!isAtEnd()) current++;
    return previous();
  }
```

> These methods bottom out on the last handful of primitive operations.

這些方法最後都歸結於幾個基本操作。

*<u>lox/Parser.java，在 advance()後添加：</u>*

```java
  private boolean isAtEnd() {
    return peek().type == EOF;
  }

  private Token peek() {
    return tokens.get(current);
  }

  private Token previous() {
    return tokens.get(current - 1);
  }
```

> `isAtEnd()` checks if we’ve run out of tokens to parse. `peek()` returns the current token we have yet to consume, and `previous()` returns the most recently consumed token. The latter makes it easier to use `match()` and then access the just-matched token.

`isAtEnd()`檢查我們是否處理完了待解析的標記。`peek()`方法返回我們還未消費的當前標記，而`previous()`會返回最近消費的標記。後者讓我們更容易使用`match()`，然後訪問剛剛匹配的標記。

> That’s most of the parsing infrastructure we need. Where were we? Right, so if we are inside the `while` loop in `equality()`, then we know we have found a `!=` or `==` operator and must be parsing an equality expression.

這就是我們需要的大部分解析基本工具。我們説到哪裏了？對，如果我們在`equality()`的`while`循環中，也就能知道我們已經找到了一個`!=`或`==`操作符，並且一定是在解析一個等式表達式。

> We grab the matched operator token so we can track which kind of equality expression we have. Then we call `comparison()` again to parse the right-hand operand. We combine the operator and its two operands into a new `Expr.Binary` syntax tree node, and then loop around. For each iteration, we store the resulting expression back in the same `expr` local variable. As we zip through a sequence of equality expressions, that creates a left-associative nested tree of binary operator nodes.
>

我們獲取到匹配的操作符標記，這樣就可以知道我們要處理哪一類等式表達式。之後，我們再次調用`comparison()`解析右邊的操作數。我們將操作符和它的兩個操作數組合成一個新的`Expr.Binary`語法樹節點，然後開始循環。對於每一次迭代，我們都將結果表達式存儲在同一個`expr`局部變量中。在對等式表達式序列進行壓縮時，會創建一個由二元操作符節點組成的左結合嵌套樹[^9]。

![The syntax tree created by parsing 'a == b == c == d == e'](6.解析表達式/sequence.png)

> The parser falls out of the loop once it hits a token that’s not an equality operator. Finally, it returns the expression. Note that if the parser never encounters an equality operator, then it never enters the loop. In that case, the `equality()` method effectively calls and returns `comparison()`. In that way, this method matches an equality operator *or anything of higher precedence*.

一旦解析器遇到一個不是等式操作符的標記，就會退出循環。最後，它會返回對應的表達式。請注意，如果解析器從未遇到過等式操作符，它就永遠不會進入循環。在這種情況下，`equality()`方法有效地調用並返回`comparison()`。這樣一來，這個方法就會匹配一個等式運算符或*任何更高優先級的表達式*。

> Moving on to the next rule . . . 

繼續看下一個規則。

```js
comparison     → term ( ( ">" | ">=" | "<" | "<=" ) term )* ;
```

> Translated to Java:

翻譯成Java：

*<u>lox/Parser.java，在 equality()方法後添加：</u>*

```java
  private Expr comparison() {
    Expr expr = term();

    while (match(GREATER, GREATER_EQUAL, LESS, LESS_EQUAL)) {
      Token operator = previous();
      Expr right = term();
      expr = new Expr.Binary(expr, operator, right);
    }

    return expr;
  }
```

> The grammar rule is virtually identical to `equality` and so is the corresponding code. The only differences are the token types for the operators we match, and the method we call for the operands—now `term()` instead of `comparison()`. The remaining two binary operator rules follow the same pattern.

語法規則與`equality`幾乎完全相同，相應的代碼也是如此。唯一的區別是匹配的操作符的標記類型，而且現在獲取操作數時調用的方法是`term()`而不是`comparison()`。其餘兩個二元操作符規則遵循相同的模式。

> In order of precedence, first addition and subtraction:

按照優先級順序，先做加減法：

*<u>lox/Parser.java，在 comparison()方法後添加：</u>*

```java
  private Expr term() {
    Expr expr = factor();

    while (match(MINUS, PLUS)) {
      Token operator = previous();
      Expr right = factor();
      expr = new Expr.Binary(expr, operator, right);
    }

    return expr;
  }
```

> And finally, multiplication and division:

最後，是乘除法：

*<u>lox/Parser.java，在 term()方法後面添加：</u>*

```java
  private Expr factor() {
    Expr expr = unary();

    while (match(SLASH, STAR)) {
      Token operator = previous();
      Expr right = unary();
      expr = new Expr.Binary(expr, operator, right);
    }

    return expr;
  }
```

> That’s all of the binary operators, parsed with the correct precedence and associativity. We’re crawling up the precedence hierarchy and now we’ve reached the unary operators.

這就是所有的二元運算符，已經按照正確的優先級和結合性進行了解析。接下來，按照優先級層級，我們要處理一元運算符了。

```js
unary          → ( "!" | "-" ) unary
               | primary ;
```

> The code for this is a little different.

該規則對應的代碼有些不同。

*<u>lox/Parser.java，在 factor()方法後添加：</u>*

```java
  private Expr unary() {
    if (match(BANG, MINUS)) {
      Token operator = previous();
      Expr right = unary();
      return new Expr.Unary(operator, right);
    }

    return primary();
  }
```

> Again, we look at the current token to see how to parse. If it’s a `!` or `-`, we must have a unary expression. In that case, we grab the token and then recursively call `unary()` again to parse the operand. Wrap that all up in a unary expression syntax tree and we’re done.

同樣的，我們先檢查當前的標記以確認要如何進行解析[^10]。如果是`!`或`-`，我們一定有一個一元表達式。在這種情況下，我們使用當前的標記遞歸調用`unary()`來解析操作數。將所有這些都包裝到一元表達式語法樹中，我們就完成了。

> Otherwise, we must have reached the highest level of precedence, primary expressions.

否則，我們就達到了最高級別的優先級，即基本表達式。

```js
primary        → NUMBER | STRING | "true" | "false" | "nil"
               | "(" expression ")" ;
```

> Most of the cases for the rule are single terminals, so parsing is straightforward.

該規則中大部分都是終止符，可以直接進行解析。

*<u>lox/Parser.java，在 unary()方法後添加：</u>*

```java
  private Expr primary() {
    if (match(FALSE)) return new Expr.Literal(false);
    if (match(TRUE)) return new Expr.Literal(true);
    if (match(NIL)) return new Expr.Literal(null);

    if (match(NUMBER, STRING)) {
      return new Expr.Literal(previous().literal);
    }

    if (match(LEFT_PAREN)) {
      Expr expr = expression();
      consume(RIGHT_PAREN, "Expect ')' after expression.");
      return new Expr.Grouping(expr);
    }
  }
```

The interesting branch is the one for handling parentheses. After we match an opening `(` and parse the expression inside it, we *must* find a `)` token. If we don’t, that’s an error.

有趣的一點是處理括號的分支。當我們匹配了一個開頭`(`並解析了裏面的表達式後，我們必須找到一個`)`標記。如果沒有找到，那就是一個錯誤。

> ## 6 . 3 Syntax Errors

## 6.3 語法錯誤

> A parser really has two jobs:

解析器實際上有兩項工作：

1. > Given a valid sequence of tokens, produce a corresponding syntax tree.

   給定一個有效的標記序列，生成相應的語法樹。

2. > Given an *invalid* sequence of tokens, detect any errors and tell the user about their mistakes.

   給定一個*無效*的標記序列，檢測錯誤並告知用户。

> Don’t underestimate how important the second job is! In modern IDEs and editors, the parser is constantly reparsing code—often while the user is still editing it—in order to syntax highlight and support things like auto-complete. That means it will encounter code in incomplete, half-wrong states *all the time.*

不要低估第二項工作的重要性！在現代的IDE和編輯器中，為了語法高亮顯示和支持自動補齊等功能，當用户還在編輯代碼時，解析器就會不斷地重新解析代碼。這也意味着解析器*總是*會遇到不完整的、半錯誤狀態的代碼。

> When the user doesn’t realize the syntax is wrong, it is up to the parser to help guide them back onto the right path. The way it reports errors is a large part of your language’s user interface. Good syntax error handling is hard. By definition, the code isn’t in a well-defined state, so there’s no infallible way to know what the user *meant* to write. The parser can’t read your mind.

當用户沒有意識到語法錯誤時，解析器要幫助引導他們回到正確的道路上。在你的語言的人機交互中，錯誤反饋佔據了很大的比重。良好的語法錯誤處理是很難的。根據定義，代碼並不是處於良好定義的狀態，所以沒有可靠的方法能夠知道用户*想要*寫什麼。解析器無法讀懂你的思想。

> There are a couple of hard requirements for when the parser runs into a syntax error. A parser must:

當解析器遇到語法錯誤時，有幾個硬性要求。解析器必須能夠：

- > **Detect and report the error.** If it doesn’t detect the error and passes the resulting malformed syntax tree on to the interpreter, all manner of horrors may be summoned.

  **檢測並報告錯誤**。如果它沒有檢測到錯誤，並將由此產生的畸形語法樹傳遞給解釋器，就會出現各種可怕的情況。

- > **Avoid crashing or hanging.** Syntax errors are a fact of life, and language tools have to be robust in the face of them. Segfaulting or getting stuck in an infinite loop isn’t allowed. While the source may not be valid *code*, it’s still a valid *input to the parser* because users use the parser to learn what syntax is allowed.

  **避免崩潰或掛起**。語法錯誤是生活中不可避免的事實，面對語法錯誤，語言工具必須非常健壯。段錯誤或陷入無限循環是不允許的。雖然源代碼可能不是有效的*代碼*，但它仍然是*解析器的有效輸入*，因為用户使用解析器來了解什麼是允許的語法。

> Those are the table stakes if you want to get in the parser game at all, but you really want to raise the ante beyond that. A decent parser should:

如果你想參與到解析器的遊戲中來，這些就是桌面的籌碼，但你真的想提高賭注，除了這些。一個像樣的解析器還應該：

- > **Be fast.** Computers are thousands of times faster than they were when parser technology was first invented. The days of needing to optimize your parser so that it could get through an entire source file during a coffee break are over. But programmer expectations have risen as quickly, if not faster. They expect their editors to reparse files in milliseconds after every keystroke.

  **要快**。計算機的速度比最初發明解析器技術時快了幾千倍。那種需要優化解析器，以便它能在喝咖啡的時候處理完整個源文件的日子已經一去不復返了。但是程序員的期望值也上升得同樣快，甚至更快。他們希望他們的編輯器能在每次擊鍵後的幾毫秒內回覆文件。

- > **Report as many distinct errors as there are.** Aborting after the first error is easy to implement, but it’s annoying for users if every time they fix what they think is the one error in a file, a new one appears. They want to see them all.

  **儘可能多地報告出不同的錯誤**。在第一個錯誤後中止是很容易實現的，但是如果每次當用户修復文件中的一個錯誤時，又出現了另一個新的錯誤，這對用户來説是很煩人的。他們希望一次看到所有的錯誤。

- > **Minimize \*cascaded\* errors.** Once a single error is found, the parser no longer really knows what’s going on. It tries to get itself back on track and keep going, but if it gets confused, it may report a slew of ghost errors that don’t indicate other real problems in the code. When the first error is fixed, those phantoms disappear, because they reflect only the parser’s own confusion. Cascaded errors are annoying because they can scare the user into thinking their code is in a worse state than it is.

  **最小化*級聯*錯誤**。一旦發現一個錯誤，解析器就不再能知道發生了什麼。它會試圖讓自己回到正軌並繼續工作，但如果它感到混亂，它可能會報告大量的幽靈錯誤，而這些錯誤並不表明代碼中存在其它問題。當第一個錯誤被修正後，這些幽靈錯誤就消失了，因為它們只反映瞭解析器自身的混亂。級聯錯誤很煩人，因為它們會讓用户害怕，讓用户認為自己的代碼比實際情況更糟糕。

> The last two points are in tension. We want to report as many separate errors as we can, but we don’t want to report ones that are merely side effects of an earlier one.

最後兩點是相互矛盾的。我們希望儘可能多地報告單獨的錯誤，但我們不想報告那些只是由早期錯誤的副作用導致的錯誤。

> The way a parser responds to an error and keeps going to look for later errors is called **error recovery**. This was a hot research topic in the ’60s. Back then, you’d hand a stack of punch cards to the secretary and come back the next day to see if the compiler succeeded. With an iteration loop that slow, you *really* wanted to find every single error in your code in one pass.

解析器對一個錯誤做出反應，並繼續去尋找後面的錯誤的方式叫做**錯誤恢復**。這在60年代是一個熱門的研究課題。那時，你需要把一疊打孔卡交給秘書，第二天再來看看編譯器是否成功。在迭代循環如此緩慢的情況下，你真的會想在一次執行中找到代碼中的每個錯誤。

> Today, when parsers complete before you’ve even finished typing, it’s less of an issue. Simple, fast error recovery is fine.

如今，解析器在您甚至還沒有完成輸入之前就完成解析了，這不再是一個問題。 簡單，快速的錯誤恢復就可以了。

> ### 6 . 3 . 1 Panic mode error recovery

### 6.3.1 恐慌模式錯誤恢復

> Of all the recovery techniques devised in yesteryear, the one that best stood the test of time is called—somewhat alarmingly—**panic mode**. As soon as the parser detects an error, it enters panic mode. It knows at least one token doesn’t make sense given its current state in the middle of some stack of grammar productions.

在過去設計的所有恢復技術中，最能經受住時間考驗的一種叫做**恐慌模式**（有點令人震驚）。一旦解析器檢測到一個錯誤，它就會進入恐慌模式。它知道至少有一個token是沒有意義的，因為它目前的狀態是在一些語法生成式的堆棧中間。

> Before it can get back to parsing, it needs to get its state and the sequence of forthcoming tokens aligned such that the next token does match the rule being parsed. This process is called **synchronization**.

在程序繼續進行解析之前，它需要將自己的狀態和即將到來的標記序列對齊，使下一個標記能夠匹配正則解析的規則。這個過程稱為**同步**。

> To do that, we select some rule in the grammar that will mark the synchronization point. The parser fixes its parsing state by jumping out of any nested productions until it gets back to that rule. Then it synchronizes the token stream by discarding tokens until it reaches one that can appear at that point in the rule.

為此，我們在語法中選擇一些規則來標記同步點。解析器會跳出所有嵌套的生成式直到回退至該規則中，來修復其解析狀態。然後，它會丟棄標記，直到遇到一個可以匹配該規則的標記，以此來同步標記流。

> Any additional real syntax errors hiding in those discarded tokens aren’t reported, but it also means that any mistaken cascaded errors that are side effects of the initial error aren’t *falsely* reported either, which is a decent trade-off.

這些被丟棄的標記中隱藏的其它真正的語法錯誤都不會被報告，但是這也意味着由初始錯誤引起的其它級聯錯誤也不會被*錯誤地*報告出來，這是個不錯的權衡。

> The traditional place in the grammar to synchronize is between statements. We don’t have those yet, so we won’t actually synchronize in this chapter, but we’ll get the machinery in place for later.

語法中傳統的要同步的地方是語句之間。我們還沒有這些，所以我們不會在這一章中真正地同步，但我們會在以後把這些機制準備好。

> ### 6 . 3 . 2 Entering panic mode

### 6.3.2 進入恐慌模式

> Back before we went on this side trip around error recovery, we were writing the code to parse a parenthesized expression. After parsing the expression, it looks for the closing `)` by calling `consume()`. Here, finally, is that method:

在我們討論錯誤恢復之前，我們正在編寫解析括號表達式的代碼。在解析表達式之後，會調用`consume()`方法查找收尾的`)`。這裏，終於可以實現那個方法了：

*<u>lox/Parser.java，在 match()方法後添加：</u>*

```java
  private Token consume(TokenType type, String message) {
    if (check(type)) return advance();

    throw error(peek(), message);
  }
```

> It’s similar to `match()` in that it checks to see if the next token is of the expected type. If so, it consumes it and everything is groovy. If some other token is there, then we’ve hit an error. We report it by calling this:

它和 `match()`方法類似，檢查下一個標記是否是預期的類型。如果是，它就會消費該標記，一切都很順利。如果是其它的標記，那麼我們就遇到了錯誤。我們通過調用下面的方法來報告錯誤：

*<u>lox/Parser.java，在 previous()方法後添加：</u>*

```java
  private ParseError error(Token token, String message) {
    Lox.error(token, message);
    return new ParseError();
  }
```

> First, that shows the error to the user by calling:

首先，通過調用下面的方法向用户展示錯誤信息：

*<u>lox/Lox.java，在 report()方法後添加：</u>*

```java
  static void error(Token token, String message) {
    if (token.type == TokenType.EOF) {
      report(token.line, " at end", message);
    } else {
      report(token.line, " at '" + token.lexeme + "'", message);
    }
  }
```

> This reports an error at a given token. It shows the token’s location and the token itself. This will come in handy later since we use tokens throughout the interpreter to track locations in code.

該方法會報告給定標記處的錯誤。它顯示了標記的位置和標記本身。這在以後會派上用場，因為我們在整個解釋器中使用標記來跟蹤代碼中的位置。

> After we report the error, the user knows about their mistake, but what does the *parser* do next? Back in `error()`, we create and return a ParseError, an instance of this new class:

在我們報告錯誤後，用户知道了他們的錯誤，但接下來解析器要做什麼呢？回到`error()`方法中，我們創建並返回了一個`ParseError`，是下面這個新類的實例:

*<u>lox/Parser.java，在 Parser中嵌入內部類：</u>*

```java
class Parser {  
  // 新增部分開始
  private static class ParseError extends RuntimeException {}
  // 新增部分結束
  private final List<Token> tokens;
```

> This is a simple sentinel class we use to unwind the parser. The `error()` method *returns* the error instead of *throwing* it because we want to let the calling method inside the parser decide whether to unwind or not. Some parse errors occur in places where the parser isn’t likely to get into a weird state and we don’t need to synchronize. In those places, we simply report the error and keep on truckin’.

這是一個簡單的哨兵類，我們用它來幫助解析器擺脱錯誤。`error()`方法是*返回*錯誤而不是*拋出*錯誤，因為我們希望解析器內的調用方法決定是否要跳脱出該錯誤。有些解析錯誤發生在解析器不可能進入異常狀態的地方，這時我們就不需要同步。在這些地方，我們只需要報告錯誤，然後繼續解析。

> For example, Lox limits the number of arguments you can pass to a function. If you pass too many, the parser needs to report that error, but it can and should simply keep on parsing the extra arguments instead of freaking out and going into panic mode.

例如，Lox限制了你可以傳遞給一個函數的參數數量。如果你傳遞的參數太多，解析器需要報告這個錯誤，但它可以而且應該繼續解析額外的參數，而不是驚慌失措，進入恐慌模式[^11]。

> In our case, though, the syntax error is nasty enough that we want to panic and synchronize. Discarding tokens is pretty easy, but how do we synchronize the parser’s own state?

但是，在我們的例子中，語法錯誤非常嚴重，以至於我們要進入恐慌模式並進行同步。丟棄標記非常簡單，但是我們如何同步解析器自己的狀態呢？

> ### 6 . 3 . 3 Synchronizing a recursive descent parser
>

### 6.3.3 同步遞歸下降解析器

> With recursive descent, the parser’s state—which rules it is in the middle of recognizing—is not stored explicitly in fields. Instead, we use Java’s own call stack to track what the parser is doing. Each rule in the middle of being parsed is a call frame on the stack. In order to reset that state, we need to clear out those call frames.

在遞歸下降中，解析器的狀態（即它正在識別哪個規則）不是顯式存儲在字段中的。相反，我們使用Java自身的調用棧來跟蹤解析器正在做什麼。每一條正在被解析的規則都是棧上的一個調用幀。為了重置狀態，我們需要清除這些調用幀。

> The natural way to do that in Java is exceptions. When we want to synchronize, we *throw* that ParseError object. Higher up in the method for the grammar rule we are synchronizing to, we’ll catch it. Since we synchronize on statement boundaries, we’ll catch the exception there. After the exception is caught, the parser is in the right state. All that’s left is to synchronize the tokens.

在Java中，最自然的實現方式是異常。當我們想要同步時，我們拋出ParseError對象。在我們正同步的語法規則的方法上層，我們將捕獲它。因為我們在語句邊界上同步，所以我們可以在那裏捕獲異常。捕獲異常後，解析器就處於正確的狀態。剩下的就是同步標記了。

> We want to discard tokens until we’re right at the beginning of the next statement. That boundary is pretty easy to spot—it’s one of the main reasons we picked it. *After* a semicolon, we’re probably finished with a statement. Most statements start with a keyword—`for`, `if`, `return`, `var`, etc. When the *next* token is any of those, we’re probably about to start a statement.

我們想要丟棄標記，直至達到下一條語句的開頭。這個邊界很容易發現——這也是我們選其作為邊界的原因。在*分號*之後，我們可能就結束了一條語句[^12]。大多數語句都通過一個關鍵字開頭——`for`、 `if`、 `return`、 `var`等等。當下一個標記是其中之一時，我們可能就要開始一條新語句了。

> This method encapsulates that logic:

下面的方法封裝了這個邏輯：

*<u>lox/Parser.java，在 error()方法後添加：</u>*

```java
  private void synchronize() {
    advance();

    while (!isAtEnd()) {
      if (previous().type == SEMICOLON) return;

      switch (peek().type) {
        case CLASS:
        case FUN:
        case VAR:
        case FOR:
        case IF:
        case WHILE:
        case PRINT:
        case RETURN:
          return;
      }

      advance();
    }
  }
```

> It discards tokens until it thinks it has found a statement boundary. After catching a ParseError, we’ll call this and then we are hopefully back in sync. When it works well, we have discarded tokens that would have likely caused cascaded errors anyway, and now we can parse the rest of the file starting at the next statement.

該方法會不斷丟棄標記，直到它發現一個語句的邊界。在捕獲一個ParseError後，我們會調用該方法，然後我們就有望回到同步狀態。當它工作順利時，我們就已經丟棄了無論如何都可能會引起級聯錯誤的語法標記，現在我們可以從下一條語句開始解析文件的其餘部分。

> Alas, we don’t get to see this method in action, since we don’t have statements yet. We’ll get to that [in a couple of chapters](http://craftinginterpreters.com/statements-and-state.html). For now, if an error occurs, we’ll panic and unwind all the way to the top and stop parsing. Since we can parse only a single expression anyway, that’s no big loss.

唉，我們還沒有看到這個方法的實際應用，因為我們目前還沒有語句。我們會在後面幾章中開始引入語句。現在，如果出現錯誤，我們就會進入恐慌模式，一直跳出到最頂層，並停止解析。由於我們只能解析一個表達式，所以這並不是什麼大損失。

> ## 6 . 4 Wiring up the Parser
>

## 6.4 調整解析器

> We are mostly done parsing expressions now. There is one other place where we need to add a little error handling. As the parser descends through the parsing methods for each grammar rule, it eventually hits `primary()`. If none of the cases in there match, it means we are sitting on a token that can’t start an expression. We need to handle that error too.

我們現在基本上已經完成了對錶達式的解析。我們還需要在另一個地方添加一些錯誤處理。當解析器在每個語法規則的解析方法中下降時，它最終會進入`primary()`。如果該方法中的case都不匹配，就意味着我們正面對一個不是表達式開頭的語法標記。我們也需要處理這個錯誤。

*<u>lox/Parser.java，在 primary()方法中添加：</u>*

```java
    if (match(LEFT_PAREN)) {
      Expr expr = expression();
      consume(RIGHT_PAREN, "Expect ')' after expression.");
      return new Expr.Grouping(expr);
    }
    // 新增部分開始
    throw error(peek(), "Expect expression.");
    // 新增部分結束
  }
```

> With that, all that remains in the parser is to define an initial method to kick it off. That method is called, naturally enough, `parse()`.

這樣，解析器中剩下的工作就是定義一個初始方法來啓動它。這個方法自然應該叫做`parse()`。

*<u>lox/Parser.java，在 Parser()方法後添加：</u>*

```java
  Expr parse() {
    try {
      return expression();
    } catch (ParseError error) {
      return null;
    }
  }
```

> We’ll revisit this method later when we add statements to the language. For now, it parses a single expression and returns it. We also have some temporary code to exit out of panic mode. Syntax error recovery is the parser’s job, so we don’t want the ParseError exception to escape into the rest of the interpreter.

稍後在向語言中添加語句時，我們將重新審視這個方法。目前，它只解析一個表達式並返回它。我們還有一些臨時代碼用於退出恐慌模式。語法錯誤恢復是解析器的工作，所以我們不希望ParseError異常逃逸到解釋器的其它部分。

> When a syntax error does occur, this method returns `null`. That’s OK. The parser promises not to crash or hang on invalid syntax, but it doesn’t promise to return a *usable syntax tree* if an error is found. As soon as the parser reports an error, `hadError` gets set, and subsequent phases are skipped.

當確實出現語法錯誤時，該方法會返回`null`。這沒關係。解析器承諾不會因為無效語法而崩潰或掛起，但它不承諾在發現錯誤時返回一個*可用的語法樹*。一旦解析器報告錯誤，就會對`hadError`賦值，然後跳過後續階段。

> Finally, we can hook up our brand new parser to the main Lox class and try it out. We still don’t have an interpreter, so for now, we’ll parse to a syntax tree and then use the AstPrinter class from the [last chapter](http://craftinginterpreters.com/representing-code.html#a-(not-very)-pretty-printer) to display it.

最後，我們可以將全新的解析器掛到Lox主類並進行試驗。我們仍然還沒有解釋器，所以現在，我們將表達式解析為一個語法樹，然後使用上一章中的AstPrinter類來顯示它。

> Delete the old code to print the scanned tokens and replace it with this:

刪除打印已掃描標記的舊代碼，將其替換為：

*<u>lox/Lox.java，在 run()方法中，替換其中5行</u>*

```java
    List<Token> tokens = scanner.scanTokens();
    // 替換部分開始
    Parser parser = new Parser(tokens);
    Expr expression = parser.parse();

    // Stop if there was a syntax error.
    if (hadError) return;

    System.out.println(new AstPrinter().print(expression));
    // 替換部分結束
  }
```

> Congratulations, you have crossed the threshold! That really is all there is to handwriting a parser. We’ll extend the grammar in later chapters with assignment, statements, and other stuff, but none of that is any more complex than the binary operators we tackled here.

祝賀你，你已經跨過了門檻!這就是手寫解析器的全部內容[^13]。我們將在後面的章節中擴展賦值、語句和其它特性對應的語法，但這些都不會比我們本章處理的二元操作符更復雜。

> Fire up the interpreter and type in some expressions. See how it handles precedence and associativity correctly? Not bad for less than 200 lines of code.

啓動解釋器並輸入一些表達式。查看它是如何正確處理優先級和結合性的?這對於不到200行代碼來説已經很不錯了。



[^1]: 英語中的"Parse "來自古法語 "pars"，意為 "語言的一部分"。它的意思是取一篇文章，把每一個詞都映射到語言的語法上。我們在這裏使用它也是這個意思，只不過我們的語言比古法語更現代一些。
[^2]: 可以想見，在那些老機器上進行彙編編程是多麼痛苦，以至於他們認為Fortran是一種改進。
[^3]: 雖然現在並不常見，但有些語言規定某些運算符之間沒有相對優先級。這種語言中，在表達式中混合使用這些操作符而不使用顯式分組是一種語法錯誤。同樣，有些運算符是**非結合**的。這意味着在語句序列中多次使用該操作符是錯誤的。例如，Perl的範圍操作符是非結合的，所以`a ..b`是可以的，但是`a ..b . .c`是錯誤的。
[^4]: 一些解析器生成器並沒有將優先級直接寫入語法規則中，而是允許你保持同樣的模糊但簡單的語法，然後在旁邊添加一點明確的操作符優先級元數據，以消除歧義。
[^5]: 我們可以取消`expression`，而只是在其他包含表達式的規則中使用`equality`，但使用`expression`會使這些其他規則可讀性更好。另外，在後面的章節中，當我們將語法擴展到包括賦值和邏輯運算符時，我們只需要改變`expression`的生成式，而不需要修改每條包含`expression`的規則。
[^6]: 原則上，你把乘法當作左關聯還是右關聯都沒有關係——無論你使用哪種方式都可以得到相同的結果。但是，在精度有限的情況下，舍入和溢出意味着關聯性會影響乘法序列的計算結果。如`print 0. 1 * (0. 2 * 0. 3);`和`print (0.1 * 0.2) * 0.3;`，在Lox等使用[IEEE 754](https://en.wikipedia.org/wiki/Double-precision_floating-point_format)雙精度浮點數的語言中，第一個算式的計算結果是`0.006`，而第二個算式的計算結果是`0.006000000000000001`。有時，這種微小的差異很重要。可以在[這裏](https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html)瞭解更多信息。

[^7]: 該方法之所以被稱為“遞歸*下降*”，是因為它是沿着語法*向下*運行的。令人困惑的是，在談論“高”和“低”優先級時，我們也使用方向來比喻，但是方向卻是相反的。在自頂向下的解析器中，首先達到優先級最低的表達式，因為其中可能包含優先級更高的子表達式。<br/>![Top-down grammar rules in order of increasing precedence.](6.解析表達式/direction.png)<br/>CS的人真的需要聚在一起理清他們的隱喻。甚至不要讓我開始討論堆棧向哪個方向生長，或者為什麼樹的根在上面。
[^8]: 這就是為什麼左遞歸對於遞歸下降是有問題的。左遞歸規則的函數會立即調用自身，並循環往復，直到解析器遇到堆棧溢出並崩潰。
[^9]: 解析`a==b==c==d`。對於每一次迭代，使用前一個子式結果作為左操作數並創建一個新的二元表達式。
[^10]: 解析器提前觀察即將到來的標記來決定如何解析，這就把遞歸下降納入了**預測性解析器**的範疇。
[^11]: 另一種處理常見語法錯誤的方法是**錯誤生成式**。你可以使用一個能*成功*匹配*錯誤*語法的規則來擴充語法。解析器可以對其進行安全地解析，但是不會生成語法樹，而是會報告一個錯誤。<br/>舉例來説，有些語言中有一元運算符`+`，如`+123`，但是Lox不支持。當解析器在表達式的開頭遇到一個`+`時，我們不必感到困惑，我們可以擴展一元規則來允許該語法。<br/>`unary          → ( "!" | "-" | "+" ) unary | primary ;`<br/>這樣解析器就會消費`+`標記，而不是進入恐慌模式或讓解析器陷入奇怪的狀態。<br/>錯誤生成式的效果很好。因為你作為解析器的作者，知道代碼的*如何*出錯的以及用户想要做什麼。這意味着你可以給出一個更有用的信息來幫助用户回到正軌，比如，"不支持一元'+'表達式"。成熟的解析器往往會積累錯誤生成式，因為它們可以幫助用户修復常見的錯誤。
[^12]: 我説 "可能 "是因為我們可以在for循環中碰到分隔子句的分號。我們的同步並不完美，但這沒關係。我們已經準確地報告了第一個錯誤，所以之後的一切都算是 "盡力而為 "了。
[^13]: 你可能會定義一個比Lox更復雜的語法，使用遞歸下降法難以對其解析。當你可能需要預先查看大量的標記以弄清你面臨的情況時，預測性解析就變得很棘手。實際上，大多數語言都是為了避免這種情況而設計的。 即使情況並非如此，您通常也可以毫不費力地解決問題。 既然您可以使用遞歸下降來解析C ++（許多C ++編譯器都可以做到），那麼您就可以解析任何內容。



------

> ## CHALLENGES

## 習題

> 1、In C, a block is a statement form that allows you to pack a series of statements where a single one is expected. The [comma operator](https://en.wikipedia.org/wiki/Comma_operator) is an analogous syntax for expressions. A comma-separated series of expressions can be given where a single expression is expected (except inside a function call’s argument list). At runtime, the comma operator evaluates the left operand and discards the result. Then it evaluates and returns the right operand.
>
> Add support for comma expressions. Give them the same precedence and associativity as in C. Write the grammar, and then implement the necessary parsing code.

1、在C語言中，塊是一種語句形式，它允許你把一系列的語句打包作為一個語句來使用。[逗號運算符](https://en.wikipedia.org/wiki/Comma_operator)是表達式的類似語法。可以在需要單個表達式的地方給出以逗號分隔的表達式序列(函數調用的參數列表除外)。在運行時，逗號操作符計算左操作數並丟棄結果。然後計算並返回右操作數。

添加對逗號表達式的支持。賦予它們與c語言中相同的優先級和結合性。編寫語法，然後實現必要的解析代碼。

> 2、Likewise, add support for the C-style conditional or “ternary” operator `?:`. What precedence level is allowed between the `?` and `:`? Is the whole operator left-associative or right-associative?

2、同樣，添加對C風格的條件操作符或 "三元 "操作符`?:`的支持。在`?`和`:`之間採用什麼優先級順序？整個操作符是左關聯還是右關聯？

> 3、Add error productions to handle each binary operator appearing without a left-hand operand. In other words, detect a binary operator appearing at the beginning of an expression. Report that as an error, but also parse and discard a right-hand operand with the appropriate precedence.

3、添加錯誤生成式處理沒有左操作數的二元操作符。換句話説，檢測出現在表達式開頭的二元操作符。將其作為錯誤報告給用户，同時也要解析並丟棄具有相應優先級的右操作數。

------

> ## DESIGN NOTE: LOGIC VERSUS HISTORY

> Let’s say we decide to add bitwise `&` and `|` operators to Lox. Where should we put them in the precedence hierarchy? C—and most languages that follow in C’s footsteps—place them below `==`. This is widely considered a mistake because it means common operations like testing a flag require parentheses.
>
> ```
> if (flags & FLAG_MASK == SOME_FLAG) { ... } // Wrong.
> if ((flags & FLAG_MASK) == SOME_FLAG) { ... } // Right.
> ```
>
> Should we fix this for Lox and put bitwise operators higher up the precedence table than C does? There are two strategies we can take.
>
> You almost never want to use the result of an `==` expression as the operand to a bitwise operator. By making bitwise bind tighter, users don’t need to parenthesize as often. So if we do that, and users assume the precedence is chosen logically to minimize parentheses, they’re likely to infer it correctly.
>
> This kind of internal consistency makes the language easier to learn because there are fewer edge cases and exceptions users have to stumble into and then correct. That’s good, because before users can use our language, they have to load all of that syntax and semantics into their heads. A simpler, more rational language *makes sense*.
>
> But, for many users there is an even faster shortcut to getting our language’s ideas into their wetware—*use concepts they already know*. Many newcomers to our language will be coming from some other language or languages. If our language uses some of the same syntax or semantics as those, there is much less for the user to learn (and *unlearn*).
>
> This is particularly helpful with syntax. You may not remember it well today, but way back when you learned your very first programming language, code probably looked alien and unapproachable. Only through painstaking effort did you learn to read and accept it. If you design a novel syntax for your new language, you force users to start that process all over again.
>
> Taking advantage of what users already know is one of the most powerful tools you can use to ease adoption of your language. It’s almost impossible to overestimate how valuable this is. But it faces you with a nasty problem: What happens when the thing the users all know *kind of sucks*? C’s bitwise operator precedence is a mistake that doesn’t make sense. But it’s a *familiar* mistake that millions have already gotten used to and learned to live with.
>
> Do you stay true to your language’s own internal logic and ignore history? Do you start from a blank slate and first principles? Or do you weave your language into the rich tapestry of programming history and give your users a leg up by starting from something they already know?
>
> There is no perfect answer here, only trade-offs. You and I are obviously biased towards liking novel languages, so our natural inclination is to burn the history books and start our own story.
>
> In practice, it’s often better to make the most of what users already know. Getting them to come to your language requires a big leap. The smaller you can make that chasm, the more people will be willing to cross it. But you can’t *always* stick to history, or your language won’t have anything new and compelling to give people a *reason* to jump over.

## 設計筆記：邏輯和歷史

假設我們決定在Lox中添加位元`&`和`|`運算符。我們應該將它們放在優先級層次結構的哪個位置？ C（以及大多數跟隨C語言步伐的語言）將它們放在`==`之下。 目前普遍認為這是一個錯誤，因為這意味着檢測標誌位等常用操作都需要加括號。

```java
if (flags & FLAG_MASK == SOME_FLAG) { ... } // Wrong.
if ((flags & FLAG_MASK) == SOME_FLAG) { ... } // Right.
```

我們是否應該在 Lox 中修正這個問題，為位運算符賦予比 C 中更高的優先級？我們可以採取兩種策略。

幾乎可以肯定你不會想把`==`表達式的計算結果當作位運算的操作數。將位運算操作綁定更緊密，用户就不需要像以前那樣經常使用括號。所以如果我們這樣做，並且用户認為優先級的選擇是合乎邏輯的，是為了儘量減少小括號，他們很可能會正確地推斷出來。

這種內部一致性使語言更容易學習，因為用户需要糾正的邊界情況和異常變少了。這很好，因為用户在使用我們的語言之前，需要先理解所有的語法和語義。一個更簡單、更合理的語言是*有意義的*。

但是，對於許多用户來説，有一個更快的捷徑，可以將我們語言的思想融入他們的濕件中——*使用他們已經知道的概念*。許多我們語言的新用户都使用過其它一門或多門語言。如果我們的語言使用了與那些語言相同的一些語法或語義，那麼用户需要學習（和*忘掉*）的東西就會少很多。

這對詞法語法特別有幫助。您現在可能不太記得了，但是回想一下您學習第一門編程語言時，代碼看起來似乎很陌生且難以理解。 只有通過艱苦的努力，您才學會閲讀和接受它。 如果你為你的新語言設計了一種新穎的語法，你就會迫使用户重新開始這個過程。

利用用户已經知道的知識，是你可以用來簡化語言採用的最強大的工具之一。這一點的價值怎麼估計都不過分。但它也給你帶來了一個棘手的問題：如果用户都知道的東西*有點糟糕*時，會發生什麼？C語言的位運算操作符優先是一個沒有意義的錯誤。但這是一個數以百萬計的人已經習慣並學會忍受的熟悉錯誤。

你是否忠於語言的內在邏輯而忽略歷史？你是從一張白紙和基本原則開始的嗎？還是把你的語言編織到豐富的編程歷史中去，從用户已經知道的東西開始，使您的用户受益？

這裏沒有完美的答案，只有權衡取捨。你和我顯然都傾向於喜歡新奇的語言，所以我們的自然傾向是燒掉歷史書，開始我們自己的故事。

在實踐中，充分利用用户已經知道的知識往往更好。讓他們來使用你的語言需要一個大的跨越。兩個語言間的鴻溝越小，人們就越願意跨越它。但你不能總是拘泥於歷史，否則你的語言就不會有什麼新穎的、令人信服的東西讓用户們有理由跳過去。

