# 14. Chunks of Bytecode 字節碼塊

> If you find that you’re spending almost all your time on theory, start turning some attention to practical things; it will improve your theories. If you find that you’re spending almost all your time on practice, start turning some attention to theoretical things; it will improve your practice.
>
> ​																																									——Donald Knuth

如果你發現你幾乎把所有的時間都花在了理論上，那就開始把一些注意力轉向實際的東西；這會提高你的理論水平。如果你發現你幾乎把所有的時間都花在了實踐上，那就開始把一些注意力轉向理論上的東西；這將改善你的實踐。（高德納）

> We already have ourselves a complete implementation of Lox with jlox, so why isn’t the book over yet? Part of this is because jlox relies on the JVM to do lots of things for us. If we want to understand how an interpreter works all the way down to the metal, we need to build those bits and pieces ourselves.

我們已經有了一個Lox 的完整實現jlox，那麼為什麼這本書還沒有結束呢？部分原因是jlox依賴JVM為我們做很多事情[^1]。如果我們想要了解一個解釋器是如何工作的，我們就需要自己構建這些零碎的東西。

> An even more fundamental reason that jlox isn’t sufficient is that it’s too damn slow. A tree-walk interpreter is fine for some kinds of high-level, declarative languages. But for a general-purpose, imperative language—even a “scripting” language like Lox—it won’t fly. Take this little script:

jlox不夠用的一個更根本的原因在於，它太慢了。樹遍歷解釋器對於某些高級的聲明式語言來説是不錯的，但是對於通用的命令式語言——即使是Lox這樣的“腳本”語言——這是行不通的。以下面的小腳本為例[^2]：

```javascript
fun fib(n) {
  if (n < 2) return n;
  return fib(n - 1) + fib(n - 2); 
}

var before = clock();
print fib(40);
var after = clock();
print after - before;
```

> On my laptop, that takes jlox about 72 seconds to execute. An equivalent C program finishes in half a second. Our dynamically typed scripting language is never going to be as fast as a statically typed language with manual memory management, but we don’t need to settle for more than *two orders of magnitude* slower.

在我的筆記本電腦上，jlox大概需要72秒的時間來執行。一個等價的C程序在半秒內可以完成。我們的動態類型的腳本語言永遠不可能像手動管理內存的靜態類型語言那樣快，但我們沒必要滿足於慢兩個數量級以上的速度。

> We could take jlox and run it in a profiler and start tuning and tweaking hotspots, but that will only get us so far. The execution model—walking the AST—is fundamentally the wrong design. We can’t micro-optimize that to the performance we want any more than you can polish an AMC Gremlin into an SR-71 Blackbird.

我們可以把jlox放在性能分析器中運行，並進行調優和調整熱點，但這也只能到此為止了。它的執行模型（遍歷AST）從根本上説就是一個錯誤的設計。我們無法將其微優化到我們想要的性能，就像你無法將AMC Gremlin打磨成SR-71 Blackbird一樣。

> We need to rethink the core model. This chapter introduces that model, bytecode, and begins our new interpreter, clox.

我們需要重新考慮核心模型。本章將介紹這個模型——字節碼，並開始我們的新解釋器，clox。

> ## 14 . 1 Bytecode?

## 14.1 字節碼？

> In engineering, few choices are without trade-offs. To best understand why we’re going with bytecode, let’s stack it up against a couple of alternatives.

在工程領域，很少有選擇是不需要權衡的。為了更好地理解我們為什麼要使用字節碼，讓我們將它與幾個備選方案進行比較。

> ### 14 . 1 . 1 Why not walk the AST?

### 14.1.1 為什麼不遍歷AST？

> Our existing interpreter has a couple of things going for it:

我們目前的解釋器有幾個優點：

- > Well, first, we already wrote it. It’s done. And the main reason it’s done is because this style of interpreter is *really simple to implement*. The runtime representation of the code directly maps to the syntax. It’s virtually effortless to get from the parser to the data structures we need at runtime.

  嗯，首先我們已經寫好了，它已經完成了。它能完成的主要原因是這種風格的解釋器*實現起來非常簡單*。代碼的運行時表示直接映射到語法。從解析器到我們在運行時需要的數據結構，幾乎都毫不費力。

- It’s *portable*. Our current interpreter is written in Java and runs on any platform Java supports. We could write a new implementation in C using the same approach and compile and run our language on basically every platform under the sun.

  它是可移植的。我們目前的解釋器是使用Java編寫的，可以在Java支持的任何平台上運行。我們可以用同樣的方法在C語言中編寫一個新的實現，並在世界上幾乎所有平台上編譯並運行我們的語言。

> Those are real advantages. But, on the other hand, it’s *not memory-efficient*. Each piece of syntax becomes an AST node. A tiny Lox expression like `1 + 2` turns into a slew of objects with lots of pointers between them, something like:

這些是真正的優勢。但是，另一方面，它的內存使用效率不高。每一段語法都會變成一個AST節點。像`1+2`這樣的Lox表達式會變成一連串的對象，對象之間有很多指針，就像[^3]：

![The tree of Java objects created to represent '1 + 2'.](14.字節碼塊/ast.png)

> Each of those pointers adds an extra 32 or 64 bits of overhead to the object. Worse, sprinkling our data across the heap in a loosely connected web of objects does bad things for *spatial locality*.

每個指針都會給對象增加32或64比特的開銷。更糟糕的是，將我們的數據散佈在一個鬆散連接的對象網絡中的堆上，會對空間局部性造成影響。

> Modern CPUs process data way faster than they can pull it from RAM. To compensate for that, chips have multiple layers of caching. If a piece of memory it needs is already in the cache, it can be loaded more quickly. We’re talking upwards of 100 *times* faster.
>

現代CPU處理數據的速度遠遠超過它們從RAM中提取數據的速度。為了彌補這一點，芯片中有多層緩存。如果它需要的一塊存儲數據已經在緩存中，它就可以更快地被加載。我們談論的是100倍以上的提速。

> How does data get into that cache? The machine speculatively stuffs things in there for you. Its heuristic is pretty simple. Whenever the CPU reads a bit of data from RAM, it pulls in a whole little bundle of adjacent bytes and stuffs them in the cache.
>

數據是如何進入緩存的？機器會推測性地為你把數據塞進去。它的啓發式方法很簡單。每當CPU從RAM中讀取數據時，它就會拉取一塊相鄰的字節並放到緩存中。

> If our program next requests some data close enough to be inside that cache line, our CPU runs like a well-oiled conveyor belt in a factory. We *really* want to take advantage of this. To use the cache effectively, the way we represent code in memory should be dense and ordered like it’s read.
>

如果我們的程序接下來請求一些在緩存行中的數據，那麼我們的CPU就能像工廠裏一條運轉良好的傳送帶一樣運行。我們真的很想利用這一點。為了有效的利用緩存，我們在內存中表示代碼的方式應該像讀取時一樣緊密而有序。

> Now look u**p at that tree. Those sub-objects could be *anywhere*. Every step the tree-walker takes where it follows a reference to a child node may step outside the bounds of the cache and force the CPU to stall until a new lump of data can be slurped in from RAM. Just the *overhead* of those tree nodes with all of their pointer fields and object headers tends to push o**bjects away from each other and out of the cache.
>

現在抬頭看看那棵樹。這些子對象可能在任何地方。樹遍歷器的每一步都會引用子節點，都可能會超出緩存的範圍，並迫使CPU暫停，直到從RAM中拉取到新的數據塊（才會繼續執行）。僅僅是這些樹形節點及其所有指針字段和對象頭的開銷，就會把對象彼此推離，並將其推出緩存區。

> Our AST walker has other overhead too around interface dispatch and the Visitor pattern, but the locality issues alone are enough to justify a better code representation.
>

我們的AST遍歷器在接口調度和Visitor模式方面還有其它開銷，但僅僅是局部性問題就足以證明使用更好的代碼表示是合理的。

> ### 14 . 1 . 2 Why not compile to native code?

### 14.1.2 為什麼不編譯成本地代碼？

> If you want to go *real* fast, you want to get all of those layers of indirection out of the way. Right down to the metal. Machine code. It even *sounds* fast. *Machine code.*

如果你想真正快，就要擺脱所有的中間層，一直到最底層——機器碼。聽起來就很快，*機器碼*。

> Compiling directly to the native instruction set the chip supports is what the fastest languages do. Targeting native code has been the most efficient option since way back in the early days when engineers actually handwrote programs in machine code.

最快的語言所做的是直接把代碼編譯為芯片支持的本地指令集。從早期工程師真正用機器碼手寫程序以來，以本地代碼為目標一直是最有效的選擇。

> If you’ve never written any machine code, or its slightly more human-palatable cousin assembly code before, I’ll give you the gentlest of introductions. Native code is a dense series of operations, encoded directly in binary. Each instruction is between one and a few bytes long, and is almost mind-numbingly low level. “Move a value from this address to this register.” “Add the integers in these two registers.” Stuff like that.

如果你以前從來沒有寫過任何機器碼，或者是它略微討人喜歡的近親彙編語言，那我給你做一個簡單的介紹。本地代碼是一系列密集的操作，直接用二進制編碼。每條指令的長度都在一到幾個字節之間，而且幾乎是令人頭疼的底層指令。“將一個值從這個地址移動到這個寄存器”“將這兩個寄存器中的整數相加”，諸如此類。

> The CPU cranks through the instructions, decoding and executing each one in order. There is no tree structure like our AST, and control flow is handled by jumping from one point in the code directly to another. No indirection, no overhead, no unnecessary skipping around or chasing pointers.

通過解碼和按順序執行指令來操作CPU。沒有像AST那樣的樹狀結構，控制流是通過從代碼中的一個點跳到另一個點來實現的。沒有中間層，沒有開銷，沒有不必要的跳轉或指針尋址。

> Lightning fast, but that performance comes at a cost. First of all, compiling to native code ain’t easy. Most chips in wide use today have sprawling Byzantine architectures with heaps of instructions that accreted over decades. They require sophisticated register allocation, pipelining, and instruction scheduling.
>

閃電般的速度，但這種性能是有代價的。首先，編譯成本地代碼並不容易。如今廣泛使用的大多數芯片都有着龐大的拜占庭式架構，其中包含了幾十年來積累的大量指令。它們需要複雜的寄存器分配、流水線和指令調度。

> And, of course, you’ve thrown portability out. Spend a few years mastering some architecture and that still only gets you onto *one* of the several popular instruction sets out there. To get your language on all of them, you need to learn all of their instruction sets and write a separate back end for each one.
>

當然，你可以把可移植性拋在一邊。花費幾年時間掌握一些架構，但這仍然只能讓你接觸到一些流行的指令集。為了讓你的語言能在所有的架構上運行，你需要學習所有的指令集，併為每個指令集編寫一個單獨的後端[^4]。

> ### 14 . 1 . 3 What is bytecode?

### 14.1.3 什麼是字節碼？

> Fix those two points in your mind. On one end, a tree-walk interpreter is simple, portable, and slow. On the other, native code is complex and platform-specific but fast. Bytecode sits in the middle. It retains the portability of a tree-walker—we won’t be getting our hands dirty with assembly code in this book. It sacrifices *some* simplicity to get a performance boost in return, though not as fast as going fully native.

記住這兩點。一方面，樹遍歷解釋器簡單、可移植，而且慢。另一方面，本地代碼複雜且特定與平台，但是很快。字節碼位於中間。它保留了樹遍歷型的可移植性——在本書中我們不會編寫彙編代碼，同時它犧牲了一些簡單性來換取性能的提升，雖然沒有完全的本地代碼那麼快。

> Structurally, bytecode resembles machine code. It’s a dense, linear sequence of binary instructions. That keeps overhead low and plays nice with the cache. However, it’s a much simpler, higher-level instruction set than any real chip out there. (In many bytecode formats, each instruction is only a single byte long, hence “bytecode”.)

結構上講，字節碼類似於機器碼。它是一個密集的、線性的二進制指令序列。這樣可以保持較低的開銷，並可以與高速緩存配合得很好。然而，它是一個更簡單、更高級的指令集，比任何真正的芯片都要簡單。（在很多字節碼格式中，每條指令只有一個字節長，因此稱為“字節碼”）

> Imagine you’re writing a native compiler from some source language and you’re given carte blanche to define the easiest possible architecture to target. Bytecode is kind of like that. It’s an idealized fantasy instruction set that makes your life as the compiler writer easier.

想象一下，你在用某種源語言編寫一個本地編譯器，並且你可以全權定義一個儘可能簡單的目標架構。字節碼就有點像這樣，它是一個理想化的幻想指令集，可以讓你作為編譯器作者的生活更輕鬆。

> The problem with a fantasy architecture, of course, is that it doesn’t exist. We solve that by writing an *emulator*—a simulated chip written in software that interprets the bytecode one instruction at a time. A *virtual machine (VM)*, if you will.

當然，幻想架構的問題在於它並不存在。我們提供編寫模擬器來解決這個問題，這個模擬器是一個用軟件編寫的芯片，每次會解釋字節碼的一條指令。如果你願意的話，可以叫它*虛擬機（VM）*。

> That emulation layer adds overhead, which is a key reason bytecode is slower than native code. But in return, it gives us portability. Write our VM in a language like C that is already supported on all the machines we care about, and we can run our emulator on top of any hardware we like.

模擬層增加了開銷，這是字節碼比本地代碼慢的一個關鍵原因。但作為回報，它為我們提供了可移植性[^5]。用像C這樣的語言來編寫我們的虛擬機，它已經被我們所關心的所有機器所支持，這樣我們就可以在任何我們喜歡的硬件上運行我們的模擬器。

> This is the path we’ll take with our new interpreter, clox. We’ll follow in the footsteps of the main implementations of Python, Ruby, Lua, OCaml, Erlang, and others. In many ways, our VM’s design will parallel the structure of our previous interpreter:

這就是我們的新解釋器clox要走的路。我們將追隨Python、Ruby、Lua、OCaml、Erlang和其它主要語言實現的腳步。在許多方面，我們的VM設計將與之前的解釋器結構並行。

![Phases of the two implementations. jlox is Parser to Syntax Trees to Interpreter. clox is Compiler to Bytecode to Virtual Machine.](14.字節碼塊/phases.png)

> Of course, we won’t implement the phases strictly in order. Like our previous interpreter, we’ll bounce around, building up the implementation one language feature at a time. In this chapter, we’ll get the skeleton of the application in place and create the data structures needed to store and represent a chunk of bytecode.

當然，我們不會嚴格按照順序實現這些階段。像我們之前的解釋器一樣，我們會反覆地構建實現，每次只構建一種語言特性。在這一章中，我們將瞭解應用程序的框架，並創建用於存儲和表示字節碼塊的數據結構。

> ## 14 . 2 Getting Started

## 14.2 開始

> Where else to begin, but at `main()`? Fire up your trusty text editor and start typing.

除了`main()`還能從哪裏開始呢？啓動你的文本編輯器，開始輸入。

*<u>main.c，創建新文件：</u>*

```c
#include "common.h"

int main(int argc, const char* argv[]) {
  return 0;
}
```

> From this tiny seed, we will grow our entire VM. Since C provides us with so little, we first need to spend some time amending the soil. Some of that goes into this header:

從這顆小小的種子開始，我們將成長為整個VM。由於C提供給我們的東西太少，我們首先需要花費一些時間來培育土壤。其中一部分就在下面的header中。

*<u>common.h，創建新文件：</u>*

```c
#ifndef clox_common_h
#define clox_common_h

#include <stdbool.h>
#include <stddef.h>
#include <stdint.h>

#endif
```

> There are a handful of types and constants we’ll use throughout the interpreter, and this is a convenient place to put them. For now, it’s the venerable `NULL`, `size_t`, the nice C99 Boolean `bool`, and explicit-sized integer types—`uint8_t` and friends.

在整個解釋器中，我們會使用一些類型和常量，這是一個方便放置它們的地方。現在，它是古老的`NULL`、`size_t`，C99中的布爾類型`bool`，以及顯式聲明大小的整數類型——`uint8_t`和它的朋友們。

> ## 14 . 3 Chunks of Instructions

## 14.3 指令塊

> Next, we need a module to define our code representation. I’ve been using “chunk” to refer to sequences of bytecode, so let’s make that the official name for that module.

接下來，我們需要一個模塊來定義我們的代碼表示形式。我一直使用“chunk”指代字節碼序列，所以我們把它作為該模塊的正式名稱。

*<u>chunk.h，創建新文件：</u>*

```c
#ifndef clox_chunk_h
#define clox_chunk_h

#include "common.h"

#endif
```

> In our bytecode format, each instruction has a one-byte **operation code** (universally shortened to **opcode**). That number controls what kind of instruction we’re dealing with—add, subtract, look up variable, etc. We define those here:

在我們的字節碼格式中，每個指令都有一個字節的**操作碼**（通常簡稱為**opcode**）。這個數字控制我們要處理的指令類型——加、減、查找變量等。我們在這塊定義這些：

*<u>chunk.h，添加代碼：</u>*

```c
#include "common.h"
// 新增部分開始
typedef enum {
  OP_RETURN,
} OpCode;
// 新增部分結束
#endif
```

> For now, we start with a single instruction, `OP_RETURN`. When we have a full-featured VM, this instruction will mean “return from the current function”. I admit this isn’t exactly useful yet, but we have to start somewhere, and this is a particularly simple instruction, for reasons we’ll get to later.
>

現在，我們從一條指令`OP_RETURN`開始。當我們有一個全功能的VM時，這個指令意味着“從當前函數返回”。我承認這還不是完全有用，但是我們必須從某個地方開始下手，而這是一個特別簡單的指令，原因我們會在後面講到。

> ### 14 . 3 . 1 A dynamic array of instructions

### 14.3.1 指令動態數組

> Bytecode is a series of instructions. Eventually, we’ll store some other data along with the instructions, so let’s go ahead and create a struct to hold it all.

字節碼是一系列指令。最終，我們會與指令一起存儲一些其它數據，所以讓我們繼續創建一個結構體來保存所有這些數據。

*<u>chunk.h，在枚舉 OpCode後添加：</u>*

```c
} OpCode;
// 新增部分開始
typedef struct {
  uint8_t* code;
} Chunk;
// 新增部分結束
#endif
```

> At the moment, this is simply a wrapper around an array of bytes. Since we don’t know how big the array needs to be before we start compiling a chunk, it must be dynamic. Dynamic arrays are one of my favorite data structures. That sounds like claiming vanilla is my favorite ice cream flavor, but hear me out. Dynamic arrays provide:

目前，這只是一個字節數組的簡單包裝。由於我們在開始編譯塊之前不知道數組需要多大，所以它必須是動態的。動態數組是我最喜歡的數據結構之一。這聽起來就像是在説香草是我最喜愛的冰淇淋口味，但請聽我説完。動態數組提供了：

- > Cache-friendly, dense storage

  緩存友好，密集存儲

- > Constant-time indexed element lookup

  索引元素查找為常量時間複雜度

- > Constant-time appending to the end of the array

  數組末尾追加元素為常量時間複雜度

> Those features are exactly why we used dynamic arrays all the time in jlox under the guise of Java’s ArrayList class. Now that we’re in C, we get to roll our own. If you’re rusty on dynamic arrays, the idea is pretty simple. In addition to the array itself, we keep two numbers: the number of elements in the array we have allocated (“capacity”) and how many of those allocated entries are actually in use (“count”).

這些特性正是我們在jlox中以ArrayList類的名義一直使用動態數組的原因。現在我們在C語言中，可以推出我們自己的動態數組。如果你對動態數組不熟悉，其實這個想法非常簡單。除了數組本身，我們還保留了兩個數字：數組中已分配的元素數量（容量，capacity）和實際使用的已分配元數數量（計數，count）。

*<u>chunk.h，在結構體 Chunk中添加代碼：</u>*

```c
typedef struct {
  // 新增部分開始
  int count;
  int capacity;
  // 新增部分結束
  uint8_t* code;
} Chunk;
```

> When we add an element, if the count is less than the capacity, then there is already available space in the array. We store the new element right in there and bump the count.

當添加元素時，如果計數小於容量，那麼數組中已有可用空間。我們將新元素直接存入其中，並修改計數值。

![Storing an element in an array that has enough capacity.](14.字節碼塊/insert.png)

> If we have no spare capacity, then the process is a little more involved.

如果沒有多餘的容量，那麼這個過程會稍微複雜一些。

![Growing the dynamic array before storing an element.](14.字節碼塊/grow.png)

1. > Allocate a new array with more capacity.

   分配一個容量更大的新數組[^6]。

2. > Copy the existing elements from the old array to the new one.

   將舊數組中的已有元素複製到新數組中。

3. > Store the new `capacity`.

   保存新的`capacity`。

4. > Delete the old array.

   刪除舊數組。

5. > Update `code` to point to the new array.

   更新`code`指向新的數組。

6. > Store the element in the new array now that there is room.

   現在有了空間，將元素存儲在新數組中。

7. > Update the `count`.

   更新`count`。

> We have our struct ready, so let’s implement the functions to work with it. C doesn’t have constructors, so we declare a function to initialize a new chunk.

我們的結構體已經就緒，現在我們來實現和它相關的函數。C語言沒有構造函數，所以我們聲明一個函數來初始化一個新的塊。

*<u>chunk.h，在結構體 Chunk後添加：</u>*

```c
} Chunk;
// 新增部分開始
void initChunk(Chunk* chunk);
// 新增部分結束
#endif
```

> And implement it thusly:

並這樣實現它：

*<u>chunk.c，創建新文件：</u>*

```c
#include <stdlib.h>

#include "chunk.h"

void initChunk(Chunk* chunk) {
  chunk->count = 0;
  chunk->capacity = 0;
  chunk->code = NULL;
}
```

> The dynamic array starts off completely empty. We don’t even allocate a raw array yet. To append a byte to the end of the chunk, we use a new function.

動態數組一開始是完全空的。我們甚至還沒有分配原始數組。要將一個字節追加到塊的末尾，我們使用一個新函數。

*<u>chunk.h，在 initChunk()方法後添加：</u>*

```c
void initChunk(Chunk* chunk);
// 新增部分開始
void writeChunk(Chunk* chunk, uint8_t byte);
// 新增部分結束
#endif
```

> This is where the interesting work happens.

這就是有趣的地方。

*<u>chunk.c，在 initChunk()方法後添加：</u>*

```c
void writeChunk(Chunk* chunk, uint8_t byte) {
  if (chunk->capacity < chunk->count + 1) {
    int oldCapacity = chunk->capacity;
    chunk->capacity = GROW_CAPACITY(oldCapacity);
    chunk->code = GROW_ARRAY(uint8_t, chunk->code,
        oldCapacity, chunk->capacity);
  }

  chunk->code[chunk->count] = byte;
  chunk->count++;
}
```

> The first thing we need to do is see if the current array already has capacity for the new byte. If it doesn’t, then we first need to grow the array to make room. (We also hit this case on the very first write when the array is `NULL` and `capacity` is 0.)

我們需要做的第一件事是查看當前數組是否已經有容納新字節的容量。如果沒有，那麼我們首先需要擴充數組以騰出空間（當我們第一個寫入時，數組為`NULL`並且`capacity`為0，也會遇到這種情況）

> To grow the array, first we figure out the new capacity and grow the array to that size. Both of those lower-level memory operations are defined in a new module.

要擴充數組，首先我們要算出新容量，然後將數組容量擴充到該大小。這兩種低級別的內存操作都在一個新模塊中定義。

*<u>chunk.c，添加代碼：</u>*

```c
#include "chunk.h"
// 新增部分開始
#include "memory.h"
// 新增部分結束
void initChunk(Chunk* chunk) {
```

> This is enough to get us started.

這就足夠我們開始後面的事情了。

*<u>memory.h，創建新文件：</u>*

```c
#ifndef clox_memory_h
#define clox_memory_h

#include "common.h"

#define GROW_CAPACITY(capacity) \
    ((capacity) < 8 ? 8 : (capacity) * 2)

#endif
```

> This macro calculates a new capacity based on a given current capacity. In order to get the performance we want, the important part is that it *scales* based on the old size. We grow by a factor of two, which is pretty typical. 1.5× is another common choice.

這個宏會根據給定的當前容量計算出新的容量。為了獲得我們想要的性能，重要的部分就是基於舊容量大小進行擴展。我們以2的係數增長，這是一個典型的取值。1.5是另外一個常見的選擇。

> We also handle when the current capacity is zero. In that case, we jump straight to eight elements instead of starting at one. That avoids a little extra memory churn when the array is very small, at the expense of wasting a few bytes on very small chunks.

我們還會處理當前容量為0的情況。在這種情況下，我們的容量直接跳到8，而不是從1開始[^7]。這就避免了在數組非常小的時候出現額外的內存波動，代價是在非常小的塊中浪費幾個字節。

> Once we know the desired capacity, we create or grow the array to that size using `GROW_ARRAY()`.

一旦我們知道了所需的容量，就可以使用`GROW_ARRAY()`創建或擴充數組到該大小。

*<u>memory.h，添加代碼：</u>*

```c
#define GROW_CAPACITY(capacity) ((capacity) < 8 ? 8 : (capacity) * 2)
// 新增部分開始    
#define GROW_ARRAY(type, pointer, oldCount, newCount) \
    (type*)reallocate(pointer, sizeof(type) * (oldCount), \
        sizeof(type) * (newCount))

void* reallocate(void* pointer, size_t oldSize, size_t newSize);
// 新增部分結束
#endif
```

> This macro pretties up a function call to `reallocate()` where the real work happens. The macro itself takes care of getting the size of the array’s element type and casting the resulting `void*` back to a pointer of the right type.

這個宏簡化了對`reallocate()`函數的調用，真正的工作就是在其中完成的。宏本身負責獲取數組元素類型的大小，並將生成的`void*`轉換成正確類型的指針。

> This `reallocate()` function is the single function we’ll use for all dynamic memory management in clox—allocating memory, freeing it, and changing the size of an existing allocation. Routing all of those operations through a single function will be important later when we add a garbage collector that needs to keep track of how much memory is in use.

這個`reallocate()`函數是我們將在clox中用於所有動態內存管理的唯一函數——分配內存，釋放內存以及改變現有分配的大小。當我們稍後添加一個需要跟蹤內存使用情況的垃圾收集器時，通過單個函數路由所有這些操作是很重要的。

> The two size arguments passed to `reallocate()` control which operation to perform:

傳遞給`reallocate()` 函數的兩個大小參數控制了要執行的操作：

| oldSize  | newSize                | Operation                                   |
| -------- | ---------------------- | ------------------------------------------- |
| 0        | Non‑zero               | Allocate new block.  分配新塊               |
| Non‑zero | 0                      | Free allocation. 釋放已分配內存             |
| Non‑zero | Smaller than `oldSize` | Shrink existing allocation.  收縮已分配內存 |
| Non‑zero | Larger than `oldSize`  | Grow existing allocation. 增加已分配內存    |

> That sounds like a lot of cases to handle, but here’s the implementation:

看起來好像有很多情況需要處理，但下面是其實現：

*<u>memory.c，創建新文件：</u>*

```c
#include <stdlib.h>

#include "memory.h"

void* reallocate(void* pointer, size_t oldSize, size_t newSize) {
  if (newSize == 0) {
    free(pointer);
    return NULL;
  }

  void* result = realloc(pointer, newSize);
  return result;
}
```

> When `newSize` is zero, we handle the deallocation case ourselves by calling `free()`. Otherwise, we rely on the C standard library’s `realloc()` function. That function conveniently supports the other three aspects of our policy. When `oldSize` is zero, `realloc()` is equivalent to calling `malloc()`.
>

當`newSize`為0時，我們通過調用`free()`來自己處理回收的情況。其它情況下，我們依賴於C標準庫的`realloc()`函數。該函數可以方便地支持我們策略中的其它三個場景。當`oldSize`為0時，`realloc()` 等同於調用`malloc()`。

> The interesting cases are when both `oldSize` and `newSize` are not zero. Those tell `realloc()` to resize the previously allocated block. If the new size is smaller than the existing block of memory, it simply updates the size of the block and returns the same pointer you gave it. If the new size is larger, it attempts to grow the existing block of memory.
>

有趣的情況是當`oldSize`和`newSize`都不為0時。它們會告訴`realloc()`要調整之前分配的塊的大小。如果新的大小小於現有的內存塊，它就只是更新塊的大小，並返回傳入的指針。如果新塊大小更大，它就會嘗試增長現有的內存塊[^8]。

> It can do that only if the memory after that block isn’t already in use. If there isn’t room to grow the block, `realloc()` instead allocates a *new* block of memory of the desired size, copies over the old bytes, frees the old block, and then returns a pointer to the new block. Remember, that’s exactly the behavior we want for our dynamic array.
>

只有在該塊之後的內存未被使用的情況下，才能這樣做。如果沒有空間支持塊的增長，`realloc()`會分配一個所需大小的*新*的內存塊，複製舊的字節，釋放舊內存塊，然後返回一個指向新內存塊的指針。記住，這正是我們的動態數組想要的行為。

> Because computers are finite lumps of matter and not the perfect mathematical abstractions computer science theory would have us believe, allocation can fail if there isn’t enough memory and `realloc()` will return `NULL`. We should handle that.
>

因為計算機是有限的物質塊，而不是計算機科學理論所認為的完美的數學抽象，如果沒有足夠的內存，分配就會失敗，`reealloc()`會返回`NULL`。我們應該解決這個問題。

*<u>memory.c，在 reallocate()方法中添加：</u>*

```c
  void* result = realloc(pointer, newSize);
  // 新增部分開始
  if (result == NULL) exit(1);
  // 新增部分結束
  return result;
```

> There’s not really anything *useful* that our VM can do if it can’t get the memory it needs, but we at least detect that and abort the process immediately instead of returning a `NULL` pointer and letting it go off the rails later.

如果我們的VM不能得到它所需要的內存，那就做不了什麼有用的事情，但我們至少可以檢測這一點，並立即中止進程，而不是返回一個`NULL`指針，然後讓程序運行偏離軌道。

> OK, we can create new chunks and write instructions to them. Are we done? Nope! We’re in C now, remember, we have to manage memory ourselves, like in Ye Olden Times, and that means *freeing* it too.

好了，我們可以創建新的塊並向其中寫入指令。我們完成了嗎？不！要記住，我們現在是在C語言中，我們必須自己管理內存，就像在《Ye Olden Times》中那樣，這意味着我們也要*釋放*內存。

*<u>chunk.h，在 initChunk()方法後添加：</u>*

```c
void initChunk(Chunk* chunk);
// 新增部分開始
void freeChunk(Chunk* chunk);
// 新增部分結束
void writeChunk(Chunk* chunk, uint8_t byte);
```

實現為:

*<u>chunk.c，在 initChunk()方法後添加：</u>*

```c
void freeChunk(Chunk* chunk) {
  FREE_ARRAY(uint8_t, chunk->code, chunk->capacity);
  initChunk(chunk);
}
```

> We deallocate all of the memory and then call `initChunk()` to zero out the fields leaving the chunk in a well-defined empty state. To free the memory, we add one more macro.

我們釋放所有的內存，然後調用`initChunk()`將字段清零，使字節碼塊處於一個定義明確的空狀態。為了釋放內存，我們再添加一個宏。

*<u>memory.h，添加代碼：</u>*

```c
#define GROW_ARRAY(type, pointer, oldCount, newCount) \
    (type*)reallocate(pointer, sizeof(type) * (oldCount), \
        sizeof(type) * (newCount))
// 新增部分開始        
#define FREE_ARRAY(type, pointer, oldCount) \
    reallocate(pointer, sizeof(type) * (oldCount), 0)
// 新增部分結束    
void* reallocate(void* pointer, size_t oldSize, size_t newSize);
```

> Like `GROW_ARRAY()`, this is a wrapper around a call to `reallocate()`. This one frees the memory by passing in zero for the new size. I know, this is a lot of boring low-level stuff. Don’t worry, we’ll get a lot of use out of these in later chapters and will get to program at a higher level. Before we can do that, though, we gotta lay our own foundation.
>

與`GROW_ARRAY()`類似，這是對`reallocate()`調用的包裝。這個函數通過傳入0作為新的內存塊大小，來釋放內存。我知道，這是一堆無聊的低級別代碼。別擔心，在後面的章節中，我們會大量使用這些內容。但在此之前，我們必須先打好自己的基礎。

> ## 14 . 4 Disassembling Chunks

## 14.4 反彙編字節碼塊

> Now we have a little module for creating chunks of bytecode. Let’s try it out by hand-building a sample chunk.

現在我們有一個創建字節碼塊的小模塊。讓我們手動構建一個樣例字節碼塊來測試一下。

*<u>main.c，在 main()方法中添加：</u>*

```c
int main(int argc, const char* argv[]) {
  // 新增部分開始
  Chunk chunk;
  initChunk(&chunk);
  writeChunk(&chunk, OP_RETURN);
  freeChunk(&chunk);
  // 新增部分結束
  return 0;
```

> Don’t forget the include.

不要忘了include。

*<u>main.c，添加代碼：</u>*

```c
#include "common.h"
// 新增部分開始
#include "chunk.h"
// 新增部分結束
int main(int argc, const char* argv[]) {
```

> Run that and give it a try. Did it work? Uh . . . who knows? All we’ve done is push some bytes around in memory. We have no human-friendly way to see what’s actually inside that chunk we made.

試着運行一下，它起作用了嗎？額……誰知道呢。我們所做的只是在內存中存入一些字節。我們沒有友好的方法來查看我們製作的字節碼塊中到底有什麼。

> To fix this, we’re going to create a **disassembler**. An **assembler** is an old-school program that takes a file containing human-readable mnemonic names for CPU instructions like “ADD” and “MULT” and translates them to their binary machine code equivalent. A *dis*assembler goes in the other direction—given a blob of machine code, it spits out a textual listing of the instructions.

為了解決這個問題，我們要創建一個**反彙編程序**。**彙編程序**是一個老式程序，它接收一個文件，該文件中包含CPU指令（如 "ADD "和 "MULT"）的可讀助記符名稱，並將它們翻譯成等價的二進制機器代碼。反彙編程序則相反——給定一串機器碼，它會返回指令的文本列表。

> We’ll implement something similar. Given a chunk, it will print out all of the instructions in it. A Lox *user* won’t use this, but we Lox *maintainers* will certainly benefit since it gives us a window into the interpreter’s internal representation of code.

我們將實現一個類似的模塊。給定一個字節碼塊，它將打印出其中所有的指令。Lox用户不會使用它，但我們這些Lox的維護者肯定會從中受益，因為它給我們提供了一個瞭解解釋器內部代碼表示的窗口。

> In `main()`, after we create the chunk, we pass it to the disassembler.

在`main()`中，我們創建字節碼塊後，將其傳入反彙編器。

*<u>main.c，在 main()方法中添加：</u>*

```c
  initChunk(&chunk);
  writeChunk(&chunk, OP_RETURN);
  // 新增部分開始
  disassembleChunk(&chunk, "test chunk");
  // 新增部分結束
  freeChunk(&chunk);
```

> Again, we whip up yet another module.

我們又創建了另一個模塊。

*<u>main.c，添加代碼：</u>*

```c
#include "chunk.h"
// 新增部分開始
#include "debug.h"
// 新增部分結束
int main(int argc, const char* argv[]) {
```

> Here’s that header:

下面是這個頭文件：

*<u>debug.h，創建新文件：</u>*

```c
#ifndef clox_debug_h
#define clox_debug_h

#include "chunk.h"

void disassembleChunk(Chunk* chunk, const char* name);
int disassembleInstruction(Chunk* chunk, int offset);

#endif
```

> In `main()`, we call `disassembleChunk()` to disassemble all of the instructions in the entire chunk. That’s implemented in terms of the other function, which just disassembles a single instruction. It shows up here in the header because we’ll call it from the VM in later chapters.

在`main()`方法中，我們調用`disassembleChunk()`來反彙編整個字節碼塊中的所有指令。這是用另一個函數實現的，該函數只反彙編一條指令。因為我們將在後面的章節中從VM中調用它，所以將它添加到頭文件中。

> Here’s a start at the implementation file:

下面是簡單的實現文件：

*<u>debug.c，創建新文件：</u>*

```c
#include <stdio.h>

#include "debug.h"

void disassembleChunk(Chunk* chunk, const char* name) {
  printf("== %s ==\n", name);

  for (int offset = 0; offset < chunk->count;) {
    offset = disassembleInstruction(chunk, offset);
  }
}
```

> To disassemble a chunk, we print a little header (so we can tell *which* chunk we’re looking at) and then crank through the bytecode, disassembling each instruction. The way we iterate through the code is a little odd. Instead of incrementing `offset` in the loop, we let `disassembleInstruction()` do it for us. When we call that function, after disassembling the instruction at the given offset, it returns the offset of the *next* instruction. This is because, as we’ll see later, instructions can have different sizes.
>

要反彙編一個字節碼塊，我們首先打印一個小標題（這樣我們就知道正在看哪個字節碼塊），然後通過字節碼反彙編每個指令。我們遍歷代碼的方式有點奇怪。我們沒有在循環中增加`offset`，而是讓`disassembleInstruction()` 為我們做這個。當我們調用該函數時，在對給定偏移量的位置反彙編指令後，會返回*下一條*指令的偏移量。這是因為，我們後面也會看到，指令可以有不同的大小。

> The core of the “debug” module is this function:

“debug”模塊的核心是這個函數：

*<u>debug.c，在disassembleChunk()方法後添加：</u>*

```c
int disassembleInstruction(Chunk* chunk, int offset) {
  printf("%04d ", offset);

  uint8_t instruction = chunk->code[offset];
  switch (instruction) {
    case OP_RETURN:
      return simpleInstruction("OP_RETURN", offset);
    default:
      printf("Unknown opcode %d\n", instruction);
      return offset + 1;
  }
}
```

> First, it prints the byte offset of the given instruction—that tells us where in the chunk this instruction is. This will be a helpful signpost when we start doing control flow and jumping around in the bytecode.

首先，它會打印給定指令的字節偏移量——這能告訴我們當前指令在字節碼塊中的位置。當我們在字節碼中實現控制流和跳轉時，這將是一個有用的路標。

> Next, it reads a single byte from the bytecode at the given offset. That’s our opcode. We switch on that. For each kind of instruction, we dispatch to a little utility function for displaying it. On the off chance that the given byte doesn’t look like an instruction at all—a bug in our compiler—we print that too. For the one instruction we do have, `OP_RETURN`, the display function is:
>

接下來，它從字節碼中的給定偏移量處讀取一個字節。這也就是我們的操作碼。我們根據該值做switch操作。對於每一種指令，我們都分派給一個小的工具函數來展示它。如果給定的字節看起來根本不像一條指令——這是我們編譯器的一個錯誤——我們也要打印出來。對於我們目前僅有的一條指令`OP_RETURN`，對應的展示函數是：

*<u>debug.c，在 disassembleChunk()方法後添加：</u>*

```c
static int simpleInstruction(const char* name, int offset) {
  printf("%s\n", name);
  return offset + 1;
}
```

> There isn’t much to a return instruction, so all it does is print the name of the opcode, then return the next byte offset past this instruction. Other instructions will have more going on.

return指令的內容不多，所以它所做的只是打印操作碼的名稱，然後返回該指令後的下一個字節偏移量。其它指令會有更多的內容。

> If we run our nascent interpreter now, it actually prints something:

如果我們現在運行我們的新解釋器，它實際上會打印出來：

```
== test chunk ==
0000 OP_RETURN
```

> It worked! This is sort of the “Hello, world!” of our code representation. We can create a chunk, write an instruction to it, and then extract that instruction back out. Our encoding and decoding of the binary bytecode is working.
>

成功了！這有點像我們代碼表示中的“Hello, world!”。我們可以創建一個字節碼塊，向其中寫入一條指令，然後將該指令提取出來。我們對二進制字節碼的編碼和解碼工作正常。

> ## 14 . 5 Constants

## 14.5 常量

> Now that we have a rudimentary chunk structure working, let’s start making it more useful. We can store *code* in chunks, but what about *data*? Many values the interpreter works with are created at runtime as the result of operations.

現在我們有了一個基本的塊結構，我們來讓它變得更有用。我們可以在塊中存儲*代碼*，但是*數據*呢？解釋器中使用的很多值都是在運行時作為操作的結果創建的。

```
1 + 2;
```

> The value 3 appears nowhere in the code here. However, the literals `1` and `2` do. To compile that statement to bytecode, we need some sort of instruction that means “produce a constant” and those literal values need to get stored in the chunk somewhere. In jlox, the Expr.Literal AST node held the value. We need a different solution now that we don’t have a syntax tree.

這裏的代碼中沒有出現3這個值。但是，字面量`1`和`2`出現了。為了將該語句編譯成字節碼，我們需要某種指令，其含義是“生成一個常量”，而這些字母值需要存儲在字節碼塊中的某個地方。在jlox中，Expr.Literal 這個AST節點中保存了這些值。因為我們沒有語法樹，現在我們需要一個不同的解決方案。

> ### 14 . 5 . 1 Representing values

### 14.5.1 表示值

> We won’t be *running* any code in this chapter, but since constants have a foot in both the static and dynamic worlds of our interpreter, they force us to start thinking at least a little bit about how our VM should represent values.

在本章中我們不會運行任何代碼，但是由於常量在解釋器的靜態和動態世界中都有涉足，這會迫使我們開始思考我們的虛擬機中應該如何表示數值。

> For now, we’re going to start as simple as possible—we’ll support only double-precision, floating-point numbers. This will obviously expand over time, so we’ll set up a new module to give ourselves room to grow.

現在，我們儘可能從最簡單的開始——只支持雙精度浮點數。這種表示形式顯然會逐漸擴大，所以我們將建立一個新的模塊，給自己留出擴展的空間。

*<u>value.h，創建新文件：</u>*

```c
#ifndef clox_value_h
#define clox_value_h

#include "common.h"

typedef double Value;

#endif
```

> This typedef abstracts how Lox values are concretely represented in C. That way, we can change that representation without needing to go back and fix existing code that passes around values.

這個類型定義抽象了Lox值在C語言中的具體表示方式。這樣，我們就可以直接改變表示方法，而不需要回去修改現有的傳遞值的代碼。

> Back to the question of where to store constants in a chunk. For small fixed-size values like integers, many instruction sets store the value directly in the code stream right after the opcode. These are called **immediate instructions** because the bits for the value are immediately after the opcode.

回到在字節碼塊中存儲常量的問題。對於像整數這種固定大小的值，許多指令集直接將值存儲在操作碼之後的代碼流中。這些指令被稱為**即時指令**，因為值的比特位緊跟在操作碼之後。

> That doesn’t work well for large or variable-sized constants like strings. In a native compiler to machine code, those bigger constants get stored in a separate “constant data” region in the binary executable. Then, the instruction to load a constant has an address or offset pointing to where the value is stored in that section.

對於字符串這種較大的或可變大小的常量來説，這並不適用。在本地編譯器的機器碼中，這些較大的常量會存儲在二進制可執行文件中的一個單獨的“常量數據”區域。然後，加載常量的指令會有一個地址和偏移量，指向該值在區域中存儲的位置。

> Most virtual machines do something similar. For example, the Java Virtual Machine [associates a **constant pool**](https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-4.html#jvms-4.4) with each compiled class. That sounds good enough for clox to me. Each chunk will carry with it a list of the values that appear as literals in the program. To keep things simpler, we’ll put *all* constants in there, even simple integers.
>

大多數虛擬機都會做類似的事。例如，Java虛擬機將常量池與每個編譯後的類關聯起來。我認為，這對於clox來説已經足夠了。每個字節碼塊都會攜帶一個在程序中以字面量形式出現的值的列表。為簡單起見，我們會把所有的常量都放進去，甚至包括簡單的整數[^9]。

> ### 14 . 5 . 2 Value arrays

### 14.5.2 值數組

> The constant pool is an array of values. The instruction to load a constant looks up the value by index in that array. As with our bytecode array, the compiler doesn’t know how big the array needs to be ahead of time. So, again, we need a dynamic one. Since C doesn’t have generic data structures, we’ll write another dynamic array data structure, this time for Value.

常量池是一個值的數組。加載常量的指令根據數組中的索引查找該數組中的值。與字節碼數組一樣，編譯器也無法提前知道這個數組需要多大。因此，我們需要一個動態數組。由於C語言沒有通用數據結構，我們將編寫另一個動態數組數據結構，這次存儲的是Value。

*<u>value.h：</u>*

```c
typedef double Value;
// 新增部分開始
typedef struct {
  int capacity;
  int count;
  Value* values;
} ValueArray;
// 新增部分結束
#endif
```

> As with the bytecode array in Chunk, this struct wraps a pointer to an array along with its allocated capacity and the number of elements in use. We also need the same three functions to work with value arrays.

與Chunk中的字節碼數組一樣，這個結構體包裝了一個指向數組的指針，以及其分配的容量和已使用元素的數量。我們也需要相同的三個函數來處理值數組。

*<u>value.h，在結構體 ValueArray後添加：</u>*

```c
} ValueArray;
// 新增部分開始
void initValueArray(ValueArray* array);
void writeValueArray(ValueArray* array, Value value);
void freeValueArray(ValueArray* array);
// 新增部分結束
#endif
```

> The implementations will probably give you déjà vu. First, to create a new one:

對應的實現可能會讓你有似曾相識的感覺。首先，創建一個新文件：

*<u>value.c，創建一個新文件：</u>*

```c
#include <stdio.h>

#include "memory.h"
#include "value.h"

void initValueArray(ValueArray* array) {
  array->values = NULL;
  array->capacity = 0;
  array->count = 0;
}
```

> Once we have an initialized array, we can start adding values to it.
>

一旦我們有了初始化的數組，我們就可以開始向其中添加值。

*<u>value.c，在 initValueArray()方法後添加：</u>*

```c
void writeValueArray(ValueArray* array, Value value) {
  if (array->capacity < array->count + 1) {
    int oldCapacity = array->capacity;
    array->capacity = GROW_CAPACITY(oldCapacity);
    array->values = GROW_ARRAY(Value, array->values,
                               oldCapacity, array->capacity);
  }

  array->values[array->count] = value;
  array->count++;
}
```

> The memory-management macros we wrote earlier do let us reuse some of the logic from the code array, so this isn’t too bad. Finally, to release all memory used by the array:

我們之前寫的內存管理宏確實讓我們重用了代碼數組中的一些邏輯，所以這並不是太糟糕。最後，釋放數組所使用的所有內存：

*<u>value.c，在 writeValueArray()方法後添加：</u>*

```c
void freeValueArray(ValueArray* array) {
  FREE_ARRAY(Value, array->values, array->capacity);
  initValueArray(array);
}
```

> Now that we have growable arrays of values, we can add one to Chunk to store the chunk’s constants.

現在我們有了可增長的值數組，我們可以向Chunk中添加一個來保存字節碼塊中的常量值。

*<u>chunk.h，在結構體 Chunk中添加：</u>*

```c
  uint8_t* code;
  // 新增部分開始
  ValueArray constants;
  // 新增部分結束
} Chunk;
```

> Don’t forget the include.

不要忘記include。

*<u>chunk.h，添加代碼：</u>*

```c
#include "common.h"
// 新增部分開始
#include "value.h"
// 新增部分結束
typedef enum {
```

> Ah, C, and its Stone Age modularity story. Where were we? Right. When we initialize a new chunk, we initialize its constant list too.

初始化新的字節碼塊時，我們也要初始化其常量值列表。

*<u>chunk.c，在 initChunk()方法中添加：</u>*

```c
  chunk->code = NULL;
  // 新增部分開始
  initValueArray(&chunk->constants);
  // 新增部分結束
}
```

> Likewise, we free the constants when we free the chunk.

同樣地，我們在釋放字節碼塊時，也需要釋放常量值。

*<u>chunk.c，在 freeChunk()方法中添加：</u>*

```c
  FREE_ARRAY(uint8_t, chunk->code, chunk->capacity);
  // 新增部分開始
  freeValueArray(&chunk->constants);
  // 新增部分結束
  initChunk(chunk);
```

> Next, we define a convenience method to add a new constant to the chunk. Our yet-to-be-written compiler could write to the constant array inside Chunk directly—it’s not like C has private fields or anything—but it’s a little nicer to add an explicit function.

接下來，我們定義一個便捷的方法來向字節碼塊中添加一個新常量。我們尚未編寫的編譯器可以在Chunk內部直接把常量值寫入常量數組——它不像C語言那樣有私有字段之類的東西——但是添加一個顯式函數顯然會更好一些。

*<u>chunk.h，在 writeChunk()方法後添加：</u>*

```c
void writeChunk(Chunk* chunk, uint8_t byte);
// 新增部分開始
int addConstant(Chunk* chunk, Value value);
// 新增部分結束
#endif
```

> Then we implement it.

然後我們實現它。

*<u>chunk.c，在 writeChunk()方法後添加：</u>*

```c
int addConstant(Chunk* chunk, Value value) {
  writeValueArray(&chunk->constants, value);
  return chunk->constants.count - 1;
}
```

> After we add the constant, we return the index where the constant was appended so that we can locate that same constant later.
>

在添加常量之後，我們返回追加常量的索引，以便後續可以定位到相同的常量。

> ### 14 . 5 . 3 Constant instructions

### 14.5.3 常量指令

> We can *store* constants in chunks, but we also need to *execute* them. In a piece of code like:

我們可以將常量存儲在字節碼塊中，但是我們也需要執行它們。在如下這段代碼中：

```c
print 1;
print 2;
```

> The compiled chunk needs to not only contain the values 1 and 2, but know *when* to produce them so that they are printed in the right order. Thus, we need an instruction that produces a particular constant.

編譯後的字節碼塊不僅需要包含數值1和2，還需要知道何時生成它們，以便按照正確的順序打印它們。因此，我們需要一種產生特定常數的指令。

*<u>chunk.h，在枚舉 OpCode中添加：</u>*

```c
typedef enum {
  // 新增部分開始
  OP_CONSTANT,
  // 新增部分結束
  OP_RETURN,
```

> When the VM executes a constant instruction, it “loads” the constant for use. This new instruction is a little more complex than `OP_RETURN`. In the above example, we load two different constants. A single bare opcode isn’t enough to know *which* constant to load.

當VM執行常量指令時，它會“加載”常量以供使用[^10]。這個新指令比`OP_RETURN`要更復雜一些。在上面的例子中，我們加載了兩個不同的常量。一個簡單的操作碼不足以知道要加載哪個常量。

> To handle cases like this, our bytecode—like most others—allows instructions to have **operands**. These are stored as binary data immediately after the opcode in the instruction stream and let us parameterize what the instruction does.

為了處理這樣的情況，我們的字節碼像大多數其它字節碼一樣，允許指令有**操作數**[^11]。這些操作數以二進制數據的形式存儲在指令流的操作碼之後，讓我們對指令的操作進行參數化。

![OP_CONSTANT is a byte for the opcode followed by a byte for the constant index.](14.字節碼塊/format.png)

> Each opcode determines how many operand bytes it has and what they mean. For example, a simple operation like “return” may have no operands, where an instruction for “load local variable” needs an operand to identify which variable to load. Each time we add a new opcode to clox, we specify what its operands look like—its **instruction format**.

每個操作碼會定義它有多少操作數以及各自的含義。例如，一個像“return”這樣簡單的操作可能沒有操作數，而一個“加載局部變量”的指令需要一個操作數來確定要加載哪個變量。每次我們向clox添加一個新的操作碼時，我們都會指定它的操作數是什麼樣子的——即它的**指令格式**。

> In this case, `OP_CONSTANT` takes a single byte operand that specifies which constant to load from the chunk’s constant array. Since we don’t have a compiler yet, we “hand-compile” an instruction in our test chunk.

在這種情況下，`OP_CONSTANT`會接受一個單字節的操作數，該操作數指定從塊的常量數組中加載哪個常量。由於我們還沒有編譯器，所以我們在測試字節碼塊中“手動編譯”一個指令。

*<u>main.c，在 main()方法中添加：</u>*

```c
  initChunk(&chunk);
  // 新增部分開始
  int constant = addConstant(&chunk, 1.2);
  writeChunk(&chunk, OP_CONSTANT);
  writeChunk(&chunk, constant);
  // 新增部分結束
  writeChunk(&chunk, OP_RETURN);
```

> We add the constant value itself to the chunk’s constant pool. That returns the index of the constant in the array. Then we write the constant instruction, starting with its opcode. After that, we write the one-byte constant index operand. Note that `writeChunk()` can write opcodes or operands. It’s all raw bytes as far as that function is concerned.

我們將常量值添加到字節碼塊的常量池中。這會返回常量在數組中的索引。然後我們寫常量操作指令，從操作碼開始。之後，我們寫入一字節的常量索引操作數。注意， `writeChunk()` 可以寫操作碼或操作數。對於該函數而言，它們都是原始字節。

> If we try to run this now, the disassembler is going to yell at us because it doesn’t know how to decode the new instruction. Let’s fix that.

如果我們現在嘗試運行上面的代碼，反彙編器會遇到問題，因為它不知道如何解碼新指令。讓我們來修復這個問題。

*<u>debug.c，在 disassembleInstruction()方法中添加：</u>*

```c
  switch (instruction) {
    // 新增部分開始
    case OP_CONSTANT:
      return constantInstruction("OP_CONSTANT", chunk, offset);
    // 新增部分結束  
    case OP_RETURN:
```

> This instruction has a different instruction format, so we write a new helper function to disassemble it.

這條指令的格式有所不同，所以我們編寫一個新的輔助函數來對其反彙編。

*<u>debug.c，在 disassembleChunk()方法後添加：</u>*

```c
static int constantInstruction(const char* name, Chunk* chunk,
                               int offset) {
  uint8_t constant = chunk->code[offset + 1];
  printf("%-16s %4d '", name, constant);
  printValue(chunk->constants.values[constant]);
  printf("'\n");
}
```

> There’s more going on here. As with `OP_RETURN`, we print out the name of the opcode. Then we pull out the constant index from the subsequent byte in the chunk. We print that index, but that isn’t super useful to us human readers. So we also look up the actual constant value—since constants *are* known at compile time after all—and display the value itself too.

這裏要做的事情更多一些。與`OP_RETURN`一樣，我們會打印出操作碼的名稱。然後，我們從該字節碼塊的後續字節中獲取常量索引。我們打印出這個索引值，但是這對於我們人類讀者來説並不十分有用。所以，我們也要查找實際的常量值——因為常量畢竟是在編譯時就知道的——並將這個值也展示出來。

> This requires some way to print a clox Value. That function will live in the “value” module, so we include that.

這就需要一些方法來打印clox中的一個Value。這個函數放在“value”模塊中，所以我們要將其include。

*<u>debug.c，新增代碼：</u>*

```c
#include "debug.h"
// 新增部分開始
#include "value.h"
// 新增部分結束
void disassembleChunk(Chunk* chunk, const char* name) {
```

> Over in that header, we declare:

在這個頭文件中，我們聲明：

*<u>value.h，在 freeValueArray()方法後添加：</u>*

```c
void freeValueArray(ValueArray* array);
// 新增部分開始
void printValue(Value value);
// 新增部分結束
#endif
```

> And here’s an implementation:

下面是對應的實現：

*<u>value.c，在 freeValueArray()方法後添加：</u>*

```c
void printValue(Value value) {
  printf("%g", value);
}
```

> Magnificent, right? As you can imagine, this is going to get more complex once we add dynamic typing to Lox and have values of different types.

很壯觀，是吧？你可以想象，一旦我們在Lox中加入動態類型，並且包含了不同類型的值，這部分將會變得更加複雜。

> Back in `constantInstruction()`, the only remaining piece is the return value.

回到`constantInstruction()`中，唯一剩下的部分就是返回值。

*<u>debug.c，在 constantInstruction()方法中添加：</u>*

```c
  printf("'\n");
  // 新增部分開始
  return offset + 2;
  // 新增部分結束
}
```

> Remember that `disassembleInstruction()` also returns a number to tell the caller the offset of the beginning of the *next* instruction. Where `OP_RETURN` was only a single byte, `OP_CONSTANT` is two—one for the opcode and one for the operand.

記住，`disassembleInstruction()`也會返回一個數字，告訴調用方*下一條*指令的起始位置的偏移量。`OP_RETURN`只有一個字節，而`OP_CONSTANT`有兩個字節——一個是操作碼，一個是操作數。

> ## 14 . 6 Line Information

## 14.6 行信息

> Chunks contain almost all of the information that the runtime needs from the user’s source code. It’s kind of crazy to think that we can reduce all of the different AST classes that we created in jlox down to an array of bytes and an array of constants. There’s only one piece of data we’re missing. We need it, even though the user hopes to never see it.

字節碼塊中幾乎包含了運行時需要從用户源代碼中獲取的所有信息。想到我們可以把jlox中不同的AST類減少到一個字節數組和一個常量數組，這實在有一點瘋狂。我們只缺少一個數據。我們需要它，儘管用户希望永遠不會看到它。

> When a runtime error occurs, we show the user the line number of the offending source code. In jlox, those numbers live in tokens, which we in turn store in the AST nodes. We need a different solution for clox now that we’ve ditched syntax trees in favor of bytecode. Given any bytecode instruction, we need to be able to determine the line of the user’s source program that it was compiled from.

當運行時錯誤發生時，我們會向用户顯示出錯的源代碼的行號。在jlox中，這些數字保存在詞法標記中，而我們又將詞法標記存儲在AST節點中。既然我們已經拋棄了語法樹而採用了字節碼，我們就需要為clox提供不同的解決方案。對於任何字節碼指令，我們需要能夠確定它是從用户源代碼的哪一行編譯出來的。

> There are a lot of clever ways we could encode this. I took the absolute simplest approach I could come up with, even though it’s embarrassingly inefficient with memory. In the chunk, we store a separate array of integers that parallels the bytecode. Each number in the array is the line number for the corresponding byte in the bytecode. When a runtime error occurs, we look up the line number at the same index as the current instruction’s offset in the code array.

我們有很多聰明的方法可以對此進行編碼。我採取了我能想到的絕對最簡單的方法，儘管這種方法的內存效率低得令人髮指[^12]。在字節碼塊中，我們存儲一個單獨的整數數組，該數組與字節碼平級。數組中的每個數字都是字節碼中對應字節所在的行號。當發生運行時錯誤時，我們根據當前指令在代碼數組中的偏移量查找對應的行號。

> To implement this, we add another array to Chunk.

為了實現這一點，我們向Chunk中添加另一個數組。

*<u>chunk.h， 在結構體 Chunk中添加：</u>*

```c
  uint8_t* code;
  // 新增部分開始
  int* lines;
  // 新增部分結束
  ValueArray constants;
```

> Since it exactly parallels the bytecode array, we don’t need a separate count or capacity. Every time we touch the code array, we make a corresponding change to the line number array, starting with initialization.

由於它與字節碼數組完全平行，我們不需要單獨的計數值和容量值。每次我們訪問代碼數組時，也會對行號數組做相應的修改，從初始化開始。

*<u>chunk.c，在 initChunk()方法中添加：</u>*

```c
  chunk->code = NULL;
  // 新增部分開始
  chunk->lines = NULL;
  // 新增部分結束
  initValueArray(&chunk->constants);
```

> And likewise deallocation:

回收也是類似的：

*<u>chunk.c，在 freeChunk()中添加：</u>*

```c
  FREE_ARRAY(uint8_t, chunk->code, chunk->capacity);
  // 新增部分開始
  FREE_ARRAY(int, chunk->lines, chunk->capacity);
  // 新增部分結束
  freeValueArray(&chunk->constants);
```

> When we write a byte of code to the chunk, we need to know what source line it came from, so we add an extra parameter in the declaration of `writeChunk()`.

當我們向塊中寫入一個代碼字節時，我們需要知道它來自哪個源代碼行，所以我們在`writeChunk()`的聲明中添加一個額外的參數。

*<u>chunk.h，在 writeChunk()函數中替換一行：</u>*

```c
void freeChunk(Chunk* chunk);
// 替換部分開始
void writeChunk(Chunk* chunk, uint8_t byte, int line);
// 替換部分結束
int addConstant(Chunk* chunk, Value value);
```

> And in the implementation:

然後在實現中修改：

*<u>chunk.c，在 writeChunk()函數中替換一行：</u>*

```c
// 替換部分開始
void writeChunk(Chunk* chunk, uint8_t byte, int line) {
// 替換部分結束
  if (chunk->capacity < chunk->count + 1) {
```

> When we allocate or grow the code array, we do the same for the line info too.

當我們分配或擴展代碼數組時，我們也要對行信息進行相同的處理。

*<u>chunk.c，在 writeChunk()方法中添加：</u>*

```c
    chunk->code = GROW_ARRAY(uint8_t, chunk->code,
        oldCapacity, chunk->capacity);
    // 新增部分開始    
    chunk->lines = GROW_ARRAY(int, chunk->lines,
        oldCapacity, chunk->capacity);
    // 新增部分結束    
  }
```

> Finally, we store the line number in the array.

最後，我們在數組中保存行信息。

*<u>chunk.c，在 writeChunk()方法中添加：</u>*

```c
  chunk->code[chunk->count] = byte;
  // 新增部分開始
  chunk->lines[chunk->count] = line;
  // 新增部分結束
  chunk->count++;
```

> ### 14 . 6 . 1 Disassembling line information

### 14.6.1 反彙編行信息

> Alright, let’s try this out with our little, uh, artisanal chunk. First, since we added a new parameter to `writeChunk()`, we need to fix those calls to pass in some—arbitrary at this point—line number.

好吧，讓我們手動編譯一個小的字節碼塊測試一下。首先，由於我們向`writeChunk()`添加了一個新參數，我們需要修改一下該方法的調用，向其中添加一些行號（這裏可以隨意選擇行號值）。

> *main.c*，在 *main*()方法中替換四行：

```c
  int constant = addConstant(&chunk, 1.2);
  // 替換部分開始
  writeChunk(&chunk, OP_CONSTANT, 123);
  writeChunk(&chunk, constant, 123);

  writeChunk(&chunk, OP_RETURN, 123);
  // 替換部分結束
  disassembleChunk(&chunk, "test chunk");
```

> Once we have a real front end, of course, the compiler will track the current line as it parses and pass that in.

當然，一旦我們有了真正的前端，編譯器會在解析時跟蹤當前行，並將其傳入字節碼中。

> Now that we have line information for every instruction, let’s put it to good use. In our disassembler, it’s helpful to show which source line each instruction was compiled from. That gives us a way to map back to the original code when we’re trying to figure out what some blob of bytecode is supposed to do. After printing the offset of the instruction—the number of bytes from the beginning of the chunk—we show its source line.

現在我們有了每條指令的行信息，讓我們好好利用它吧。在我們的反彙編程序中，展示每條指令是由哪一行源代碼編譯出來的是很有幫助的。當我們試圖弄清楚某些字節碼應該做什麼時，這給我們提供了一種方法來映射回原始代碼。在打印了指令的偏移量之後——從字節碼塊起點到當前指令的字節數——我們也展示它在源代碼中的行號。

*<u>debug.c，在 disassembleInstruction()方法中添加：</u>*

```c
int disassembleInstruction(Chunk* chunk, int offset) {
  printf("%04d ", offset);
  // 新增部分開始
  if (offset > 0 &&
      chunk->lines[offset] == chunk->lines[offset - 1]) {
    printf("   | ");
  } else {
    printf("%4d ", chunk->lines[offset]);
  }
  // 新增部分結束
  uint8_t instruction = chunk->code[offset];
```

> Bytecode instructions tend to be pretty fine-grained. A single line of source code often compiles to a whole sequence of instructions. To make that more visually clear, we show a `|` for any instruction that comes from the same source line as the preceding one. The resulting output for our handwritten chunk looks like:

字節碼指令往往是非常細粒度的。一行源代碼往往可以編譯成一個完整的指令序列。為了更直觀地説明這一點，我們在與前一條指令來自同一源碼行的指令前面顯示一個“|”。我們的手寫字節碼塊的輸出結果如下所示：

```
== test chunk ==
0000  123 OP_CONSTANT         0 '1.2'
0002    | OP_RETURN
```

> We have a three-byte chunk. The first two bytes are a constant instruction that loads 1.2 from the chunk’s constant pool. The first byte is the `OP_CONSTANT` opcode and the second is the index in the constant pool. The third byte (at offset 2) is a single-byte return instruction.

我們有一個三字節的塊。前兩個字節是一個常量指令，從該塊的常量池中加載1.2。第一個字節是`OP_CONSTANT`字節碼，第二個是在常量池中的索引。第三個字節（偏移量為2）是一個單字節的返回指令。

> In the remaining chapters, we will flesh this out with lots more kinds of instructions. But the basic structure is here, and we have everything we need now to completely represent an executable piece of code at runtime in our virtual machine. Remember that whole family of AST classes we defined in jlox? In clox, we’ve reduced that down to three arrays: bytes of code, constant values, and line information for debugging.

在接下來的章節中，我們將用更多種類的指令來充實這個結構。但是基本結構已經在這裏了，我們現在擁有了所需要的一切，可以在虛擬機運行時完全表示一段可執行的代碼。還記得我們在jlox中定義的整個AST類族嗎？在clox中，我們把它減少到了三個數組：代碼字節數組，常量值數組，以及用於調試的行信息。

> This reduction is a key reason why our new interpreter will be faster than jlox. You can think of bytecode as a sort of compact serialization of the AST, highly optimized for how the interpreter will deserialize it in the order it needs as it executes. In the [next chapter](http://craftinginterpreters.com/a-virtual-machine.html), we will see how the virtual machine does exactly that.

這種減少是我們的新解釋器比jlox更快的一個關鍵原因。你可以把字節碼看作是AST的一種緊湊的序列化，並且解釋器在執行時按照需要對其反序列化的方式進行了高度優化。在下一章中，我們將會看到虛擬機是如何做到這一點的。



[^1]:當然，我們的第二個解釋器會依賴C標準庫來實現內存分配等基本功能，而C編譯器將我們從運行它的底層機器碼的細節中解放出來。糟糕的是，該機器碼可能是通過芯片上的微碼來實現的。而C語言的運行時依賴於操作系統來分配內存頁。但是，如果要想在你的書架放得下這本書，我們必須在某個地方停下來。
[^2]:這種計算斐波那契數列的方式效率低得可笑。我們的目的是查看解釋器的運行速度，而不是看我們編寫的程序有多快。一個做了大量工作的程序，無論是否有意義，都是一個很好的測試用例。
[^3]:“（header）”部分是Java虛擬機用來支持內存管理和存儲對象類型的記錄信息，這些也會佔用空間。
[^4]:情況也沒有那麼可怕。一個架構良好的編譯器，可以讓你跨不同的架構共享前端和大部分中間層的優化通道。每次都需要重新編寫的主要是代碼生成和指令選擇的一些細節。[LLVM](https://llvm.org/)項目提供了一些開箱即用的功能。如果你的編譯器輸出LLVM自己特定的中間語言，LLVM可以反過來將其編譯為各種架構的本地代碼。
[^5]:最早的字節碼格式之一是p-code，是為Niklaus Wirth的Pascal語言開發的。你可能會認為一個運行在15MHz的PDP-11無法承擔模擬虛擬機的開銷。但在當時，計算機正處於寒武紀大爆發時期，每天都有新的架構出現。跟上最新的芯片要比從某個芯片中壓榨出最大性能更有價值。這就是為什麼p-code中的“p”指的不是“Pascal”而是“可移植性Portable”。
[^6]:增長數組時會複製現有元素，使得追加元素的複雜度看起來像是O(n)，而不是O(1)。但是，你只需要在某些追加操作中執行這個操作步驟。大多數時候，已有多餘的容量，所以不需要複製。要理解這一點，我們需要進行[攤銷分析](https://en.wikipedia.org/wiki/Amortized_analysis)。這表明，只要我們把數組大小增加到當前大小的倍數，當我們把一系列追加操作的成本平均化時，每次追加都是O(1)。
[^7]:我在這本書中選擇了數字8，有些隨意。大多數動態數組實現都有一個這樣的最小閾值。挑選這個值的正確方法是根據實際使用情況進行分析，看看那個常數能在額外增長和浪費的空間之間做出最佳的性能權衡。
[^8]:既然我們傳入的只是一個指向內存第一個字節的裸指針，那麼“更新”塊的大小意味着什麼呢？在內部，內存分配器為堆分配的每個內存塊都維護了額外的簿記信息，包括它的大小。給定一個指向先前分配的內存的指針，它就可以找到這個簿記信息，為了能幹淨地釋放內存，這是必需的。`realloc()`所更新的正是這個表示大小的元數據。許多`malloc()`的實現將分配的大小存儲在返回地址之前的內存中。
[^9]:除了需要兩種常量指令（一種用於即時值，一種用於常量表中的常量）之外，即時指令還要求我們考慮對齊、填充和字節順序的問題。如果你嘗試在一個奇數地址填充一個4字節的整數，有些架構中會出錯。
[^10]:我這裏對於“加載”或“產生”一個常量的含義含糊其辭，因為我們還沒有學到虛擬機在運行時是如何執行的代碼的。關於這一點，你必須等到（或者直接跳到）下一章。
[^11]:字節碼指令的操作數與傳遞給算術操作符的操作數不同。當我們講到表達式時，你會看到算術操作數的值是被單獨跟蹤的。指令操作數是一個較低層次的概念，它可以修改字節碼指令本身的行為方式。
[^12]: 這種腦殘的編碼至少做對了一件事：它將行信息保存一個單獨的數組中，而不是將其編入字節碼本身中。由於行信息只在運行時出現錯誤時才使用，我們不希望它在指令之間佔用CPU緩存中的寶貴空間，而且解釋器在跳過行數獲取它所關心的操作碼和操作數時，會造成更多的緩存丟失。

------

> ## CHALLENGES

## 習題

1. > Our encoding of line information is hilariously wasteful of memory. Given that a series of instructions often correspond to the same source line, a natural solution is something akin to [run-length encoding](https://en.wikipedia.org/wiki/Run-length_encoding) of the line numbers.

   我們對行信息的編碼非常浪費內存。鑑於一系列指令通常對應於同一源代碼行，一個自然的解決方案是對行號進行類似[遊程編碼](https://en.wikipedia.org/wiki/Run-length_encoding)的操作。

   > Devise an encoding that compresses the line information for a series of instructions on the same line. Change `writeChunk()` to write this compressed form, and implement a `getLine()` function that, given the index of an instruction, determines the line where the instruction occurs.

   設計一個編碼方式，壓縮同一行上一系列指令的行信息。修改`writeChunk()` 以寫入該壓縮形式，並實現一個`getLine()` 函數，給定一條指令的索引，確定該指令所在的行。

   > *Hint: It’s not necessary for `getLine()` to be particularly efficient. Since it is called only when a runtime error occurs, it is well off the critical path where performance matters.*

   *提示：`getLine()`不一定要特別高效。因為它只在出現運行時錯誤時才被調用，所以在它並不是影響性能的關鍵因素。*

2. > Because `OP_CONSTANT` uses only a single byte for its operand, a chunk may only contain up to 256 different constants. That’s small enough that people writing real-world code will hit that limit. We could use two or more bytes to store the operand, but that makes *every* constant instruction take up more space. Most chunks won’t need that many unique constants, so that wastes space and sacrifices some locality in the common case to support the rare case.

   因為`OP_CONSTANT`只使用一個字節作為操作數，所以一個塊最多隻能包含256個不同的常數。這已經夠小了，用户在編寫真正的代碼時很容易會遇到這個限制。我們可以使用兩個或更多字節來存儲操作數，但這會使*每個*常量指令佔用更多的空間。大多數字節碼塊都不需要那麼多獨特的常量，所以這就浪費了空間，並犧牲了一些常規情況下的局部性來支持罕見場景。

   > To balance those two competing aims, many instruction sets feature multiple instructions that perform the same operation but with operands of different sizes. Leave our existing one-byte `OP_CONSTANT` instruction alone, and define a second `OP_CONSTANT_LONG` instruction. It stores the operand as a 24-bit number, which should be plenty.

   為了平衡這兩個相互衝突的目標，許多指令集具有多個執行相同操作但操作數大小不同的指令。保留現有的使用一個字節的`OP_CONSTANT`指令，並定義一個新的`OP_CONSTANT_LONG`指令。它將操作數存儲為24位的數字，這應該就足夠了。

   > Implement this function:

   實現該函數：

   ```c
   void writeConstant(Chunk* chunk, Value value, int line) {
     // Implement me...
   }
   ```

   > It adds `value` to `chunk`’s constant array and then writes an appropriate instruction to load the constant. Also add support to the disassembler for `OP_CONSTANT_LONG` instructions.
   >

   它向`chunk`的常量數組中添加`value`，然後寫一條合適的指令來加載常量。同時在反彙編程序中增加對 `OP_CONSTANT_LONG`指令的支持。

   > Defining two instructions seems to be the best of both worlds. What sacrifices, if any, does it force on us?
   >

   定義兩條指令似乎是兩全其美的辦法。它會迫使我們做出什麼犧牲呢（如果有的話）？

3. > Our `reallocate()` function relies on the C standard library for dynamic memory allocation and freeing. `malloc()` and `free()` aren’t magic. Find a couple of open source implementations of them and explain how they work. How do they keep track of which bytes are allocated and which are free? What is required to allocate a block of memory? Free it? How do they make that efficient? What do they do about fragmentation?

   我們的`reallocate()`函數依賴於C標準庫進行動態內存分配和釋放。`malloc()` 和 `free()` 並不神奇。找幾個它們的開源實現，並解釋它們是如何工作的。它們如何跟蹤哪些字節被分配，哪些被釋放？分配一個內存塊需要什麼？釋放的時候呢？它們如何實現高效？它們如何處理碎片化內存？
   
   > *Hardcore mode:* Implement `reallocate()` without calling `realloc()`, `malloc()`, or `free()`. You are allowed to call `malloc()` *once*, at the beginning of the interpreter’s execution, to allocate a single big block of memory, which your `reallocate()` function has access to. It parcels out blobs of memory from that single region, your own personal heap. It’s your job to define how it does that.
   
   *硬核模式*：在不調用`realloc()`, `malloc()`, 和 `free()`的前提下，實現`reallocate()`。你可以在解釋器開始執行時調用一次`malloc()`，來分配一個大的內存塊，你的`reallocate()`函數能夠訪問這個內存塊。它可以從這個區域（你自己的私人堆內存）中分配內存塊。你的工作就是定義如何做到這一點。



------

> ## DESIGN NOTE: TEST YOUR LANGUAGE

## 設計筆記：測試你的語言

> We’re almost halfway through the book and one thing we haven’t talked about is *testing* your language implementation. That’s not because testing isn’t important. I can’t possibly stress enough how vital it is to have a good, comprehensive test suite for your language.
>
> I wrote a [test suite for Lox](https://github.com/munificent/craftinginterpreters/tree/master/test) (which you are welcome to use on your own Lox implementation) before I wrote a single word of this book. Those tests found countless bugs in my implementations.
>
> Tests are important in all software, but they’re even more important for a programming language for at least a couple of reasons:
>
> - **Users expect their programming languages to be rock solid.** We are so used to mature, stable compilers and interpreters that “It’s your code, not the compiler” is [an ingrained part of software culture](https://blog.codinghorror.com/the-first-rule-of-programming-its-always-your-fault/). If there are bugs in your language implementation, users will go through the full five stages of grief before they can figure out what’s going on, and you don’t want to put them through all that.
> - **A language implementation is a deeply interconnected piece of software.** Some codebases are broad and shallow. If the file loading code is broken in your text editor, it—hopefully!—won’t cause failures in the text rendering on screen. Language implementations are narrower and deeper, especially the core of the interpreter that handles the language’s actual semantics. That makes it easy for subtle bugs to creep in caused by weird interactions between various parts of the system. It takes good tests to flush those out.
> - **The input to a language implementation is, by design, combinatorial.** There are an infinite number of possible programs a user could write, and your implementation needs to run them all correctly. You obviously can’t test that exhaustively, but you need to work hard to cover as much of the input space as you can.
> - **Language implementations are often complex, constantly changing, and full of optimizations.** That leads to gnarly code with lots of dark corners where bugs can hide.
>
> All of that means you’re gonna want a lot of tests. But *what* tests? Projects I’ve seen focus mostly on end-to-end “language tests”. Each test is a program written in the language along with the output or errors it is expected to produce. Then you have a test runner that pushes the test program through your language implementation and validates that it does what it’s supposed to. Writing your tests in the language itself has a few nice advantages:
>
> - The tests aren’t coupled to any particular API or internal architecture decisions of the implementation. This frees you to reorganize or rewrite parts of your interpreter or compiler without needing to update a slew of tests.
> - You can use the same tests for multiple implementations of the language.
> - Tests can often be terse and easy to read and maintain since they are simply scripts in your language.
>
> It’s not all rosy, though:
>
> - End-to-end tests help you determine *if* there is a bug, but not *where* the bug is. It can be harder to figure out where the erroneous code in the implementation is because all the test tells you is that the right output didn’t appear.
> - It can be a chore to craft a valid program that tickles some obscure corner of the implementation. This is particularly true for highly optimized compilers where you may need to write convoluted code to ensure that you end up on just the right optimization path where a bug may be hiding.
> - The overhead can be high to fire up the interpreter, parse, compile, and run each test script. With a big suite of tests—which you *do* want, remember—that can mean a lot of time spent waiting for the tests to finish running.
>
> I could go on, but I don’t want this to turn into a sermon. Also, I don’t pretend to be an expert on *how* to test languages. I just want you to internalize how important it is *that* you test yours. Seriously. Test your language. You’ll thank me for it.

我們的書已經過半了，有一件事我們還沒有談及，那就是*測試*你的語言實現。這並不是因為測試不重要。語言實現有一個好的、全面的套件是多麼重要，我怎麼強調都不為過。

在我寫本書之前，我為Lox寫了一個[測試套件](https://github.com/munificent/craftinginterpreters/tree/master/test)（你也可以在自己的Lox實現中使用它）。這些測試在我的語言實現中發現了無數的bug。

測試在所有軟件中都很重要，但對於編程語言來説，測試甚至更重要，至少有以下幾個原因：

* **用户希望他們的編程語言能夠堅如磐石**。我們已經習慣了成熟的編譯器、解釋器，以至於“是你的代碼（出錯了），而不是編譯器”成為[軟件文化中根深蒂固的一部分](https://blog.codinghorror.com/the-first-rule-of-programming-its-always-your-fault/)。如果你的語言實現中有錯誤，用户需要經歷全部五個痛苦的階段才能弄清楚發生了什麼，而你並不想讓他們經歷這一切。
* **語言的實現是一個緊密相連的軟件**。有些代碼庫既廣泛又浮淺。如果你的文本編輯器中的文件加載代碼被破壞了，它不會導致屏幕上的文本渲染失敗（希望如此）。語言的實現則更狹窄和深入，特別是處理語言實際語義的解釋器核心部分。這使得系統的各個部分之間奇怪的交互會造成微妙的錯誤。這就需要好的測試來清除這些問題。
* **從設計上來説，語言實現的輸入是組合性的**。用户可以寫出無限多的程序，而你的實現需要能夠正確地運行這些程序。您顯然不能進行詳盡地測試，但需要努力覆蓋儘可能多的輸入空間。
* **語言的實現通常是複雜的、不斷變化的，而且充滿了優化**。這就導致了粗糙代碼中有很多隱藏錯誤的黑暗角落。

所有這些都意味着你需要做大量的測試。但是什麼測試呢？我見過的項目主要集中在端到端的“語言測試”上。每個測試都是一段用該語言編寫的程序，以及它預期產生的輸出或錯誤。然後，你還需要一個測試運行器，將這些測試程序輸入到你的語言實現中，並驗證它是否按照預期執行。用語言本身編寫測試有一些很好的優勢：

* 測試不與任何特定的API或語言實現的內部結構相耦合。這樣你可以重新組織或重寫解釋器或編譯器的一部分，而不需要更新大量的測試。
* 你可以對該語言的多種實現使用相同的測試。
* 測試通常是簡潔的，易於閲讀和維護，因為它們只是語言寫就的簡單腳本。

不過，這並不全是好事：

* 端到端測試可以幫助你確定是否存在錯誤，但不能確認錯誤在哪裏。在語言實現中找出錯誤代碼的位置可能更加困難，因為測試只能告訴你沒有出現正確的輸出。
* 要編寫一個有效的程序來測試實現中一些不太明顯的角落，可能是一件比較麻煩的事。對於高度優化的編譯器來説尤其如此，你可能需要編寫複雜的代碼，以確保最終能夠到達正確的優化路徑，以測試其中可能隱藏的錯誤。
* 啓動解釋器、解析、編譯和運行每個測試腳本的開銷可能很高。對於一個大的測試套件來説，（如果你確實需要的話，請記住）這可能意味着需要花費很多時間來等待測試的完成。

我可以繼續説下去，但是我不希望這變成一場説教。此外，我並不想假裝自己是語言測試專家。我只是想讓你在內心深處明白，測試你的語言是多麼重要。我是認真的。測試你的語言。你會為此感謝我的。

