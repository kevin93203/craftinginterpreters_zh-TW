# 4. Scanning 掃描

> Take big bites. Anything worth doing is worth overdoing.
>
> ​                                                  ——  Robert A. Heinlein, *Time Enough for Love*

大幹特工。每件值得做的事都要盡力做好。

> The first step in any compiler or interpreter is scanning. The scanner takes in raw source code as a series of characters and groups it into a series of chunks we call **tokens**. These are the meaningful “words” and “punctuation” that make up the language’s grammar.
>

任何編譯器或解釋器的第一步都是掃描[^1]。掃描器以一系列字符的形式接收原始源代碼，並將其分組成一系列的塊，我們稱之為**標識**（詞法單元）。這些是有意義的 "單詞 "和 "標點"，它們構成了語言的語法。

> Scanning is a good starting point for us too because the code isn’t very hard—pretty much a `switch` statement with delusions of grandeur. It will help us warm up before we tackle some of the more interesting material later. By the end of this chapter, we’ll have a full-featured, fast scanner that can take any string of Lox source code and produce the tokens that we’ll feed into the parser in the next chapter.
>

對於我們來説，掃描也是一個很好的起點，因為代碼不是很難——相當於有很多分支的`switch`語句。這可以幫助我們在學習更後面有趣的部分之前進行熱身。在本章結束時，我們將擁有一個功能齊全、速度快的掃描器，它可以接收任何一串Lox源代碼，併產生標記，我們將在下一章把這些標記輸入到解析器中。

> ## 4 . 1 The Interpreter Framework

## 4.1 解釋器框架

> Since this is our first real chapter, before we get to actually scanning some code we need to sketch out the basic shape of our interpreter, jlox. Everything starts with a class in Java.
>

由於這是我們的第一個真正的章節，在我們開始實際掃描代碼之前，我們需要先勾勒出我們的解釋器jlox的基本形態。在Java中，一切都是從一個類開始的。

【譯者注：原作者在代碼的側邊欄標註了代碼名及對應的操作（創建文件、追加代碼、刪除代碼等），由於翻譯版的格式受限，將這部分信息遷移到代碼塊之前，以帶下劃線的斜體突出，後同】

 <u>*lox/Lox.java，創建新文件[^2]*</u> 

```java
package com.craftinginterpreters.lox;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.nio.charset.Charset;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.List;

public class Lox {
  public static void main(String[] args) throws IOException {
    if (args.length > 1) {
      System.out.println("Usage: jlox [script]");
      System.exit(64); 
    } else if (args.length == 1) {
      runFile(args[0]);
    } else {
      runPrompt();
    }
  }
}
```

> Stick that in a text file, and go get your IDE or Makefile or whatever set up. I’ll be right here when you’re ready. Good? OK!

把它貼在一個文本文件裏，然後去把你的IDE或者Makefile或者其他工具設置好。我就在這裏等你準備好。好了嗎？好的！

> Lox is a scripting language, which means it executes directly from source. Our interpreter supports two ways of running code. If you start jlox from the command line and give it a path to a file, it reads the file and executes it.
>

Lox是一種腳本語言，這意味着它直接從源代碼執行。我們的解釋器支持兩種運行代碼的方式。如果從命令行啓動jlox併為其提供文件路徑，它將讀取該文件並執行。

*<u>lox/Lox.java，添加到`main()`方法之後</u>*

```java
private static void runFile(String path) throws IOException {
  byte[] bytes = Files.readAllBytes(Paths.get(path));
  run(new String(bytes, Charset.defaultCharset()));
}
```

> If you want a more intimate conversation with your interpreter, you can also run it interactively. Fire up jlox without any arguments, and it drops you into a prompt where you can enter and execute code one line at a time.

如果你想與你的解釋器對話, 可以交互式的啓動它。 啓動的時候不加任何參數就可以了，它會有一個提示符，你可以在提示符處一次輸入並執行一行代碼。

*<u>lox/Lox.java，添加到`runFile()`方法之後[^3]</u>*

```java
private static void runPrompt() throws IOException {
  InputStreamReader input = new InputStreamReader(System.in);
  BufferedReader reader = new BufferedReader(input);

  for (;;) { 
    System.out.print("> ");
    String line = reader.readLine();
    if (line == null) break;
    run(line);
  }
}
```

> The `readLine()` function, as the name so helpfully implies, reads a line of input from the user on the command line and returns the result. To kill an interactive command-line app, you usually type Control-D. Doing so signals an “end-of-file” condition to the program. When that happens `readLine()` returns `null`, so we check for that to exit the loop.

`readLine()`函數，顧名思義，讀取用户在命令行上的一行輸入，並返回結果。要終止交互式命令行應用程序，通常需要輸入Control-D。這樣做會向程序發出 "文件結束" 的信號。當這種情況發生時，readLine()就會返回null，所以我們檢查一下是否存在null以退出循環。

> Both the prompt and the file runner are thin wrappers around this core function:

交互式提示符和文件運行工具都是對這個核心函數的簡單包裝：

*<u>lox/Lox.java，添加到`runPrompt()`之後</u>*

```java
  private static void run(String source) {
    Scanner scanner = new Scanner(source);
    List<Token> tokens = scanner.scanTokens();

    // For now, just print the tokens.
    for (Token token : tokens) {
      System.out.println(token);
    }
  }
```

> It’s not super useful yet since we haven’t written the interpreter, but baby steps, you know? Right now, it prints out the tokens our forthcoming scanner will emit so that we can see if we’re making progress.

因為我們還沒有寫出解釋器，所以這些代碼還不是很有用，但這只是小步驟，你要明白？現在，它可以打印出我們即將完成的掃描器所返回的標記，這樣我們就可以看到我們的解析是否生效。

> ### 4 . 1 . 1 Error handling

### 4.1.1 錯誤處理

> While we’re setting things up, another key piece of infrastructure is *error handling*. Textbooks sometimes gloss over this because it’s more a practical matter than a formal computer science-y problem. But if you care about making a language that’s actually *usable*, then handling errors gracefully is vital.

當我們設置東西的時候，另一個關鍵的基礎設施是錯誤處理。教科書有時會掩蓋這一點，因為這更多的是一個實際問題，而不是一個正式的計算機科學問題。但是，如果你關心的是如何製作一個真正可用的語言，那麼優雅地處理錯誤是至關重要的。

> The tools our language provides for dealing with errors make up a large portion of its user interface. When the user’s code is working, they aren’t thinking about our language at all—their headspace is all about *their program*. It’s usually only when things go wrong that they notice our implementation.

我們的語言提供的處理錯誤的工具構成了其用户界面的很大一部分。當用户的代碼在工作時，他們根本不會考慮我們的語言——他們的腦子裏都是他們的程序。通常只有當程序出現問題時，他們才會注意到我們的實現。

> When that happens, it’s up to us to give the user all the information they need to understand what went wrong and guide them gently back to where they are trying to go. Doing that well means thinking about error handling all through the implementation of our interpreter, starting now.

當這種情況發生時，我們就需要向用户提供他們所需要的所有信息，讓他們瞭解哪裏出了問題，並引導他們慢慢達到他們想要去的地方。要做好這一點，意味着從現在開始，在解釋器的整個實現過程中都要考慮錯誤處理[^4]。

*<u>lox/Lox.java，添加到`run()`方法之後</u>*

```java
static void error(int line, String message) {
    report(line, "", message);
  }

  private static void report(int line, String where,
                             String message) {
    System.err.println(
        "[line " + line + "] Error" + where + ": " + message);
    hadError = true;
  }
```

> This `error()` function and its `report()` helper tells the user some syntax error occurred on a given line. That is really the bare minimum to be able to claim you even *have* error reporting. Imagine if you accidentally left a dangling comma in some function call and the interpreter printed out:

這個`error()`函數和其工具方法`report()`會告訴用户在某一行上發生了一些語法錯誤。這其實是最起碼的，可以説你有錯誤報告功能。想象一下，如果你在某個函數調用中不小心留下了一個懸空的逗號，解釋器就會打印出來：

```java
Error: Unexpected "," somewhere in your code. Good luck finding it!
```

> That’s not very helpful. We need to at least point them to the right line. Even better would be the beginning and end column so they know *where* in the line. Even better than *that* is to *show* the user the offending line, like:

這種信息沒有多大幫助。我們至少要給他們指出正確的方向。好一些的做法是指出開頭和結尾一欄，這樣他們就知道這一行的位置了。更好的做法是向用户顯示違規的行，比如：

```java
Error: Unexpected "," in argument list.

    15 | function(first, second,);
                               ^-- Here.
```

> I’d love to implement something like that in this book but the honest truth is that it’s a lot of grungy string manipulation code. Very useful for users, but not super fun to read in a book and not very technically interesting. So we’ll stick with just a line number. In your own interpreters, please do as I say and not as I do.

我很想在這本書裏實現這樣的東西，但老實説，這會引入很多繁瑣的字符串操作代碼。這些代碼對用户來説非常有用，但在書中讀起來並不友好，而且技術上也不是很有趣。所以我們還是隻用一個行號。在你們自己的解釋器中，請按我説的做，而不是按我做的做。

> The primary reason we’re sticking this error reporting function in the main Lox class is because of that `hadError` field. It’s defined here:

我們在Lox主類中堅持使用這個錯誤報告功能的主要原因就是因為那個hadError字段。它的定義在這裏：

*<u>lox/Lox.java 在Lox類中添加：</u>*

```java
public class Lox {
  static boolean hadError = false;
```

> We’ll use this to ensure we don’t try to execute code that has a known error. Also, it lets us exit with a non-zero exit code like a good command line citizen should.

我們將以此來確保我們不會嘗試執行有已知錯誤的代碼。此外，它還能讓我們像一個好的命令行工具那樣，用一個非零的結束代碼退出。

*<u>lox/Lox.java，在runFile()中添加：</u>*

```java
    run(new String(bytes, Charset.defaultCharset()));
    
    // Indicate an error in the exit code.
    if (hadError) System.exit(65);
  }
```

> We need to reset this flag in the interactive loop. If the user makes a mistake, it shouldn’t kill their entire session.

我們需要在交互式循環中重置此標誌。 如果用户輸入有誤，也不應終止整個會話。

*<u>lox/Lox.java，在runPrompt()中添加：</u>*

```java
      run(line);
      hadError = false;
    }
```

> The other reason I pulled the error reporting out here instead of stuffing it into the scanner and other phases where the error might occur is to remind you that it’s good engineering practice to separate the code that *generates* the errors from the code that *reports* them.

我把錯誤報告拉出來，而不是把它塞進掃描器和其他可能發生錯誤的階段，還有另一個原因，是為了提醒您，把產生錯誤的代碼和報告錯誤的代碼分開是一個很好的工程實踐。

> Various phases of the front end will detect errors, but it’s not really their job to know how to present that to a user. In a full-featured language implementation, you will likely have multiple ways errors get displayed: on stderr, in an IDE’s error window, logged to a file, etc. You don’t want that code smeared all over your scanner and parser.

前端的各個階段都會檢測到錯誤，但是它們不需要知道如何向用户展示錯誤。在一個功能齊全的語言實現中，可能有多種方式展示錯誤信息：在stderr，在IDE的錯誤窗口中，記錄到文件，等等。您肯定不希望掃描器和解釋器中到處充斥着這類代碼。

> Ideally, we would have an actual abstraction, some kind of “ErrorReporter” interface that gets passed to the scanner and parser so that we can swap out different reporting strategies. For our simple interpreter here, I didn’t do that, but I did at least move the code for error reporting into a different class.

理想情況下，我們應該有一個實際的抽象，即傳遞給掃描程序和解析器的某種ErrorReporter接口[^5]，這樣我們就可以交換不同的報告策略。對於我們這裏的簡單解釋器，我沒有那樣做，但我至少將錯誤報告代碼移到了一個不同的類中。

> With some rudimentary error handling in place, our application shell is ready. Once we have a Scanner class with a `scanTokens()` method, we can start running it. Before we get to that, let’s get more precise about what tokens are.

有了一些基本的錯誤處理，我們的應用程序外殼已經準備好了。一旦我們有了一個帶有 `scanTokens() `方法的 Scanner 類，我們就可以開始運行它了。在我們開始之前，讓我們更精確地瞭解什麼是標記（tokens）。

> ## 4 . 2 Lexemes and Tokens

## 4.2 詞素和標記（詞法單元）

下面是一行lox代碼：

```js
var language = "lox";
```

> Here, `var` is the keyword for declaring a variable. That three-character sequence “v-a-r” means something. But if we yank three letters out of the middle of `language`, like “g-u-a”, those don’t mean anything on their own.

在這裏，`var`是聲明變量的關鍵字。“v-a-r”這三個字符的序列是有意義的。但如果我們從`language`中間抽出三個字母，比如“g-u-a”，它們本身並沒有任何意義。

> That’s what lexical analysis is about. Our job is to scan through the list of characters and group them together into the smallest sequences that still represent something. Each of these blobs of characters is called a **lexeme**. In that example line of code, the lexemes are:

這就是詞法分析的意義所在。我們的工作是掃描字符列表，並將它們歸納為具有某些含義的最小序列。每一組字符都被稱為詞素。在示例代碼行中，詞素是：

!['var', 'language', '=', 'lox', ';'](4.掃描/lexemes.png)

> The lexemes are only the raw substrings of the source code. However, in the process of grouping character sequences into lexemes, we also stumble upon some other useful information. When we take the lexeme and bundle it together with that other data, the result is a token. It includes useful stuff like:

詞素只是源代碼的原始子字符串。 但是，在將字符序列分組為詞素的過程中，我們也會發現了一些其他有用的信息。 當我們獲取詞素並將其與其他數據捆綁在一起時，結果是一個標記（token，詞法單元）。它包含一些有用的內容，比如：

> ### 4 . 2 . 1 Token type 

### 4.2.1 標記類型

> Keywords are part of the shape of the language’s grammar, so the parser often has code like, “If the next token is `while` then do . . . ” That means the parser wants to know not just that it has a lexeme for some identifier, but that it has a *reserved* word, and *which* keyword it is.

關鍵詞是語言語法的一部分，所以解析器經常會有這樣的代碼："如果下一個標記是`while`，那麼就……" 。這意味着解析器想知道的不僅僅是它有某個標識符的詞素，而是它得到一個*保留詞*，以及它是*哪個*關鍵詞。

> The parser could categorize tokens from the raw lexeme by comparing the strings, but that’s slow and kind of ugly. Instead, at the point that we recognize a lexeme, we also remember which *kind* of lexeme it represents. We have a different type for each keyword, operator, bit of punctuation, and literal type.

解析器可以通過比較字符串對原始詞素中的標記進行分類，但這樣做很慢，而且有點難看[^6]。相反，在我們識別一個詞素的時候，我們還要記住它代表的是哪種詞素。我們為每個關鍵字、操作符、標點位和字面量都有不同的類型。

*<u>lox/TokenType.java  創建新文件</u>*

```java
package com.craftinginterpreters.lox;

enum TokenType {
  // Single-character tokens.
  LEFT_PAREN, RIGHT_PAREN, LEFT_BRACE, RIGHT_BRACE,
  COMMA, DOT, MINUS, PLUS, SEMICOLON, SLASH, STAR,

  // One or two character tokens.
  BANG, BANG_EQUAL,
  EQUAL, EQUAL_EQUAL,
  GREATER, GREATER_EQUAL,
  LESS, LESS_EQUAL,

  // Literals.
  IDENTIFIER, STRING, NUMBER,

  // Keywords.
  AND, CLASS, ELSE, FALSE, FUN, FOR, IF, NIL, OR,
  PRINT, RETURN, SUPER, THIS, TRUE, VAR, WHILE,

  EOF
}
```

> ### 4 . 2 . 2 Literal value

### 4.2.2 字面量

> There are lexemes for literal values—numbers and strings and the like. Since the scanner has to walk each character in the literal to correctly identify it, it can also convert that textual representation of a value to the living runtime object that will be used by the interpreter later.

字面量有對應詞素——數字和字符串等。由於掃描器必須遍歷文字中的每個字符才能正確識別，所以它還可以將值的文本表示轉換為運行時對象，解釋器後續將使用該對象。

> ### 4 . 2 . 3 Location information

### 4.2.3 位置信息

> Back when I was preaching the gospel about error handling, we saw that we need to tell users *where* errors occurred. Tracking that starts here. In our simple interpreter, we note only which line the token appears on, but more sophisticated implementations include the column and length too.

早在我宣講錯誤處理的福音時，我們就看到，我們需要告訴用户錯誤發生在哪裏。（用户）從這裏開始定位問題。在我們的簡易解釋器中，我們只説明瞭標記出現在哪一行上，但更復雜的實現中還應該包括列位置和長度[^7]。

> We take all of this data and wrap it in a class.

我們將所有這些數據打包到一個類中。

*<u>lox/Token.java，創建新文件</u>*

```java
package com.craftinginterpreters.lox;

class Token {
  final TokenType type;
  final String lexeme;
  final Object literal;
  final int line; 

  Token(TokenType type, String lexeme, Object literal, int line) {
    this.type = type;
    this.lexeme = lexeme;
    this.literal = literal;
    this.line = line;
  }

  public String toString() {
    return type + " " + lexeme + " " + literal;
  }
}
```

> Now we have an object with enough structure to be useful for all of the later phases of the interpreter.

現在我們有了一個信息充分的對象，足以支撐解釋器的所有後期階段。

> ## 4 . 3 Regular Languages and Expressions

## 4.3 正則語言和表達式

> Now that we know what we’re trying to produce, let’s, well, produce it. The core of the scanner is a loop. Starting at the first character of the source code, it figures out what lexeme it belongs to, and consumes it and any following characters that are part of that lexeme. When it reaches the end of that lexeme, it emits a token.

既然我們已知道我們要輸出什麼，那麼，我們就開始吧。掃描器的核心是一個循環。從源碼的第一個字符開始，掃描器計算出該字符屬於哪個詞素，並消費它和屬於該詞素的任何後續字符。當到達該詞素的末尾時，掃描器會輸出一個標記（詞法單元 token）。

> Then it loops back and does it again, starting from the very next character in the source code. It keeps doing that, eating characters and occasionally, uh, excreting tokens, until it reaches the end of the input.

然後再循環一次，它又循環回來，從源代碼中的下一個字符開始再做一次。它一直這樣做，吃掉字符，偶爾，呃，排出標記，直到它到達輸入的終點。

![An alligator eating characters and, well, you don't want to know.](4.掃描/lexigator.png)

> The part of the loop where we look at a handful of characters to figure out which kind of lexeme it “matches” may sound familiar. If you know regular expressions, you might consider defining a regex for each kind of lexeme and using those to match characters. For example, Lox has the same rules as C for identifiers (variable names and the like). This regex matches one:

在循環中，我們會查看一些字符，以確定它 "匹配 "的是哪種詞素，這部分內容可能聽起來很熟悉，但如果你知道正則表達式，你可以考慮為每一種詞素定義一個regex，並使用這些regex來匹配字符。例如，Lox對標識符（變量名等）的規則與C語言相同。下面的regex可以匹配一個標識符：

```js
[a-zA-Z_][a-zA-Z_0-9]*
```

> If you did think of regular expressions, your intuition is a deep one. The rules that determine how a particular language groups characters into lexemes are called its **lexical grammar**. In Lox, as in most programming languages, the rules of that grammar are simple enough for the language to be classified a **[regular language](https://en.wikipedia.org/wiki/Regular_language)**. That’s the same “regular” as in regular expressions.

如果你確實想到了正則表達式，那麼你的直覺還是很深刻的。決定一門語言如何將字符分組為詞素的規則被稱為它的**詞法語法**[^8]。在Lox中，和大多數編程語言一樣，該語法的規則非常簡單，可以將其歸為 **[正則語言](https://en.wikipedia.org/wiki/Regular_language)**。這裏的正則和正則表達式中的 "正則 "是一樣的含義。

> You very precisely *can* recognize all of the different lexemes for Lox using regexes if you want to, and there’s a pile of interesting theory underlying why that is and what it means. Tools like [Lex](http://dinosaur.compilertools.net/lex/) or [Flex](https://github.com/westes/flex) are designed expressly to let you do this—throw a handful of regexes at them, and they give you a complete scanner back.

如果你願意，你可以非常精確地使用正則表達式來識別Lox的所有不同詞組，而且還有一堆有趣的理論來支撐着為什麼會這樣以及它的意義。像[Lex](http://dinosaur.compilertools.net/lex/)[^9]或[Flex](https://github.com/westes/flex)這樣的工具就是專門為實現這一功能而設計的——向其中傳入一些正則表達式，它可以為您提供完整的掃描器。

> Since our goal is to understand how a scanner does what it does, we won’t be delegating that task. We’re about handcrafted goods.

由於我們的目標是瞭解掃描器是如何工作的，所以我們不會把這個任務交給正則表達式。我們要親自動手實現。

> ## 4 . 4 The Scanner Class

## 4.4 Scanner類

事不宜遲，我們先來建一個掃描器吧。

*<u>lox/Scanner.java，創建新文件[^10]</u>*

```java
package com.craftinginterpreters.lox;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import static com.craftinginterpreters.lox.TokenType.*; 

class Scanner {
  private final String source;
  private final List<Token> tokens = new ArrayList<>();

  Scanner(String source) {
    this.source = source;
  }
}
```

> We store the raw source code as a simple string, and we have a list ready to fill with tokens we’re going to generate. The aforementioned loop that does that looks like this:

我們將原始的源代碼存儲為一個簡單的字符串，並且我們已經準備了一個列表來保存掃描時產生的標記。前面提到的循環看起來類似於：

*<u>lox/Scanner.java，方法Scanner()後添加</u>*：

```java
  List<Token> scanTokens() {
    while (!isAtEnd()) {
      // We are at the beginning of the next lexeme.
      start = current;
      scanToken();
    }

    tokens.add(new Token(EOF, "", null, line));
    return tokens;
  }
```

> The scanner works its way through the source code, adding tokens until it runs out of characters. Then it appends one final “end of file” token. That isn’t strictly needed, but it makes our parser a little cleaner.

掃描器通過自己的方式遍歷源代碼，添加標記，直到遍歷完所有字符。然後，它在最後附加一個的 "end of file "標記。嚴格意義上來説，這並不是必須的，但它可以使我們的解析器更加乾淨。

> This loop depends on a couple of fields to keep track of where the scanner is in the source code.

這個循環依賴於幾個字段來跟蹤掃描器在源代碼中的位置。

*<u>lox/Scanner.java，在Scanner類中添加：</u>*

```java
  private final List<Token> tokens = new ArrayList<>();
// 添加下面三行代碼
  private int start = 0;
  private int current = 0;
  private int line = 1;

  Scanner(String source) {
```

> The `start` and `current` fields are offsets that index into the string. The `start` field points to the first character in the lexeme being scanned, and `current` points at the character currently being considered. The `line` field tracks what source line `current` is on so we can produce tokens that know their location.

`start`和`current`字段是指向字符串的偏移量。`start`字段指向被掃描的詞素中的第一個字符，`current`字段指向當前正在處理的字符。`line`字段跟蹤的是`current`所在的源文件行數，這樣我們產生的標記就可以知道其位置。

> Then we have one little helper function that tells us if we’ve consumed all the characters.

然後，我們還有一個輔助函數，用來告訴我們是否已消費完所有字符。

*<u>lox/Scanner.java在scanTokens()方法之後添加：</u>*

```java
  private boolean isAtEnd() {
    return current >= source.length();
  }
```
> ## 4 . 5 Recognizing Lexemes
## 4 . 5 識別詞素

> In each turn of the loop, we scan a single token. This is the real heart of the scanner. We’ll start simple. Imagine if every lexeme were only a single character long. All you would need to do is consume the next character and pick a token type for it. Several lexemes *are* only a single character in Lox, so let’s start with those.

在每一次循環中，我們可以掃描出一個 token。這是掃描器真正的核心。讓我們先從簡單情況開始。想象一下，如果每個詞素只有一個字符長。您所需要做的就是消費下一個字符併為其選擇一個 token 類型。在Lox中有一些詞素只包含一個字符，所以我們從這些詞素開始[^11]。

*<u>lox/Scanner.java添加到scanTokens()方法之後</u>*

```java
private void scanToken() {
    char c = advance();
    switch (c) {
      case '(': addToken(LEFT_PAREN); break;
      case ')': addToken(RIGHT_PAREN); break;
      case '{': addToken(LEFT_BRACE); break;
      case '}': addToken(RIGHT_BRACE); break;
      case ',': addToken(COMMA); break;
      case '.': addToken(DOT); break;
      case '-': addToken(MINUS); break;
      case '+': addToken(PLUS); break;
      case ';': addToken(SEMICOLON); break;
      case '*': addToken(STAR); break; 
    }
  }
```

> Again, we need a couple of helper methods.

同樣，我們也需要一些輔助方法。

*<u>lox/Scanner.java，添加到 isAtEnd()方法後</u>*

```java
  private char advance() {
    current++;
    return source.charAt(current - 1);
  }

  private void addToken(TokenType type) {
    addToken(type, null);
  }

  private void addToken(TokenType type, Object literal) {
    String text = source.substring(start, current);
    tokens.add(new Token(type, text, literal, line));
  }
```

> The `advance()` method consumes the next character in the source file and returns it. Where `advance()` is for input, `addToken()` is for output. It grabs the text of the current lexeme and creates a new token for it. We’ll use the other overload to handle tokens with literal values soon.

`advance()`方法獲取源文件中的下一個字符並返回它。`advance()`用於處理輸入，`addToken()`則用於輸出。該方法獲取當前詞素的文本併為其創建一個新 token。我們馬上會使用另一個重載方法來處理帶有字面值的 token。

> ### 4 . 5 . 1 Lexical errors

### 4.5.1 詞法錯誤

> Before we get too far in, let’s take a moment to think about errors at the lexical level. What happens if a user throws a source file containing some characters Lox doesn’t use, like `@#^`, at our interpreter? Right now, those characters get silently discarded. They aren’t used by the Lox language, but that doesn’t mean the interpreter can pretend they aren’t there. Instead, we report an error.

在我們深入探討之前，我們先花一點時間考慮一下詞法層面的錯誤。如果用户拋入解釋器的源文件中包含一些Lox中不使用的字符——如`@#^`，會發生什麼？現在，這些字符被默默拋棄了。它們沒有被Lox語言使用，但是不意味着解釋器可以假裝它們不存在。相反，我們應該報告一個錯誤：

*<u>lox/Scanner.java 在 scanToken()方法中添加：</u>*

```java
      case '*': addToken(STAR); break; 

      default:
        Lox.error(line, "Unexpected character.");
        break;
    }
```

> Note that the erroneous character is still *consumed* by the earlier call to `advance()`. That’s important so that we don’t get stuck in an infinite loop.

注意，錯誤的字符仍然會被前面調用的`advance()`方法消費。這一點很重要，這樣我們就不會陷入無限循環了。

> Note also that we *keep scanning*. There may be other errors later in the program. It gives our users a better experience if we detect as many of those as possible in one go. Otherwise, they see one tiny error and fix it, only to have the next error appear, and so on. Syntax error Whac-A-Mole is no fun.

另請注意，我們一直在掃描。 程序稍後可能還會出現其他錯誤。 如果我們能夠一次檢測出儘可能多的錯誤，將為我們的用户帶來更好的體驗。 否則，他們會看到一個小錯誤並修復它，但是卻出現下一個錯誤，不斷重複這個過程。語法錯誤“打地鼠”一點也不好玩。

> (Don’t worry. Since `hadError` gets set, we’ll never try to *execute* any of the code, even though we keep going and scan the rest of it.)

(別擔心。因為`hadError`進行了賦值，我們永遠不會嘗試執行任何代碼，即使程序在繼續運行並掃描代碼文件的其餘部分。)

> ### 4 . 5 . 2 Operators

### 4.5.2 操作符

> We have single-character lexemes working, but that doesn’t cover all of Lox’s operators. What about `!`? It’s a single character, right? Sometimes, yes, but if the very next character is an equals sign, then we should instead create a `!=` lexeme. Note that the `!` and `=` are *not* two independent operators. You can’t write `! =` in Lox and have it behave like an inequality operator. That’s why we need to scan `!=` as a single lexeme. Likewise, `<`, `>`, and `=` can all be followed by `=` to create the other equality and comparison operators.

我們的單字符詞素已經生效了，但是這不能涵蓋Lox中的所有操作符。比如`!`，這是單字符，對吧？有時候是的，但是如果下一個字符是等號，那麼我們應該改用`!=` 詞素。注意，這裏的`!`和`=`*不是*兩個獨立的操作符。在Lox中，你不能寫`! =`來表示不等操作符。這就是為什麼我們需要將`!=`作為單個詞素進行掃描。同樣地，`<`、`>`和`=`都可以與後面跟隨的`=`來組合成其他相等和比較操作符。

> For all of these, we need to look at the second character.

對於所有這些情況，我們都需要查看第二個字符。

*<u>lox/Scanner.java，在 scanToken()方法中添加</u>*

```java
      case '*': addToken(STAR); break; 
      case '!':
        addToken(match('=') ? BANG_EQUAL : BANG);
        break;
      case '=':
        addToken(match('=') ? EQUAL_EQUAL : EQUAL);
        break;
      case '<':
        addToken(match('=') ? LESS_EQUAL : LESS);
        break;
      case '>':
        addToken(match('=') ? GREATER_EQUAL : GREATER);
        break;
      default:
```

> Those cases use this new method:

這些分支中使用了下面的新方法：

*<u>lox/Scanner.java 添加到 scanToken()方法後</u>*

```java
  private boolean match(char expected) {
    if (isAtEnd()) return false;
    if (source.charAt(current) != expected) return false;

    current++;
    return true;
  }
```

> It’s like a conditional `advance()`. We only consume the current character if it’s what we’re looking for.

這就像一個有條件的`advance()`。只有當前字符是我們正在尋找的字符時，我們才會消費。

> Using `match()`, we recognize these lexemes in two stages. When we reach, for example, `!`, we jump to its switch case. That means we know the lexeme *starts* with `!`. Then we look at the next character to determine if we’re on a `!=` or merely a `!`.

使用`match()`，我們分兩個階段識別這些詞素。例如，當我們得到`!`時，我們會跳轉到它的case分支。這意味着我們知道這個詞素是以 `!`開始的。然後，我們查看下一個字符，以確認詞素是一個 `!=` 還是僅僅是一個 `!`。

> ## 4 . 6 Longer Lexemes

## 4.6 更長的詞素

> We’re still missing one operator: `/` for division. That character needs a little special handling because comments begin with a slash too.

我們還缺少一個操作符：表示除法的`/`。這個字符需要一些特殊處理，因為註釋也是以斜線開頭的。

*<u>lox/Scanner.java，在scanToken()方法中添加：</u>*

```java
      break;
      case '/':
        if (match('/')) {
          // A comment goes until the end of the line.
          while (peek() != '\n' && !isAtEnd()) advance();
        } else {
          addToken(SLASH);
        }
        break;
      default:
```

> This is similar to the other two-character operators, except that when we find a second `/`, we don’t end the token yet. Instead, we keep consuming characters until we reach the end of the line.

這與其它的雙字符操作符是類似的，區別在於我們找到第二個`/`時，還沒有結束本次標記。相反，我們會繼續消費字符直至行尾。

> This is our general strategy for handling longer lexemes. After we detect the beginning of one, we shunt over to some lexeme-specific code that keeps eating characters until it sees the end.

這是我們處理較長詞素的一般策略。當我們檢測到一個詞素的開頭後，我們會分流到一些特定於該詞素的代碼，這些代碼會不斷地消費字符，直到結尾。

> We’ve got another helper:

我們又有了一個輔助函數：

*<u>lox/Scanner.java，在match()方法後添加：</u>*

```java
  private char peek() {
    if (isAtEnd()) return '\0';
    return source.charAt(current);
  }
```

> It’s sort of like `advance()`, but doesn’t consume the character. This is called **lookahead**. Since it only looks at the current unconsumed character, we have *one character of lookahead*. The smaller this number is, generally, the faster the scanner runs. The rules of the lexical grammar dictate how much lookahead we need. Fortunately, most languages in wide use peek only one or two characters ahead.

這有點像`advance()`方法，只是不會消費字符。這就是所謂的**lookahead(前瞻)**[^12]。因為它只關注當前未消費的字符，所以我們有*一個前瞻字符*。一般來説，前瞻的字符越少，掃描器運行速度就越快。詞法語法的規則決定了我們需要前瞻多少字符。幸運的是，大多數廣泛使用的語言只需要提前一到兩個字符。

> Comments are lexemes, but they aren’t meaningful, and the parser doesn’t want to deal with them. So when we reach the end of the comment, we *don’t* call `addToken()`. When we loop back around to start the next lexeme, `start` gets reset and the comment’s lexeme disappears in a puff of smoke.

註釋是詞素，但是它們沒有含義，而且解析器也不想要處理它們。所以，我們達到註釋末尾後，*不會*調用`addToken()`方法。當我們循環處理下一個詞素時，`start`已經被重置了，註釋的詞素就消失在一陣煙霧中了。

> While we’re at it, now’s a good time to skip over those other meaningless characters: newlines and whitespace.

既然如此，現在正好可以跳過其它那些無意義的字符了：換行和空格。

*<u>lox/Scanner.java，在scanToken()方法中添加：</u>*

```java
      	break;
      case ' ':
      case '\r':
      case '\t':
        // Ignore whitespace.
        break;

      case '\n':
        line++;
        break;
      default:
        Lox.error(line, "Unexpected character.");
```

> When encountering whitespace, we simply go back to the beginning of the scan loop. That starts a new lexeme *after* the whitespace character. For newlines, we do the same thing, but we also increment the line counter. (This is why we used `peek()` to find the newline ending a comment instead of `match()`. We want that newline to get us here so we can update `line`.)
>

當遇到空白字符時，我們只需回到掃描循環的開頭。這樣就會在空白字符之後開始一個新的詞素。對於換行符，我們做同樣的事情，但我們也會遞增行計數器。(這就是為什麼我們使用`peek()` 而不是`match()`來查找註釋結尾的換行符。我們到這裏希望能讀取到換行符，這樣我們就可以更新行數了)

> Our scanner is getting smarter. It can handle fairly free-form code like:

我們的掃描器越來越聰明瞭。它可以處理相當自由形式的代碼，如：

```java
// this is a comment
(( )){} // grouping stuff
!*+-/=<> <= == // operators
```

> ### 4 . 6 . 1 String literals

### 4.6.1 字符串字面量

> Now that we’re comfortable with longer lexemes, we’re ready to tackle literals. We’ll do strings first, since they always begin with a specific character, `"`.

現在我們對長詞素已經很熟悉了，我們可以開始處理字面量了。我們先處理字符串，因為字符串總是以一個特定的字符`"`開頭。

*<u>lox/Scanner.java，在 scanToken()方法中添加：</u>*

```java
      	break;
      case '"': string(); break;
      default:
```

> That calls:

這裏會調用：

*lox/Scanner.java*，在 *scanToken*()方法之後添加：

```java
  private void string() {
    while (peek() != '"' && !isAtEnd()) {
      if (peek() == '\n') line++;
      advance();
    }

    if (isAtEnd()) {
      Lox.error(line, "Unterminated string.");
      return;
    }

    // The closing ".
    advance();

    // Trim the surrounding quotes.
    String value = source.substring(start + 1, current - 1);
    addToken(STRING, value);
  }
```

> Like with comments, we consume characters until we hit the `"` that ends the string. We also gracefully handle running out of input before the string is closed and report an error for that.

與註釋類似，我們會一直消費字符，直到`"`結束該字符串。如果輸入內容耗盡，我們也會進行優雅的處理，並報告一個對應的錯誤。

> For no particular reason, Lox supports multi-line strings. There are pros and cons to that, but prohibiting them was a little more complex than allowing them, so I left them in. That does mean we also need to update `line` when we hit a newline inside a string.

沒有特別的原因，Lox支持多行字符串。這有利有弊，但禁止換行比允許換行更復雜一些，所以我把它們保留了下來。這意味着當我們在字符串內遇到新行時，我們也需要更新`line`值。

> Finally, the last interesting bit is that when we create the token, we also produce the actual string *value* that will be used later by the interpreter. Here, that conversion only requires a `substring()` to strip off the surrounding quotes. If Lox supported escape sequences like `\n`, we’d unescape those here.

最後，還有一個有趣的地方就是當我們創建標記時，我們也會產生實際的字符串值，該值稍後將被解釋器使用。這裏，值的轉換只需要調用`substring()`剝離前後的引號。如果Lox支持轉義序列，比如`\n`，我們會在這裏取消轉義。

> ### 4 . 6 . 2 Number literals

### 4.6.2 數字字面量

> All numbers in Lox are floating point at runtime, but both integer and decimal literals are supported. A number literal is a series of digits optionally followed by a `.` and one or more trailing digits.

在Lox中，所有的數字在運行時都是浮點數，但是同時支持整數和小數字面量。一個數字字面量就是一系列數位，後面可以跟一個`.`和一或多個尾數[^13]。

```java
1234
12.34
```

我們不允許小數點處於最開始或最末尾，所以下面的格式是不正確的：

```java
.1234
1234.
```

> We could easily support the former, but I left it out to keep things simple. The latter gets weird if we ever want to allow methods on numbers like `123.sqrt()`.

我們可以很容易地支持前者，但為了保持簡單，我把它刪掉了。如果我們要允許對數字進行方法調用，比如`123.sqrt()`，後者會變得很奇怪。

> To recognize the beginning of a number lexeme, we look for any digit. It’s kind of tedious to add cases for every decimal digit, so we’ll stuff it in the default case instead.

為了識別數字詞素的開頭，我們會尋找任何一位數字。 為每個十進制數字添加case分支有點乏味，所以我們直接在默認分支中進行處理。

*<u>lox/Scanner.java，在 scanToken()方法中替換一行：</u>*

```java
      default:
      	// 替換部分開始
      	if (isDigit(c)) {
          number();
        } else {
          Lox.error(line, "Unexpected character.");
        }
        // 替換部分結束
        break;
```

> This relies on this little utility:

這裏依賴下面的小工具函數[^14]：

*<u>lox/Scanner.java，在 peek()方法之後添加：</u>*

```java
  private boolean isDigit(char c) {
    return c >= '0' && c <= '9';
  } 
```

> Once we know we are in a number, we branch to a separate method to consume the rest of the literal, like we do with strings.

一旦我們知道當前在處理數字，我們就分支進入一個單獨的方法消費剩餘的字面量，跟字符串的處理類似。

*<u>lox/Scanner.java，在 scanToken()方法後添加：</u>*

```java
  private void number() {
    while (isDigit(peek())) advance();

    // Look for a fractional part.
    if (peek() == '.' && isDigit(peekNext())) {
      // Consume the "."
      advance();

      while (isDigit(peek())) advance();
    }

    addToken(NUMBER,
        Double.parseDouble(source.substring(start, current)));
  }
```

> We consume as many digits as we find for the integer part of the literal. Then we look for a fractional part, which is a decimal point (`.`) followed by at least one digit. If we do have a fractional part, again, we consume as many digits as we can find.

我們在字面量的整數部分中儘可能多地獲取數字。然後我們尋找小數部分，也就是一個小數點(`.`)後面至少跟一個數字。如果確實有小數部分，同樣地，我們也儘可能多地獲取數字。

> Looking past the decimal point requires a second character of lookahead since we don’t want to consume the `.` until we’re sure there is a digit *after* it. So we add:

在定位到小數點之後需要繼續前瞻第二個字符，因為我們只有確認其*後*有數字才會消費`.`。所以我們添加了[^15]：

*<u>lox/Scanner.java，在 peek()方法後添加</u>*

```java
  private char peekNext() {
    if (current + 1 >= source.length()) return '\0';
    return source.charAt(current + 1);
  }
```

> Finally, we convert the lexeme to its numeric value. Our interpreter uses Java’s `Double` type to represent numbers, so we produce a value of that type. We’re using Java’s own parsing method to convert the lexeme to a real Java double. We could implement that ourselves, but, honestly, unless you’re trying to cram for an upcoming programming interview, it’s not worth your time.

最後，我們將詞素轉換為其對應的數值。我們的解釋器使用Java的`Double`類型來表示數字，所以我們創建一個該類型的值。我們使用Java自帶的解析方法將詞素轉換為真正的Java double。我們可以自己實現，但是，説實話，除非你想為即將到來的編程面試做準備，否則不值得你花時間。

> The remaining literals are Booleans and `nil`, but we handle those as keywords, which gets us to . . . 

剩下的詞素是Boolean和`nil`，但我們把它們作為關鍵字來處理，這樣我們就來到了......

> ## 4 . 7 Reserved Words and Identifiers

## 4.7 保留字和標識符

> Our scanner is almost done. The only remaining pieces of the lexical grammar to implement are identifiers and their close cousins, the reserved words. You might think we could match keywords like `or` in the same way we handle multiple-character operators like `<=`.

我們的掃描器基本完成了，詞法語法中還需要實現的部分僅剩標識符及其近親——保留字。你也許會想，我們可以採用與處理`<=`等多字符操作符時相同的方法來匹配關鍵字，如`or`。

```java
case 'o':
  if (peek() == 'r') {
    addToken(OR);
  }
  break;
```

> Consider what would happen if a user named a variable `orchid`. The scanner would see the first two letters, `or`, and immediately emit an `or` keyword token. This gets us to an important principle called **maximal munch**. When two lexical grammar rules can both match a chunk of code that the scanner is looking at, *whichever one matches the most characters wins*.

考慮一下，如果用户將變量命名為`orchid`會發生什麼？掃描器會先看到前面的兩個字符，然後立刻生成一個`or`標記。這就涉及到了一個重要原則，叫作**maximal munch**(最長匹配)[^16]。當兩個語法規則都能匹配掃描器正在處理的一大塊代碼時，*哪個規則相匹配的字符最多，就使用哪個規則*。

> That rule states that if we can match `orchid` as an identifier and `or` as a keyword, then the former wins. This is also why we tacitly assumed, previously, that `<=` should be scanned as a single `<=` token and not `<` followed by `=`.

該規則規定，如果我們可以將`orchid`匹配為一個標識符，也可以將`or`匹配為一個關鍵字，那就採用第一種結果。這也就是為什麼我們在前面會默認為，`<=`應該識別為單一的`<=`標記，而不是`<`後面跟了一個`=`。

> Maximal munch means we can’t easily detect a reserved word until we’ve reached the end of what might instead be an identifier. After all, a reserved word *is* an identifier, it’s just one that has been claimed by the language for its own use. That’s where the term **reserved word** comes from.

最大匹配原則意味着，我們只有掃描完一個可能是標識符的片段，才能確認是否一個保留字。畢竟，保留字也是一個標識符，只是一個已經被語言要求為自己所用的標識符。這也是**保留字**一詞的由來。

> So we begin by assuming any lexeme starting with a letter or underscore is an identifier.

所以我們首先假設任何以字母或下劃線開頭的詞素都是一個標識符。

*<u>lox/Scanner.java，在 scanToken()中添加代碼</u>*

```java
        default:
        if (isDigit(c)) {
          number();
          // 新增部分開始
        } else if (isAlpha(c)) {
          identifier();
        // 新增部分結束
        } else {
          Lox.error(line, "Unexpected character.");
        }
```

> The rest of the code lives over here:

其它代碼如下：

*<u>lox/Scanner.java，在 scanToken()方法之後添加：</u>*

```java
  private void identifier() {
    while (isAlphaNumeric(peek())) advance();

    addToken(IDENTIFIER);
  }
```

> We define that in terms of these helpers:

通過以下輔助函數來定義：

*<u>lox/Scanner.java，在 peekNext()方法之後添加：</u>*

```java
  private boolean isAlpha(char c) {
    return (c >= 'a' && c <= 'z') ||
           (c >= 'A' && c <= 'Z') ||
            c == '_';
  }

  private boolean isAlphaNumeric(char c) {
    return isAlpha(c) || isDigit(c);
  }
```

> That gets identifiers working. To handle keywords, we see if the identifier’s lexeme is one of the reserved words. If so, we use a token type specific to that keyword. We define the set of reserved words in a map.

這樣標識符就開始工作了。為了處理關鍵字，我們要查看標識符的詞素是否是保留字之一。如果是，我們就使用該關鍵字特有的標記類型。我們在map中定義保留字的集合。

<u>*lox/Scanner.java，在 Scanner類中添加：</u>*

```java
  private static final Map<String, TokenType> keywords;

  static {
    keywords = new HashMap<>();
    keywords.put("and",    AND);
    keywords.put("class",  CLASS);
    keywords.put("else",   ELSE);
    keywords.put("false",  FALSE);
    keywords.put("for",    FOR);
    keywords.put("fun",    FUN);
    keywords.put("if",     IF);
    keywords.put("nil",    NIL);
    keywords.put("or",     OR);
    keywords.put("print",  PRINT);
    keywords.put("return", RETURN);
    keywords.put("super",  SUPER);
    keywords.put("this",   THIS);
    keywords.put("true",   TRUE);
    keywords.put("var",    VAR);
    keywords.put("while",  WHILE);
  }
```

> Then, after we scan an identifier, we check to see if it matches anything in the map.

接下來，在我們掃描到標識符之後，要檢查是否與map中的某些項匹配。

*<u>lox/Scanner.java，在 identifier()方法中替換一行：</u>*

```java
    while (isAlphaNumeric(peek())) advance();

    // 替換部分開始
    String text = source.substring(start, current);
    TokenType type = keywords.get(text);
    if (type == null) type = IDENTIFIER;
    addToken(type);
    // 替換部分結束
  }
```

> If so, we use that keyword’s token type. Otherwise, it’s a regular user-defined identifier.

如果匹配的話，就使用關鍵字的標記類型。否則，就是一個普通的用户定義的標識符。

> And with that, we now have a complete scanner for the entire Lox lexical grammar. Fire up the REPL and type in some valid and invalid code. Does it produce the tokens you expect? Try to come up with some interesting edge cases and see if it handles them as it should.

至此，我們就有了一個完整的掃描器，可以掃描整個Lox詞法語法。啓動REPL，輸入一些有效和無效的代碼。它是否產生了你所期望的詞法單元？試着想出一些有趣的邊界情況，看看它是否能正確地處理它們。



[^1]: 一直以來，這項工作被稱為 "掃描(scanning) "和 "詞法分析(lexing)"（ "詞法分析(lexical analysis)"的簡稱）。早在計算機還像Winnebagos一樣大，但內存比你的手錶還小的時候，有些人就用 "掃描 "來指代從磁盤上讀取原始源代碼字符並在內存中緩衝的那段代碼。然後，"lexing "是後續階段，對字符做有用的操作。現在，將源文件讀入內存是很平常的事情，因此在編譯器中很少出現不同的階段。 因此，這兩個術語基本上可以互換。
[^2]: `System.exit(64)`，對於退出代碼，我使用UNIX sysexts .h頭文件中定義的約定。這是我能找到的最接近標準的東西。
[^3]: 交互式提示符也被稱為REPL(發音像rebel，但替換為p)。它的名稱來自於Lisp，實現Lisp非常簡單，只需圍繞幾個內置函數進行循環:`(print (eval (read)))`從嵌套最內的調用向外執行，讀取一行輸入，求值，打印結果，然後循環並再次執行。
[^4]: 説了這麼多，對於這個解釋器，我們要構建的只是基本框架。我很想談談交互式調試器、靜態分析器和其它有趣的東西，但是篇幅實在有限。
[^5]: 我第一次實現jlox的時候正是如此。最後我把它拆出去了，因為對於本書的最小解釋器來説，這有點過度設計了。
[^6]: 畢竟，字符串比較最終也會比對單個字符，這不正是掃描器的工作嗎？
[^7]: 一些標記實現將位置存儲為兩個數字：從源文件開始到詞素開始的偏移量，以及詞素的長度。掃描器無論如何都會知道這些數字，因此計算這些數字沒有任何開銷。通過回頭查看源文件並計算前面的換行數，可以將偏移量轉換為行和列位置。這聽起來很慢，確實如此。然而，只有當你需要向用户實際顯示行和列的時候，你才需要這樣做。大多數標記從來不會出現在錯誤信息中。對於這些標記，你花在提前計算位置信息上的時間越少越好。
[^8]: 我很痛心要對理論做這麼多掩飾，尤其是當它像[喬姆斯基譜系](https://en.wikipedia.org/wiki/Chomsky_hierarchy)和[有限狀態機](https://en.wikipedia.org/wiki/Finite-state_machine)那樣有趣的時候。但説實話，其他的書比我寫得好。[*Compilers: Principles, Techniques, and Tools*](https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools)(常被稱為“龍書”)是最經典的參考書。
[^9]: Lex是由Mike Lesk和Eric Schmidt創建的。是的，就是那個曾任谷歌執行董事長的Eric Schmidt。我並不是説編程語言是通往財富和名聲的必經之路，但我們中至少已經有一位超級億萬富翁。
[^10]: 我知道很多人認為靜態導入是一種不好的代碼風格，但這樣我就不必在掃描器和解析器中到處寫`TokenType`了。恕我直言，在一本書中，每個字符都很重要
[^11]: 想知道這裏為什麼沒有`/`嗎？別擔心，我們會解決的。
[^12]: 技術上來説，`match()`方法也是在做前瞻。`advance()`和`peek()`是基本運算符，`match()`將它們結合起來。
[^13]: 因為我們只會根據數字來判斷數字字面量，這就意味着`-123`不是一個數字*字面量*。相反，`-123`是一個*表達式*，將`-`應用到數字字面量`123`。在實踐中，結果是一樣的，儘管它有一個有趣的邊緣情況。試想一下，如果我們要在數字上添加方法調用：`print -123.abs();`，這裏會輸出`-123`，因為負號的優先級低於方法調用。我們可以通過將`-`作為數字字面值的一部分來解決這個問題。但接着考慮：`var n = 123; print -n.abs();`，結果仍然是`-123`，所以現在語言似乎不一致。無論你怎麼做，有些情況最後都會變得很奇怪。
[^14]: Java標準庫中提供了[Character.isDigit()](http://docs.oracle.com/javase/7/docs/api/java/lang/Character.html#isDigit(char))，這似乎是個不錯的選擇。唉，該方法中還允許梵文數字、全寬數字和其他我們不想要的有趣的東西。
[^15]: 我本可以讓`peek()`方法接受一個參數來表示要前瞻的字符數，而不需要定義兩個函數。但這樣做就會允許前瞻任意長度的字符。提供兩個函數可以讓讀者更清楚地知道，我們的掃描器最多隻能向前看兩個字符。
[^16]: 看一下這段討厭的C代碼：`---a;`，它有效嗎？這取決於掃描器如何分割詞素。如果掃描器看到的是`- --a;`，那它就可以被解析。但是這需要掃描器知道代碼前後的語法結構，這比我們需要的更復雜。相反，最大匹配原則表明，掃描結果總是：`-- -a;`，它就會這樣掃描，儘管這樣做會在解析器中導致後面的語法錯誤。

------

> ## CHALLENGES

## 習題

> 1、The lexical grammars of Python and Haskell are not *regular*. What does that mean, and why aren’t they?

1、Python和Haskell的語法不是*常規的*。 這是什麼意思，為什麼不是呢？

* Python和Haskell都採用了對縮進敏感的語法，所以它們必須將縮進級別的變動識別為詞法標記。這樣做需要比較連續行的開頭空格數量，這是使用常規語法無法做到的。

> 2、Aside from separating tokens—distinguishing `print foo` from `printfoo`—spaces aren’t used for much in most languages. However, in a couple of dark corners, a space *does* affect how code is parsed in CoffeeScript, Ruby, and the C preprocessor. Where and what effect does it have in each of those languages?

2、除了分隔標記——區分`print foo`和`printfoo`——空格在大多數語言中並沒有什麼用處。在CoffeeScript、Ruby和C預處理器中的一些隱秘的地方，空格確實會影響代碼解析方式。在這些語言中，空格在什麼地方，會有什麼影響？

> 3、Our scanner here, like most, discards comments and whitespace since those aren’t needed by the parser. Why might you want to write a scanner that does *not* discard those? What would it be useful for?

3、我們這裏的掃描器和大多數掃描器一樣，會丟棄註釋和空格，因為解析器不需要這些。什麼情況下你會寫一個不丟棄這些的掃描器？它有什麼用呢？

> 4、Add support to Lox’s scanner for C-style `/* ... */` block comments. Make sure to handle newlines in them. Consider allowing them to nest. Is adding support for nesting more work than you expected? Why?

4、為Lox掃描器增加對C樣式`/ * ... * /`屏蔽註釋的支持。確保要處理其中的換行符。 考慮允許它們嵌套， 增加對嵌套的支持是否比你預期的工作更多？ 為什麼？

------

> ## DESIGN NOTE: IMPLICIT SEMICOLONS

## 設計筆記：隱藏的分號

> Programmers today are spoiled for choice in languages and have gotten picky about syntax. They want their language to look clean and modern. One bit of syntactic lichen that almost every new language scrapes off (and some ancient ones like BASIC never had) is `;` as an explicit statement terminator.
>
> Instead, they treat a newline as a statement terminator where it makes sense to do so. The “where it makes sense” part is the challenging bit. While *most* statements are on their own line, sometimes you need to spread a single statement across a couple of lines. Those intermingled newlines should not be treated as terminators.
>
> Most of the obvious cases where the newline should be ignored are easy to detect, but there are a handful of nasty ones:
>
> - A return value on the next line:
>
>   ```
>   if (condition) return
>   "value"
>   ```
>
>   Is “value” the value being returned, or do we have a `return` statement with no value followed by an expression statement containing a string literal?
>
> - A parenthesized expression on the next line:
>
>   ```
>   func
>   (parenthesized)
>   ```
>
>   Is this a call to `func(parenthesized)`, or two expression statements, one for `func` and one for a parenthesized expression?
>
> - A `-` on the next line:
>
>   ```
>   first
>   -second
>   ```
>
>   Is this `first - second`—an infix subtraction—or two expression statements, one for `first` and one to negate `second`?
>
> In all of these, either treating the newline as a separator or not would both produce valid code, but possibly not the code the user wants. Across languages, there is an unsettling variety of rules used to decide which newlines are separators. Here are a couple:
>
> - [Lua](https://www.lua.org/pil/1.1.html) completely ignores newlines, but carefully controls its grammar such that no separator between statements is needed at all in most cases. This is perfectly legit:
>
>   ```
>   a = 1 b = 2
>   ```
>
>   Lua avoids the `return` problem by requiring a `return` statement to be the very last statement in a block. If there is a value after `return` before the keyword `end`, it *must* be for the `return`. For the other two cases, they allow an explicit `;` and expect users to use that. In practice, that almost never happens because there’s no point in a parenthesized or unary negation expression statement.
>
> - [Go](https://golang.org/ref/spec#Semicolons) handles newlines in the scanner. If a newline appears following one of a handful of token types that are known to potentially end a statement, the newline is treated like a semicolon, otherwise it is ignored. The Go team provides a canonical code formatter, [gofmt](https://golang.org/cmd/gofmt/), and the ecosystem is fervent about its use, which ensures that idiomatic styled code works well with this simple rule.
>
> - [Python](https://docs.python.org/3.5/reference/lexical_analysis.html#implicit-line-joining) treats all newlines as significant unless an explicit backslash is used at the end of a line to continue it to the next line. However, newlines anywhere inside a pair of brackets (`()`, `[]`, or `{}`) are ignored. Idiomatic style strongly prefers the latter.
>
>   This rule works well for Python because it is a highly statement-oriented language. In particular, Python’s grammar ensures a statement never appears inside an expression. C does the same, but many other languages which have a “lambda” or function literal syntax do not.
>
>   An example in JavaScript:
>
>   ```
>   console.log(function() {
>     statement();
>   });
>   ```
>
>   Here, the `console.log()` *expression* contains a function literal which in turn contains the *statement* `statement();`.
>
>   Python would need a different set of rules for implicitly joining lines if you could get back *into* a statement where newlines should become meaningful while still nested inside brackets.
>
> - JavaScript’s “[automatic semicolon insertion](https://www.ecma-international.org/ecma-262/5.1/#sec-7.9)” rule is the real odd one. Where other languages assume most newlines *are* meaningful and only a few should be ignored in multi-line statements, JS assumes the opposite. It treats all of your newlines as meaningless whitespace *unless* it encounters a parse error. If it does, it goes back and tries turning the previous newline into a semicolon to get something grammatically valid.
>
>   This design note would turn into a design diatribe if I went into complete detail about how that even *works*, much less all the various ways that JavaScript’s “solution” is a bad idea. It’s a mess. JavaScript is the only language I know where many style guides demand explicit semicolons after every statement even though the language theoretically lets you elide them.
>
> If you’re designing a new language, you almost surely *should* avoid an explicit statement terminator. Programmers are creatures of fashion like other humans, and semicolons are as passé as ALL CAPS KEYWORDS. Just make sure you pick a set of rules that make sense for your language’s particular grammar and idioms. And don’t do what JavaScript did.

現在的程序員已經被越來越多的語言選擇寵壞了，對語法也越來越挑剔。他們希望自己的代碼看起來乾淨、現代化。幾乎每一種新語言都會放棄一個小的語法點（一些古老的語言，比如BASIC從來沒有過），那就是將`;`作為顯式的語句結束符。

相對地，它們將“有意義的”換行符看作是語句結束符。這裏所説的“有意義的”是有挑戰性的部分。儘管*大多數的*語句都是在同一行，但有時你需要將一個語句擴展到多行。這些混雜的換行符不應該被視作結束符。

大多數明顯的應該忽略換行的情況都很容易發現，但也有少數討厭的情況：

* 返回值在下一行：

  ```js
  if (condition) return
  "value"
  ```

  “value”是要返回的值嗎？還是説我們有一個空的`return`語句，後面跟着包含一個字符串字面量的表達式語句。

* 下一行中有帶圓括號的表達式：

  ```js
  func
  (parenthesized)
  ```

  這是一個對`func(parenthesized)`的調用，還是兩個表達式語句，一個用於`func`，一個用於圓括號表達式？

* “-”號在下一行：

  ```js
  first
  -second
  ```

  這是一箇中綴表達式——`first - second`，還是兩個表達式語句，一個是`first`，另一個是對`second`取負？

在所有這些情況下，無論是否將換行符作為分隔符，都會產生有效的代碼，但可能不是用户想要的代碼。在不同的語言中，有各種不同的規則來決定哪些換行符是分隔符。下面是幾個例子：

* [Lua](https://www.lua.org/pil/1.1.html)完全忽略了換行符，但是仔細地控制了它的語法，因此在大多數情況下，語句之間根本不需要分隔符。這段代碼是完全合法的：

  ```lua
  a = 1 b = 2
  ```

  Lua要求 `return` 語句是一個塊中的最後一條語句，從而避免` return` 問題。如果在關鍵字`end`之前、`return`之後有一個值，這個值*必須*是用於`return`。對於其他兩種情況來説，Lua允許顯式的`;`並且期望用户使用它。在實踐中，這種情況基本不會發生，因為在小括號或一元否定表達式語句中沒有任何意義。

* [Go](https://golang.org/ref/spec#Semicolons)會處理掃描器中的換行。如果在詞法單元之後出現換行，並且該詞法標記是已知可能結束語句的少數標記類型之一，則將換行視為分號，否則就忽略它。Go團隊提供了一個規範的代碼格式化程序[gofmt](https://golang.org/cmd/gofmt/)，整個軟件生態系統非常熱衷於使用它，這確保了常用樣式的代碼能夠很好地遵循這個簡單的規則。

* Python將所有換行符都視為有效，除非在行末使用明確的反斜槓將其延續到下一行。但是，括號(`()`、`[]`或`{}`)內的任何換行都將被忽略。慣用的代碼風格更傾向於後者。

  這條規則對 Python 很有效，因為它是一種高度面向語句的語言。特別是，Python 的語法確保了語句永遠不會出現在表達式內。C語言也是如此，但許多其他有 "lambda "或函數字面語法的語言則不然。

  舉一個JavaScript中的例子：

  ```js
  console.log(function() {
    statement();
  });
  ```

  這裏，`console.log()` *表達式*包含一個函數字面量，而這個函數字面量又包含` statement();`*語句*。

  如果要求*進入*一個嵌套在括號內的語句中，並且要求其中的換行是有意義的，那麼Python將需要一套不同的隱式連接行的規則[^lambda]。

* JavaScript的“[自動分號插入](https://www.ecma-international.org/ecma-262/5.1/#sec-7.9)”規則才是真正的奇葩。其他語言認為大多數換行符都是有意義的，只有少數換行符在多行語句中應該被忽略，而JS的假設恰恰相反。它將所有的換行符都視為無意義的空白，除非遇到解析錯誤。如果遇到了，它就會回過頭來，嘗試把之前的換行變成分號，以期得到正確的語法。

  如果我完全詳細地介紹它是如何工作的，那麼這個設計説明就會變成一篇設計檄文，更不用説JavaScript的“解決方案”從各種角度看都是個壞主意。真是一團糟。JavaScript是我所知道的唯一（風格指南和語言本身背離）的語言，它的許多風格指南要求在每條語句後都顯式地使用分號，但該語言卻理論上允許您省略分號。

如果您要設計一種新的語言，則幾乎可以肯定應該避免使用顯式的語句終止符。 程序員和其他人類一樣是時尚的動物，分號和ALL CAPS KEYWORDS(全大寫關鍵字)一樣已經過時了。只是要確保您選擇了一套適用於您語言的特定語法和習語的規則即可。不要重蹈JavaScript的覆轍。



[^lambda]: 現在你明白為什麼Python中的`lambda`只允許單行的表達式體了吧。
